{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U langgraph langsmith\n",
    "! pip install langchain_community\n",
    "! pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END ,state\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage,AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration de la clé API\n",
    "os.environ['OPENAI_API_KEY'] = \"sk-proj-0xUZ6aBpi14QWLt CT3BlbkFJ6nuNH0hRFwAy9HhFfHS_cUMhXQMX6_U0pycw_XiZUUtZ4V6Gc5xEwhMZOsYA6xKN4HruNnPRcA\"\n",
    "\n",
    "\n",
    "# Création du modèle LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainty-Routed CoT Prompting\n",
    "\n",
    "Uncertainty-Routed CoT Prompting, introduced by Google (2023), is an innovative method that enhances reasoning in language models (LLMs) by strategically managing multiple reasoning paths.\n",
    "\n",
    "## How Does Uncertainty-Routed CoT Prompting Work?\n",
    "\n",
    "Imagine you're solving a complex problem. Instead of committing to your first approach, you might try several different solutions, then go with the one that multiple methods converge on—unless there's significant disagreement, in which case you'd take extra care with a single thorough approach.\n",
    "\n",
    "Uncertainty-Routed CoT Prompting follows this logic in three key steps:\n",
    "\n",
    "1. **Multiple Reasoning Paths**: The LLM generates several different chains of thought (CoT) for the same problem.\n",
    "\n",
    "2. **Majority Analysis**: The model examines all solutions and identifies whether a majority of paths lead to the same answer. The level of agreement across paths determines the confidence level.\n",
    "\n",
    "3. **Threshold-Based Selection**: If confidence exceeds a predetermined threshold (calculated from validation data), the majority answer is selected. Otherwise, the model generates a single \"greedy\" reasoning path and uses that answer instead.\n",
    "\n",
    "This approach cleverly balances between consensus-based decision making when confidence is high and focused single-path reasoning when uncertainty prevails, leading to improved performance on complex reasoning tasks like MMLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty_routed_cot_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "    Generate solutions using Uncertainty-Routed CoT Prompting for a given user question.\n",
    "\n",
    "    Uncertainty-Routed CoT Prompting involves generating multiple Chain-of-Thought (CoT) reasoning paths, then selecting the majority answer if it's above a certain confidence threshold. If not, it selects the answer from a single, greedily generated CoT path.\n",
    "\n",
    "    Please structure your response in the following format:\n",
    "\n",
    "    Step 1: Generate Multiple CoT Reasoning Paths\n",
    "    [Generate 3-5 different CoT reasoning paths for the given question.]\n",
    "\n",
    "    Step 2: Analyze Uncertainty and Majority Answer\n",
    "    [Identify the majority answer among the generated paths and assess the level of agreement.]\n",
    "\n",
    "    Step 3: Apply Threshold and Select Answer\n",
    "    [If the majority answer meets the confidence threshold, select it. Otherwise, generate a single, greedy CoT path and select its answer.]\n",
    "\n",
    "    Step 4: Final Solution\n",
    "    [Provide the selected answer with a brief explanation of the reasoning process.]\n",
    "\n",
    "    Example:\n",
    "    Question: \"If a train travels at 60 km/h and covers 300 km, how long does it take?\"\n",
    "\n",
    "    Step 1: Generate Multiple CoT Reasoning Paths\n",
    "    Path 1:\n",
    "    Distance = 300 km, Speed = 60 km/h.\n",
    "    Time = Distance / Speed = 300 / 60 = 5 hours.\n",
    "    Answer: 5 hours.\n",
    "\n",
    "    Path 2:\n",
    "    To find the time, divide the distance by the speed.\n",
    "    300 km / 60 km/h = 5 hours.\n",
    "    Answer: 5 hours.\n",
    "\n",
    "    Path 3:\n",
    "    The train travels 60 km in 1 hour.\n",
    "    To cover 300 km, it takes 300 / 60 = 5 hours.\n",
    "    Answer: 5 hours.\n",
    "\n",
    "    Step 2: Analyze Uncertainty and Majority Answer\n",
    "    All paths agree on the answer: 5 hours.\n",
    "    Confidence is high.\n",
    "\n",
    "    Step 3: Apply Threshold and Select Answer\n",
    "    Since all paths agree, the majority answer is selected.\n",
    "\n",
    "    Step 4: Final Solution\n",
    "    The train takes 5 hours to cover 300 km.\n",
    "    \"\"\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "    (\"assistant\", \"\"\"\n",
    "    I will use Uncertainty-Routed CoT Prompting to solve this problem.\n",
    "\n",
    "    Step 1: Generate Multiple CoT Reasoning Paths\n",
    "    [Generate multiple CoT reasoning paths for the question.]\n",
    "\n",
    "    Step 2: Analyze Uncertainty and Majority Answer\n",
    "    [Analyze the generated paths to identify the majority answer and assess confidence.]\n",
    "\n",
    "    Step 3: Apply Threshold and Select Answer\n",
    "    [Apply the threshold to select the answer.]\n",
    "\n",
    "    Step 4: Final Solution\n",
    "    [Provide the final solution.]\n",
    "    \"\"\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suitable Questions for Uncertainty-Routed CoT Prompting\n",
    "\n",
    "For Uncertainty-Routed CoT Prompting, the most suitable questions are those that benefit from exploring multiple reasoning paths to manage uncertainty effectively. Here are types of questions that would be particularly well-suited to this approach:\n",
    "\n",
    "### Complex Reasoning Problems\n",
    "- Multi-step logical puzzles with potential for divergent approaches\n",
    "- Probability questions with subtle considerations\n",
    "- Problems with potential calculation traps or common misunderstandings\n",
    "- Scenarios where intuition might lead to incorrect first impressions\n",
    "\n",
    "### Ambiguous Analysis Scenarios\n",
    "- Word problems with potentially misleading wording\n",
    "- Questions where multiple valid interpretations exist\n",
    "- Problems where experts might disagree on methodology\n",
    "- Cases requiring weighing of competing factors\n",
    "\n",
    "### Problems with Verification Challenges\n",
    "- Questions where common errors are easy to make but hard to detect\n",
    "- Mathematical problems where computational accuracy matters\n",
    "- Reasoning tasks where small mistakes compound significantly\n",
    "- Scenarios where different approaches produce slightly different answers\n",
    "\n",
    "### Concrete Examples of Questions\n",
    "1. \"If a factory produces widgets at a rate of 800 per day with 5% defective, and each widget costs $3 to make and sells for $8, what is the expected daily profit after accounting for defects?\"\n",
    "   - Multiple paths might handle the defect calculation differently, revealing uncertainties\n",
    "\n",
    "2. \"A dice is rolled 5 times. What is the probability of getting exactly 3 sixes?\"\n",
    "   - Different approaches (combinatorial, direct probability) might yield slightly different results due to rounding or calculation errors\n",
    "\n",
    "3. \"Based on these symptoms and test results, what is the most likely diagnosis from these five possibilities?\"\n",
    "   - Different diagnostic reasoning paths might emphasize different factors, revealing uncertainty in medical reasoning\n",
    "\n",
    "4. \"In what year will Country A's GDP exceed Country B's GDP, given their current values and growth rates?\"\n",
    "   - Different modeling assumptions could lead to different projected years\n",
    "\n",
    "5. \"Is this algorithm's time complexity O(n log n) or O(n²)?\"\n",
    "   - Multiple analysis approaches might yield different conclusions about edge cases\n",
    "\n",
    "Uncertainty-Routed CoT Prompting is particularly effective for these types of questions because:\n",
    "- It generates multiple reasoning paths to explore different angles\n",
    "- It identifies when there's strong consensus across reasoning attempts\n",
    "- It detects uncertainty when different paths lead to different conclusions\n",
    "- It automatically adjusts the approach based on confidence in the majority answer\n",
    "- It provides a fallback strategy (greedy path) when uncertainty is high\n",
    "\n",
    "This approach is especially powerful when dealing with problems where reasoning errors are common or where the confidence in an answer is as important as the answer itself. Unlike approaches that always pick the majority answer, this method intelligently adapts based on the level of uncertainty detected across multiple reasoning attempts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION:\n",
      "If a factory produces widgets at a rate of 800 per day with 5% defective, and each widget costs $3 to make and sells for $8, what is the expected daily profit after accounting for defects?\n",
      "\n",
      "FINAL SOLUTION:\n",
      "The expected daily profit after accounting for defects is $3680. This was determined by calculating the total revenue from non-defective widgets and subtracting the total production cost.\n",
      "\n",
      "(Complete results saved in 'uncertainty_routed_cot_result.txt')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from typing import Optional, TypedDict, Annotated\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "\n",
    "# Function to generate the Uncertainty-Routed CoT prompt and extract the final answer\n",
    "def generate_uncertainty_routed_cot_node(state):\n",
    "    question = state['messages'][-1].content  # Get the last question\n",
    "    prompt_value = uncertainty_routed_cot_template.invoke({\"question\": question})\n",
    "    messages = prompt_value.to_messages()\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    # Keep the full response for processing\n",
    "    full_response = response.content\n",
    "    \n",
    "    # Extract the final solution from Step 4\n",
    "    final_solution_pattern = r'Step 4: Final Solution\\s*([\\s\\S]*?)(?=$|Step \\d:)'\n",
    "    final_solution_match = re.search(final_solution_pattern, full_response)\n",
    "    \n",
    "    if final_solution_match:\n",
    "        final_solution = final_solution_match.group(1).strip()\n",
    "    else:\n",
    "        # Alternative pattern for different formatting\n",
    "        alternative_pattern = r'Step 4:([\\s\\S]*?)(?=$|Step \\d:)'\n",
    "        alternative_match = re.search(alternative_pattern, full_response)\n",
    "        \n",
    "        if alternative_match:\n",
    "            final_solution = alternative_match.group(1).strip()\n",
    "        else:\n",
    "            final_solution = \"Final solution not found in the expected format.\"\n",
    "    \n",
    "    # Save both the question, final answer, and full processing to a text file\n",
    "    with open('uncertainty_routed_cot_result.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=== QUESTION ===\\n\\n\")\n",
    "        f.write(question)\n",
    "        f.write(\"\\n\\n=== FINAL SOLUTION ===\\n\\n\")\n",
    "        f.write(final_solution)\n",
    "        f.write(\"\\n\\n=== COMPLETE PROCESSING (FOR REFERENCE) ===\\n\\n\")\n",
    "        f.write(full_response)\n",
    "    \n",
    "    # Return only the final solution in messages, plus the original question for reference\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=final_solution)],\n",
    "        \"question\": question,\n",
    "        \"full_response\": full_response\n",
    "    }\n",
    "\n",
    "# Definition of state\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    question: Optional[str]\n",
    "    full_response: Optional[str]\n",
    "\n",
    "# Graph creation\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"generate_uncertainty_routed_cot\", generate_uncertainty_routed_cot_node)\n",
    "\n",
    "# Graph configuration\n",
    "graph_builder.set_entry_point(\"generate_uncertainty_routed_cot\")\n",
    "graph_builder.add_edge(\"generate_uncertainty_routed_cot\", END)\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "# Usage example\n",
    "inputs = {\n",
    "    \"messages\": [HumanMessage(content=\"If a factory produces widgets at a rate of 800 per day with 5% defective, and each widget costs $3 to make and sells for $8, what is the expected daily profit after accounting for defects?\")],\n",
    "    \"question\": None,\n",
    "    \"full_response\": None\n",
    "}\n",
    "\n",
    "# Print the question at the beginning\n",
    "print(\"QUESTION:\")\n",
    "print(inputs[\"messages\"][0].content)\n",
    "print(\"\\nFINAL SOLUTION:\")\n",
    "\n",
    "# Graph execution - only display the final solution\n",
    "original_question = \"\"\n",
    "for output in graph.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        if key == \"generate_uncertainty_routed_cot\":\n",
    "            messages = value['messages']\n",
    "            for message in messages:\n",
    "                if isinstance(message, AIMessage):\n",
    "                    print(message.content)\n",
    "            \n",
    "            # Store question for reference\n",
    "            if \"question\" in value:\n",
    "                original_question = value[\"question\"]\n",
    "\n",
    "# Print confirmation that results were saved\n",
    "print(\"\\n(Complete results saved in 'uncertainty_routed_cot_result.txt')\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
