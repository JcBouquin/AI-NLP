{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U langgraph langsmith\n",
    "! pip install langchain_community\n",
    "! pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END ,state\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage,AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration de la clé API\n",
    "os.environ['OPENAI_API_KEY'] = \"sk-proj-0xUZ6aBpi14QWLtzQC2nF0B2gQTojxukve0byW1qgx0 \n",
    "\n",
    "# Création du modèle LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Chain-of-Thought (Auto-CoT) Prompting\n",
    "\n",
    "Automatic Chain-of-Thought (Auto-CoT) Prompting, introduced by Zhang et al. (2022), is an innovative method that enhances the reasoning capabilities of large language models (LLMs) by automatically generating effective reasoning paths.\n",
    "\n",
    "## How Does Auto-CoT Work?\n",
    "\n",
    "Imagine you're teaching a student to solve complex problems. Instead of manually creating examples of step-by-step reasoning for every possible problem type, you could be more efficient by having the student generate their own reasoning examples first, then use those as templates.\n",
    "\n",
    "Auto-CoT follows this logic in three key steps:\n",
    "\n",
    "1. **Zero-Shot Generation**: The LLM is first prompted to solve a problem using zero-shot chain-of-thought reasoning (thinking step by step without examples).\n",
    "\n",
    "2. **Example Construction**: These zero-shot reasoning paths are collected and used to automatically construct a few-shot prompt with multiple exemplars that include both questions and their reasoning chains.\n",
    "\n",
    "3. **Improved Reasoning**: When faced with a new test question, the model uses the automatically constructed few-shot examples as guidance, leading to more structured and effective reasoning.\n",
    "\n",
    "This approach eliminates the need for human-crafted reasoning examples while still harnessing the performance benefits of few-shot chain-of-thought prompting, making it both efficient and scalable for complex reasoning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_cot_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "    Generate solutions using Automatic Chain-of-Thought (Auto-CoT) Prompting for a given user question.\n",
    "\n",
    "    Auto-CoT uses a Zero-Shot prompt to automatically generate chains of thought. These generated CoTs are then used to build a Few-Shot CoT prompt for the test sample.\n",
    "\n",
    "    Please structure your response in the following format:\n",
    "\n",
    "    Step 1: Generate Zero-Shot CoT\n",
    "    [Use a Zero-Shot prompt to generate a chain of thought for the given question.]\n",
    "\n",
    "    Step 2: Construct Few-Shot CoT Prompt\n",
    "    [Use the generated Zero-Shot CoT to build a Few-Shot CoT prompt with examples.]\n",
    "\n",
    "    Step 3: Solve with Few-Shot CoT\n",
    "    [Solve the original question using the constructed Few-Shot CoT prompt.]\n",
    "\n",
    "    Step 4: Final Solution\n",
    "    [Provide the final solution with a brief explanation.]\n",
    "\n",
    "    Example:\n",
    "    Question: \"A baker has 12 eggs. If he uses 3 eggs for each cake, how many cakes can he make?\"\n",
    "\n",
    "    Step 1: Generate Zero-Shot CoT\n",
    "    Let's think step by step. If we divide the total eggs by the eggs per cake, we get the number of cakes. 12 eggs / 3 eggs/cake = 4 cakes.\n",
    "\n",
    "    Step 2: Construct Few-Shot CoT Prompt\n",
    "    Example 1:\n",
    "    Q: A student has 15 pencils. If they give 5 pencils to each friend, how many friends get pencils?\n",
    "    A: Let's think step by step. 15 pencils / 5 pencils/friend = 3 friends.\n",
    "    Example 2:\n",
    "    Q: A farmer has 20 apples. If they put 4 apples in each basket, how many baskets are needed?\n",
    "    A: Let's think step by step. 20 apples / 4 apples/basket = 5 baskets.\n",
    "    Q: A baker has 12 eggs. If he uses 3 eggs for each cake, how many cakes can he make?\n",
    "    A:\n",
    "\n",
    "    Step 3: Solve with Few-Shot CoT\n",
    "    Let's think step by step. 12 eggs / 3 eggs/cake = 4 cakes.\n",
    "\n",
    "    Step 4: Final Solution\n",
    "    The baker can make 4 cakes.\n",
    "    \"\"\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "    (\"assistant\", \"\"\"\n",
    "    I will use Automatic Chain-of-Thought (Auto-CoT) Prompting to solve this problem.\n",
    "\n",
    "    Step 1: Generate Zero-Shot CoT\n",
    "    [Generate a Zero-Shot CoT for the question.]\n",
    "\n",
    "    Step 2: Construct Few-Shot CoT Prompt\n",
    "    [Build a Few-Shot CoT prompt using the generated Zero-Shot CoT.]\n",
    "\n",
    "    Step 3: Solve with Few-Shot CoT\n",
    "    [Solve the question with the constructed Few-Shot CoT.]\n",
    "\n",
    "    Step 4: Final Solution\n",
    "    [Provide the final solution.]\n",
    "    \"\"\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suitable Questions for Automatic Chain-of-Thought (Auto-CoT)\n",
    "\n",
    "For Automatic Chain-of-Thought (Auto-CoT), the most suitable questions are those that benefit from explicit step-by-step reasoning that can be automatically generated and then used as examples. Here are types of questions that would be particularly well-suited to this approach:\n",
    "\n",
    "### Mathematical Calculations\n",
    "- Arithmetic problems requiring multiple operations\n",
    "- Word problems that can be broken down into discrete steps\n",
    "- Percentage calculations with multiple variables\n",
    "- Rate, time, and distance problems with clear solution paths\n",
    "\n",
    "### Logical Reasoning\n",
    "- Multi-step deduction problems\n",
    "- Syllogisms requiring careful tracking of premises\n",
    "- Sequence completion with identifiable patterns\n",
    "- Conditional reasoning problems (if-then scenarios)\n",
    "\n",
    "### Procedural Analysis\n",
    "- Problems involving defined algorithms or procedures\n",
    "- Step-counting problems with clear rules\n",
    "- Problems requiring systematic elimination of options\n",
    "- Tasks involving transformation according to specific rules\n",
    "\n",
    "### Concrete Examples of Questions\n",
    "1. \"If a train travels at 60 mph for 2 hours, then slows to 40 mph for 1 hour, what is the average speed for the journey?\"\n",
    "   - Auto-CoT would generate reasoning steps for calculating distance and then dividing by total time\n",
    "\n",
    "2. \"In a class of 30 students, 18 study math, 15 study science, and 10 study both. How many students study neither subject?\"\n",
    "   - Auto-CoT would generate set theory reasoning that can serve as a template for similar problems\n",
    "\n",
    "3. \"A shopkeeper buys an item for $80 and marks it up by 25%. During a sale, he offers a 10% discount. What is the final selling price?\"\n",
    "   - Auto-CoT would generate markup and discount calculation steps that can be reused\n",
    "\n",
    "4. \"If 5 workers can build 5 walls in 5 days, how many days would it take 10 workers to build 10 walls?\"\n",
    "   - Auto-CoT would generate proportional reasoning steps that can serve as examples\n",
    "\n",
    "5. \"A code replaces each letter with the letter that is 3 positions later in the alphabet. If 'HELLO' is encoded, what would be the result?\"\n",
    "   - Auto-CoT would generate letter-by-letter transformation steps useful for similar encoding problems\n",
    "\n",
    "Auto-CoT is particularly effective for these types of questions because:\n",
    "- They involve clear, traceable reasoning steps that can be automatically generated\n",
    "- The reasoning patterns are generalizable across similar problems\n",
    "- The solutions benefit from explicit intermediate calculations\n",
    "- The generated examples can effectively demonstrate the problem-solving approach\n",
    "- The step-by-step nature aligns perfectly with how Chain-of-Thought reasoning works\n",
    "\n",
    "This approach is especially powerful when dealing with problems that follow identifiable patterns of reasoning where seeing similar examples with explicit reasoning steps significantly improves performance on new instances of similar problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION:\n",
      "If a train travels at 60 mph for 2 hours, then slows to 40 mph for 1 hour, what is the average speed for the journey?\n",
      "\n",
      "FINAL SOLUTION:\n",
      "Final Solution  \n",
      "The average speed for the journey is approximately 53.33 mph. This is calculated by dividing the total distance of 160 miles by the total time of 3 hours.\n",
      "\n",
      "(Complete results saved in 'auto_cot_result.txt')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from typing import Optional, TypedDict, Annotated\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "\n",
    "# Function to generate the Auto-CoT prompt and extract the final answer\n",
    "def generate_auto_cot_node(state):\n",
    "    question = state['messages'][-1].content  # Get the last question\n",
    "    prompt_value = auto_cot_template.invoke({\"question\": question})\n",
    "    messages = prompt_value.to_messages()\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    # Keep the full response for processing\n",
    "    full_response = response.content\n",
    "    \n",
    "    # Extract the final solution from Step 4\n",
    "    final_answer_pattern = r'Step 4:([\\s\\S]*?)(?=$|Step \\d:)'\n",
    "    final_answer_match = re.search(final_answer_pattern, full_response)\n",
    "    \n",
    "    if final_answer_match:\n",
    "        final_solution = final_answer_match.group(1).strip()\n",
    "    else:\n",
    "        # Alternative pattern\n",
    "        alternative_pattern = r'Step 4: \\[Final Solution\\]([\\s\\S]*?)(?=$|Step \\d:)'\n",
    "        alternative_match = re.search(alternative_pattern, full_response)\n",
    "        \n",
    "        if alternative_match:\n",
    "            final_solution = alternative_match.group(1).strip()\n",
    "        else:\n",
    "            final_solution = \"Final solution not found in the expected format.\"\n",
    "    \n",
    "    # Save both the question, final answer, and full processing to a text file\n",
    "    with open('auto_cot_result.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=== QUESTION ===\\n\\n\")\n",
    "        f.write(question)\n",
    "        f.write(\"\\n\\n=== FINAL SOLUTION (STEP 4) ===\\n\\n\")\n",
    "        f.write(final_solution)\n",
    "        f.write(\"\\n\\n=== COMPLETE PROCESSING (FOR REFERENCE) ===\\n\\n\")\n",
    "        f.write(full_response)\n",
    "    \n",
    "    # Return only the final answer in messages, plus the original question for reference\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=final_solution)],\n",
    "        \"question\": question,\n",
    "        \"full_response\": full_response\n",
    "    }\n",
    "\n",
    "# Definition of state\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    question: Optional[str]\n",
    "    full_response: Optional[str]\n",
    "\n",
    "# Graph creation\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"generate_auto_cot\", generate_auto_cot_node)\n",
    "\n",
    "# Graph configuration\n",
    "graph_builder.set_entry_point(\"generate_auto_cot\")\n",
    "graph_builder.add_edge(\"generate_auto_cot\", END)\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "# Usage example\n",
    "inputs = {\n",
    "    \"messages\": [HumanMessage(content=\"If a train travels at 60 mph for 2 hours, then slows to 40 mph for 1 hour, what is the average speed for the journey?\")],\n",
    "    \"question\": None,\n",
    "    \"full_response\": None\n",
    "}\n",
    "\n",
    "# Print the question at the beginning\n",
    "print(\"QUESTION:\")\n",
    "print(inputs[\"messages\"][0].content)\n",
    "print(\"\\nFINAL SOLUTION:\")\n",
    "\n",
    "# Graph execution - only display final solution\n",
    "original_question = \"\"\n",
    "for output in graph.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        if key == \"generate_auto_cot\":\n",
    "            messages = value['messages']\n",
    "            for message in messages:\n",
    "                if isinstance(message, AIMessage):\n",
    "                    print(message.content)\n",
    "            \n",
    "            # Store question for reference\n",
    "            if \"question\" in value:\n",
    "                original_question = value[\"question\"]\n",
    "\n",
    "# Print confirmation that results were saved\n",
    "print(\"\\n(Complete results saved in 'auto_cot_result.txt')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
