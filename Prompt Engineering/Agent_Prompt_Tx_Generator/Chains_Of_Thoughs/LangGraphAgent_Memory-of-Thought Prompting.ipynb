{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U langgraph langsmith\n",
    "! pip install langchain_community\n",
    "! pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END ,state\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage,AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI  # Notez le changement ici\n",
    "\n",
    "# Définition de la clé API\n",
    "os.environ['OPENAI_API_KEY'] = \"sk-proj-0xUZ6aBpi1 2mjq9C0Iyh8mq8WeoK0yCT3BlbkFJ6nuNH0hRFwAy9HhFfHS_cUMhXQMX6_U0pycw_XiZUUtZ4V6Gc5xEwhMZOsYA6xKN4HruNnPRcA\"\n",
    "\n",
    "# Création du modèle\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",  # Notez que c'est 'model' et non 'model_name' dans les versions récentes\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory-of-Thought Prompting\n",
    "\n",
    "Memory-of-Thought Prompting, introduced by Li and Qiu (2023), is a powerful approach that enhances language models (LLMs) by dynamically retrieving and leveraging similar examples from a pre-built repository.\n",
    "\n",
    "## How Does Memory-of-Thought Prompting Work?\n",
    "\n",
    "Imagine you're a mathematician who keeps a notebook of solved problems. When faced with a new challenge, instead of starting from scratch, you first look through your notebook for similar problems you've already solved.\n",
    "\n",
    "Memory-of-Thought Prompting follows this intuitive strategy in three key steps:\n",
    "\n",
    "1. **Knowledge Repository Creation**: Before deployment, the system builds a collection of unlabeled training examples processed with Chain-of-Thought reasoning, creating a \"memory bank\" of solved problems.\n",
    "\n",
    "2. **Similarity-Based Retrieval**: When presented with a new problem, the system retrieves the most semantically similar examples from its memory bank, identifying those with relevant reasoning patterns.\n",
    "\n",
    "3. **Reasoning Transfer**: The model adapts the reasoning patterns from the retrieved examples to solve the new problem, effectively transferring knowledge across similar problem structures.\n",
    "\n",
    "This technique has demonstrated substantial improvements on benchmarks involving arithmetic reasoning, commonsense reasoning, and factual reasoning tasks by leveraging the power of analogical problem-solving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_of_thought_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "    Generate Memory-of-Thought Prompting examples based on user questions.\n",
    "    \n",
    "    Memory-of-Thought Prompting is a specialized technique within Few-Shot Chain-of-Thought (CoT) prompting that includes the following steps:\n",
    "    1. Creates a repository of unlabeled training exemplars with CoT reasoning\n",
    "    2. Processes these exemplars before test time using CoT inference\n",
    "    3. At test time, retrieves the most similar instances to the test sample\n",
    "    4. Incorporates the retrieved instances as context for solving the test problem\n",
    "    5. Generates a solution leveraging the \"memory\" of similar problems\n",
    "    \n",
    "    This approach enhances LLM performance by dynamically selecting relevant examples from a memory bank of solved problems.\n",
    "    \n",
    "    Please structure your response in the following format:\n",
    "    \n",
    "    Step 1: Memory Bank Creation\n",
    "    [Provide 3-5 unlabeled exemplars with questions and CoT reasoning]\n",
    "    \n",
    "    Step 2: Similarity Analysis\n",
    "    [Identify which exemplars from the memory bank are most similar to the test question]\n",
    "    \n",
    "    Step 3: Context Retrieval\n",
    "    [Extract the relevant reasoning patterns from the similar exemplars]\n",
    "    \n",
    "    Step 4: Memory-Augmented Reasoning\n",
    "    [Apply the retrieved reasoning patterns to the test question]\n",
    "    \n",
    "    Step 5: Final Solution\n",
    "    [Comprehensive answer to the original question using insights from the memory-augmented reasoning]\n",
    "    \n",
    "    Example:\n",
    "    Question: \"If a rectangle has a length of 12 meters and a width of 8 meters, what is the area of the rectangle and its perimeter?\"\n",
    "    \n",
    "    Memory Bank Creation:\n",
    "    Exemplar 1: \n",
    "    Q: What is the area of a square with sides of length 5 cm?\n",
    "    A: To find the area of a square, I need to multiply the length of one side by itself.\n",
    "    Area = side × side = side²\n",
    "    Area = 5 cm × 5 cm = 25 cm²\n",
    "    Therefore, the area of the square is 25 square centimeters.\n",
    "    \n",
    "    Exemplar 2:\n",
    "    Q: Find the perimeter of a rectangle with length 9 inches and width 4 inches.\n",
    "    A: To find the perimeter of a rectangle, I need to add all four sides.\n",
    "    Perimeter = 2 × length + 2 × width\n",
    "    Perimeter = 2 × 9 inches + 2 × 4 inches\n",
    "    Perimeter = 18 inches + 8 inches = 26 inches\n",
    "    Therefore, the perimeter of the rectangle is 26 inches.\n",
    "    \n",
    "    Exemplar 3:\n",
    "    Q: What is the area of a triangle with base 6 meters and height 8 meters?\n",
    "    A: To find the area of a triangle, I use the formula Area = (1/2) × base × height.\n",
    "    Area = (1/2) × 6 meters × 8 meters\n",
    "    Area = (1/2) × 48 square meters\n",
    "    Area = 24 square meters\n",
    "    Therefore, the area of the triangle is 24 square meters.\n",
    "    \n",
    "    Similarity Analysis:\n",
    "    For our question about a rectangle's area and perimeter, Exemplar 1 involves area calculation but for a square, and Exemplar 2 involves perimeter calculation for a rectangle. Both are relevant. Exemplar 3 is less relevant as it deals with a triangle.\n",
    "    \n",
    "    Context Retrieval:\n",
    "    From Exemplar 1: Area calculation requires multiplying length by width for a rectangle.\n",
    "    From Exemplar 2: Perimeter calculation uses the formula 2 × length + 2 × width.\n",
    "    \n",
    "    Memory-Augmented Reasoning:\n",
    "    For our rectangle with length 12 meters and width 8 meters:\n",
    "    \n",
    "    To calculate the area, I'll adapt the reasoning from Exemplar 1:\n",
    "    Area = length × width\n",
    "    Area = 12 meters × 8 meters = 96 square meters\n",
    "    \n",
    "    To calculate the perimeter, I'll use the formula from Exemplar 2:\n",
    "    Perimeter = 2 × length + 2 × width\n",
    "    Perimeter = 2 × 12 meters + 2 × 8 meters\n",
    "    Perimeter = 24 meters + 16 meters = 40 meters\n",
    "    \n",
    "    Final Solution:\n",
    "    For a rectangle with length 12 meters and width 8 meters:\n",
    "    \n",
    "    Area calculation:\n",
    "    Area = length × width\n",
    "    Area = 12 m × 8 m = 96 m²\n",
    "    \n",
    "    Perimeter calculation:\n",
    "    Perimeter = 2 × length + 2 × width\n",
    "    Perimeter = 2 × 12 m + 2 × 8 m\n",
    "    Perimeter = 24 m + 16 m = 40 m\n",
    "    \n",
    "    Therefore, the area of the rectangle is 96 square meters, and its perimeter is 40 meters.\n",
    "    \"\"\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "    (\"assistant\", \"\"\"\n",
    "    I'll solve this problem using Memory-of-Thought Prompting to leverage similar examples:\n",
    "    \n",
    "    Step 1: Memory Bank Creation\n",
    "    [Provide 3-5 relevant exemplars with detailed reasoning paths that relate to the problem domain]\n",
    "    \n",
    "    Step 2: Similarity Analysis\n",
    "    [Identify which exemplars from the memory bank are most conceptually similar to the current problem]\n",
    "    \n",
    "    Step 3: Context Retrieval\n",
    "    [Extract the key reasoning patterns and formulas from the similar exemplars]\n",
    "    \n",
    "    Step 4: Memory-Augmented Reasoning\n",
    "    [Apply the retrieved patterns to the current problem with clear step-by-step reasoning]\n",
    "    \n",
    "    Step 5: Final Solution\n",
    "    [Comprehensive solution that combines the retrieved knowledge with problem-specific reasoning]\n",
    "    \"\"\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "For Memory-of-Thought Prompting, the most suitable questions are those where retrieving and applying reasoning patterns from similar examples can significantly enhance model capabilities. Here are types of questions that would be particularly well-suited to this approach:\n",
    "\n",
    "### Pattern Recognition Problems\n",
    "- Mathematical problems that follow established formulas or methods\n",
    "- Algorithmic challenges with recognizable solution patterns\n",
    "- Tasks requiring application of specific procedures or templates\n",
    "- Questions with identifiable reasoning structures that can be reused\n",
    "\n",
    "### Procedural or Multi-Step Problems\n",
    "- Complex calculations with step-by-step processes\n",
    "- Financial problems using standard formulas\n",
    "- Scientific procedures with defined methodologies\n",
    "- Any problem requiring a sequence of well-defined operations\n",
    "\n",
    "### Domain-Specific Knowledge Application\n",
    "- Physics problems requiring application of specific laws\n",
    "- Chemistry problems involving standard reactions or equations\n",
    "- Computer science problems using established algorithms\n",
    "- Financial calculations using standard accounting principles\n",
    "\n",
    "### Problems with Generalizable Solutions\n",
    "- Questions where past solutions can directly inform new problems\n",
    "- Scenarios where established frameworks can be adapted\n",
    "- Problems that benefit from analogical reasoning from similar cases\n",
    "- Questions requiring transfer learning from one domain to a related one\n",
    "\n",
    "### Concrete Examples of Questions\n",
    "\n",
    "1. \"If a rectangle has a length of 15 meters and a width of 8 meters, what is its area and perimeter?\"\n",
    "   - This question follows a standard pattern that can be easily retrieved from memory\n",
    "\n",
    "2. \"If I invest $10,000 at an annual interest rate of 5% compounded monthly, how much will my investment be worth after 10 years?\"\n",
    "   - Financial calculation that benefits from reusing similar compound interest calculations\n",
    "\n",
    "3. \"What is the probability of drawing at least 2 red cards in 5 draws from a standard deck of 52 cards, without replacement?\"\n",
    "   - Statistical problem that follows established probability calculation patterns\n",
    "\n",
    "4. \"A projectile is launched at an angle of 45 degrees with an initial velocity of 20 m/s. How far will it travel horizontally before hitting the ground?\"\n",
    "   - Physics problem that can reuse kinematics equation patterns from similar problems\n",
    "\n",
    "5. \"Using the quadratic formula, solve for x in the equation 3x² - 5x - 2 = 0.\"\n",
    "   - Algebraic problem where memorized procedure application is beneficial\n",
    "\n",
    "Memory-of-Thought Prompting is particularly effective for these types of questions because:\n",
    "\n",
    "- It builds a \"knowledge bank\" of solved examples that can be retrieved when needed\n",
    "- It leverages similarity between current problems and previously encountered ones\n",
    "- It reduces computational effort by adapting existing solutions rather than solving from scratch\n",
    "- It mimics human expert behavior of recognizing patterns and applying known solutions\n",
    "- It excels at problems with clear, structured approaches that can be reused across similar instances\n",
    "\n",
    "This approach is especially valuable in educational contexts, standardized testing, scientific domains, and any area where recognizing and applying patterns from similar examples leads to more efficient problem-solving. The key advantage is its ability to dynamically retrieve relevant knowledge and reasoning patterns rather than starting from first principles each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from typing import Optional, TypedDict, Annotated\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "\n",
    "# Function to generate the Memory-of-Thought prompt and extract the final answer (Step 5)\n",
    "def generate_memory_of_thought_node(state):\n",
    "    question = state['messages'][-1].content  # Get the last question\n",
    "    prompt_value = memory_of_thought_template.invoke({\"question\": question})\n",
    "    messages = prompt_value.to_messages()\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    # Keep the full response for processing\n",
    "    full_response = response.content\n",
    "    \n",
    "    # Extract the final answer from Step 5\n",
    "    final_answer_pattern = r'Step 5:([\\s\\S]*?)(?=$|Step \\d:)'\n",
    "    final_answer_match = re.search(final_answer_pattern, full_response)\n",
    "    \n",
    "    if final_answer_match:\n",
    "        final_solution = final_answer_match.group(1).strip()\n",
    "    else:\n",
    "        # Alternative pattern\n",
    "        alternative_pattern = r'Step 5: Final Solution([\\s\\S]*?)(?=$|Step \\d:)'\n",
    "        alternative_match = re.search(alternative_pattern, full_response)\n",
    "        \n",
    "        if alternative_match:\n",
    "            final_solution = alternative_match.group(1).strip()\n",
    "        else:\n",
    "            final_solution = \"Final solution not found in the expected format.\"\n",
    "    \n",
    "    # Save both the question, final answer, and full processing to a text file\n",
    "    with open('memory_of_thought_result.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=== QUESTION ===\\n\\n\")\n",
    "        f.write(question)\n",
    "        f.write(\"\\n\\n=== FINAL ANSWER (STEP 5) ===\\n\\n\")\n",
    "        f.write(final_solution)\n",
    "        f.write(\"\\n\\n=== COMPLETE PROCESSING (FOR REFERENCE) ===\\n\\n\")\n",
    "        f.write(full_response)\n",
    "    \n",
    "    # Return only the final answer in messages, plus the original question for reference\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=final_solution)],\n",
    "        \"question\": question,\n",
    "        \"full_response\": full_response,\n",
    "        \"memory_bank\": extract_memory_bank(full_response)  # Extract memory bank for future reference\n",
    "    }\n",
    "\n",
    "# Helper function to extract the memory bank for potential reuse\n",
    "def extract_memory_bank(response):\n",
    "    memory_bank_pattern = r'Step 1: Memory Bank Creation([\\s\\S]*?)Step 2:'\n",
    "    memory_bank_match = re.search(memory_bank_pattern, response)\n",
    "    \n",
    "    if memory_bank_match:\n",
    "        return memory_bank_match.group(1).strip()\n",
    "    else:\n",
    "        return \"Memory bank not found in the expected format.\"\n",
    "\n",
    "# Definition of state with additional field for memory bank\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    question: Optional[str]\n",
    "    full_response: Optional[str]\n",
    "    memory_bank: Optional[str]  # Store memory bank for potential reuse\n",
    "\n",
    "# Graph creation\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"generate_memory_of_thought\", generate_memory_of_thought_node)\n",
    "\n",
    "# Graph configuration\n",
    "graph_builder.set_entry_point(\"generate_memory_of_thought\")\n",
    "graph_builder.add_edge(\"generate_memory_of_thought\", END)\n",
    "graph = graph_builder.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example\n",
    "inputs = {\"messages\": [HumanMessage(content=\"Marie gave half of her apples to Jean. Jean ate three apples,\" \n",
    "                                         \" then gave half of what he had left to Pierre. \" \n",
    "                                         \"Pierre now has 4 apples. How many apples did Marie have at the beginning?\")],\n",
    "          \"result_df\": None,  # Initialize result_df to None\n",
    "          \"memory_bank\": None}  # Initialize memory_bank to None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Solution**  \n",
      "Marie initially had 22 apples.  \n",
      "To summarize:  \n",
      "- Marie gave half (11 apples) to Jean.  \n",
      "- Jean ate 3 apples (leaving him with 8 apples).  \n",
      "- Jean then gave half of his remaining apples (4 apples) to Pierre, who now has 4 apples.  \n",
      "Thus, the calculations confirm that Marie started with 22 apples.\n",
      "\n",
      "(Complete results saved in 'memory_of_thought_result.txt')\n"
     ]
    }
   ],
   "source": [
    "# Graph execution - only display Step 5\n",
    "original_question = \"\"\n",
    "for output in graph.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        if key == \"generate_memory_of_thought\":\n",
    "            messages = value['messages']\n",
    "            for message in messages:\n",
    "                if isinstance(message, AIMessage):\n",
    "                    print(message.content)\n",
    "            \n",
    "            # Store question for reference\n",
    "            if \"question\" in value:\n",
    "                original_question = value[\"question\"]\n",
    "\n",
    "# Print confirmation that results were saved\n",
    "print(\"\\n(Complete results saved in 'memory_of_thought_result.txt')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
