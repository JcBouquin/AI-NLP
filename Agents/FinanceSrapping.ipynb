{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain_community langchain-openai langchain-anthropic scikit-learn bs4 pandas pyarrow matplotlib lxml langgraph \"mcp[cli]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "from langchain_community.document_loaders import RecursiveUrlLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_boursorama_output(raw_text):\n",
    "    \"\"\"\n",
    "    Reformate le texte brut extrait de Boursorama en un format plus lisible\n",
    "    tout en conservant plus d'informations\n",
    "    \"\"\"\n",
    "    # Extraire les informations clés\n",
    "    result = {\n",
    "        \"nom\": \"\",\n",
    "        \"cours\": \"\",\n",
    "        \"devise\": \"\",\n",
    "        \"variation\": \"\",\n",
    "        \"valeur_indicative\": \"\",\n",
    "        \"code_isin\": \"\",\n",
    "        \"symbole\": \"\",\n",
    "        \"marche\": \"\",\n",
    "        \"indicateurs\": {},\n",
    "        \"autres_info\": {}\n",
    "    }\n",
    "    \n",
    "    # Rechercher le nom de l'action\n",
    "    if \"IQVIA\" in raw_text:\n",
    "        result[\"nom\"] = \"IQVIA HOLDINGS\"\n",
    "    if \"CEGEDIM\" in raw_text:\n",
    "        result[\"nom\"] = \"CEGEDIM HOLDINGS\"    \n",
    "    \n",
    "    # Rechercher le cours (chiffre avec décimales)\n",
    "    cours_pattern = re.search(r'HOLDINGS\\s*(\\d+[,.]\\d+)', raw_text)\n",
    "    if cours_pattern:\n",
    "        result[\"cours\"] = cours_pattern.group(1)\n",
    "    \n",
    "    # Rechercher la devise\n",
    "    if \"USD\" in raw_text:\n",
    "        result[\"devise\"] = \"USD\"\n",
    "    \n",
    "    # Rechercher la variation (pourcentage avec signe)\n",
    "    variation_pattern = re.search(r'(-?\\d+[,.]\\d+%)', raw_text)\n",
    "    if variation_pattern:\n",
    "        result[\"variation\"] = variation_pattern.group(1)\n",
    "    \n",
    "    # Rechercher la valeur indicative\n",
    "    val_ind_pattern = re.search(r'valeur indicative\\s*(\\d+[,.]\\d+)', raw_text)\n",
    "    if val_ind_pattern:\n",
    "        result[\"valeur_indicative\"] = val_ind_pattern.group(1)\n",
    "    \n",
    "    # Rechercher le code ISIN\n",
    "    isin_pattern = re.search(r'(US\\d+)', raw_text)\n",
    "    if isin_pattern:\n",
    "        result[\"code_isin\"] = isin_pattern.group(1)\n",
    "    \n",
    "    # Rechercher le symbole boursier\n",
    "    symbole_pattern = re.search(r'IQV[^\\s]*', raw_text)\n",
    "    if symbole_pattern:\n",
    "        result[\"symbole\"] = symbole_pattern.group(0)\n",
    "    \n",
    "    # Rechercher le marché\n",
    "    if \"NYSE\" in raw_text:\n",
    "        result[\"marche\"] = \"NYSE\"\n",
    "    \n",
    "    # Extraire les indicateurs clés\n",
    "    indicateurs = {\n",
    "        \"ouverture\": re.search(r'ouverture\\s*(\\d+[,.]\\d+)', raw_text),\n",
    "        \"clôture veille\": re.search(r'clôture veille\\s*(\\d+[,.]\\d+)', raw_text),\n",
    "        \"plus haut\": re.search(r'\\+ haut\\s*(\\d+[,.]\\d+)', raw_text),\n",
    "        \"plus bas\": re.search(r'\\+ bas\\s*(\\d+[,.]\\d+)', raw_text),\n",
    "        \"volume\": re.search(r'volume\\s*(\\d+\\s*\\d*)', raw_text),\n",
    "        \"capital échangé\": re.search(r'capital échangé\\s*(\\d+[,.]\\d+%)', raw_text),\n",
    "        \"valorisation\": re.search(r'valorisation\\s*(\\d+\\s*\\d*\\s*MUSD)', raw_text),\n",
    "        \"capitalisation\": re.search(r'capi. boursière[^0-9]*(\\d+\\s*\\d*\\s*M)', raw_text)\n",
    "    }\n",
    "    \n",
    "    for key, match in indicateurs.items():\n",
    "        if match:\n",
    "            result[\"indicateurs\"][key] = match.group(1)\n",
    "    \n",
    "    # Formater le résultat avec plus d'informations\n",
    "    formatted_output = f\"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\\n\"\n",
    "    formatted_output += f\"┃ {result['nom']} - COTATION BOURSORAMA             ┃\\n\"\n",
    "    formatted_output += f\"┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\\n\\n\"\n",
    "    \n",
    "    # Informations principales\n",
    "    formatted_output += f\"📈 COURS ACTUEL: {result['cours']} {result['devise']} ({result['variation']})\\n\"\n",
    "    formatted_output += f\"   Valeur indicative: {result['valeur_indicative']} EUR\\n\\n\"\n",
    "    \n",
    "    # Informations de référence\n",
    "    formatted_output += f\"🏛️ RÉFÉRENCES:\\n\"\n",
    "    formatted_output += f\"   • Symbole: {result['symbole']}\\n\"\n",
    "    formatted_output += f\"   • ISIN: {result['code_isin']}\\n\"\n",
    "    formatted_output += f\"   • Marché: {result['marche']} (données temps différé)\\n\\n\"\n",
    "    \n",
    "    # Indicateurs de marché\n",
    "    formatted_output += f\"📊 INDICATEURS DE MARCHÉ:\\n\"\n",
    "    formatted_output += f\"   • Ouverture: {result['indicateurs'].get('ouverture', 'N/A')}\\n\"\n",
    "    formatted_output += f\"   • Clôture veille: {result['indicateurs'].get('clôture veille', 'N/A')}\\n\"\n",
    "    formatted_output += f\"   • Plus haut: {result['indicateurs'].get('plus haut', 'N/A')}\\n\"\n",
    "    formatted_output += f\"   • Plus bas: {result['indicateurs'].get('plus bas', 'N/A')}\\n\\n\"\n",
    "    \n",
    "    # Volumes et capitalisation\n",
    "    formatted_output += f\"📉 VOLUMES ET CAPITALISATION:\\n\"\n",
    "    formatted_output += f\"   • Volume: {result['indicateurs'].get('volume', 'N/A')}\\n\"\n",
    "    formatted_output += f\"   • Capital échangé: {result['indicateurs'].get('capital échangé', 'N/A')}\\n\"\n",
    "    formatted_output += f\"   • Valorisation: {result['indicateurs'].get('valorisation', 'N/A')}\\n\"\n",
    "    formatted_output += f\"   • Capitalisation: {result['indicateurs'].get('capitalisation', 'N/A')}\\n\"\n",
    "    \n",
    "    return formatted_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A partir des données brutes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_boursorama_output(raw_text):\n",
    "    \"\"\"\n",
    "    Reformate le texte brut extrait de Boursorama en un format plus lisible\n",
    "    \"\"\"\n",
    "    # Extraire les informations clés\n",
    "    result = {\n",
    "        \"nom\": \"\",\n",
    "        \"cours\": \"\",\n",
    "        \"devise\": \"\",\n",
    "        \"variation\": \"\",\n",
    "        \"indicateurs\": {}\n",
    "    }\n",
    "    \n",
    "    # Extraire le nom directement depuis stock_name\n",
    "    stock_name_match = re.search(r'stock_name:\\s*Cours([A-Z][A-Za-z0-9\\s&]+)', raw_text)\n",
    "    if stock_name_match:\n",
    "        result[\"nom\"] = stock_name_match.group(1).strip()\n",
    "    \n",
    "    # Rechercher le cours (chiffre avec décimales)\n",
    "    cours_pattern = re.search(r'([0-9]+[,.][0-9]+)EUR', raw_text)\n",
    "    if cours_pattern:\n",
    "        result[\"cours\"] = cours_pattern.group(1)\n",
    "    \n",
    "    # Rechercher la devise\n",
    "    if \"EUR\" in raw_text:\n",
    "        result[\"devise\"] = \"EUR\"\n",
    "    elif \"USD\" in raw_text:\n",
    "        result[\"devise\"] = \"USD\"\n",
    "    \n",
    "    # Rechercher la variation (pourcentage avec signe)\n",
    "    variation_pattern = re.search(r'([+-]?[0-9]+[,.][0-9]+%)', raw_text)\n",
    "    if variation_pattern:\n",
    "        result[\"variation\"] = variation_pattern.group(1)\n",
    "    \n",
    "    # Extraire les indicateurs clés\n",
    "    indicateurs = {\n",
    "        \"ouverture\": re.search(r'ouverture\\s*([0-9]+[,.][0-9]+)', raw_text),\n",
    "        \"clôture veille\": re.search(r'clôture veille\\s*([0-9]+[,.][0-9]+)', raw_text),\n",
    "        \"plus haut\": re.search(r'\\+ haut\\s*([0-9]+[,.][0-9]+)', raw_text),\n",
    "        \"plus bas\": re.search(r'\\+ bas\\s*([0-9]+[,.][0-9]+)', raw_text),\n",
    "        \"volume\": re.search(r'volume\\s*([0-9\\s]+)', raw_text),\n",
    "        \"capital échangé\": re.search(r'capital échangé\\s*([0-9]+[,.][0-9]+%)', raw_text),\n",
    "        \"valorisation\": re.search(r'valorisation\\s*([0-9]+\\s*[A-Z]EUR)', raw_text)\n",
    "    }\n",
    "    \n",
    "    for key, match in indicateurs.items():\n",
    "        if match:\n",
    "            result[\"indicateurs\"][key] = match.group(1)\n",
    "    \n",
    "    # Extraire le code ISIN\n",
    "    isin_match = re.search(r'([A-Z]{2}[0-9]{10})', raw_text)\n",
    "    if isin_match:\n",
    "        result[\"isin\"] = isin_match.group(1)\n",
    "    \n",
    "    # Extraire le symbole\n",
    "    symbol_match = re.search(r'([A-Z]{2,5})[A-Za-z]+ Paris', raw_text)\n",
    "    if symbol_match:\n",
    "        result[\"symbole\"] = symbol_match.group(1)\n",
    "    \n",
    "    # Extraire le marché\n",
    "    if \"Euronext Paris\" in raw_text:\n",
    "        result[\"marche\"] = \"Euronext Paris\"\n",
    "    elif \"NYSE\" in raw_text:\n",
    "        result[\"marche\"] = \"NYSE\"\n",
    "    \n",
    "    # Formater le résultat avec plus d'informations\n",
    "    formatted_output = f\" ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\\n\"\n",
    "    formatted_output += f\"┃ {result['nom']} - COTATION BOURSORAMA          ┃\\n\"\n",
    "    formatted_output += f\"┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\\n\\n\"\n",
    "    \n",
    "    # Informations principales\n",
    "    formatted_output += f\"📈 COURS ACTUEL: {result['cours']} {result['devise']} ({result['variation']})\\n\\n\"\n",
    "    \n",
    "    # Informations de référence\n",
    "    formatted_output += f\"🏛️ RÉFÉRENCES:\\n\"\n",
    "    formatted_output += f\"   • Symbole: {result.get('symbole', 'N/A')}\\n\"\n",
    "    formatted_output += f\"   • ISIN: {result.get('isin', 'N/A')}\\n\"\n",
    "    formatted_output += f\"   • Marché: {result.get('marche', 'N/A')}\\n\\n\"\n",
    "    \n",
    "    # Indicateurs de marché\n",
    "    formatted_output += f\"📊 INDICATEURS DE MARCHÉ:\\n\"\n",
    "    formatted_output += f\"   • Ouverture: {result['indicateurs'].get('ouverture', 'N/A')}\\n\"\n",
    "    formatted_output += f\"   • Clôture veille: {result['indicateurs'].get('clôture veille', 'N/A')}\\n\"\n",
    "    formatted_output += f\"   • Plus haut: {result['indicateurs'].get('plus haut', 'N/A')}\\n\"\n",
    "    formatted_output += f\"   • Plus bas: {result['indicateurs'].get('plus bas', 'N/A')}\\n\\n\"\n",
    "    \n",
    "    # Volumes et capitalisation\n",
    "    formatted_output += f\"📉 VOLUMES ET CAPITALISATION:\\n\"\n",
    "    formatted_output += f\"   • Volume: {result['indicateurs'].get('volume', 'N/A')}\\n\"\n",
    "    formatted_output += f\"   • Capital échangé: {result['indicateurs'].get('capital échangé', 'N/A')}\\n\"\n",
    "    formatted_output += f\"   • Valorisation: {result['indicateurs'].get('valorisation', 'N/A')}\\n\"\n",
    "    \n",
    "    return formatted_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the good "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boursorama_extractor(html):\n",
    "    \"\"\"\n",
    "    Extracteur spécifique pour Boursorama, utilisant les classes et IDs spécifiques\n",
    "    identifiés dans le HTML de Boursorama, avec extraction améliorée des données\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    \n",
    "    extracted_content = {}\n",
    "    \n",
    "    # Essayer d'extraire les données JSON des attributs data-faceplate\n",
    "    faceplate_data = soup.find(attrs={\"data-faceplate\": True})\n",
    "    if faceplate_data:\n",
    "        try:\n",
    "            data_init = faceplate_data.get(\"data-faceplate-is-init\", \"{}\")\n",
    "            if data_init:\n",
    "                import json\n",
    "                stock_data = json.loads(data_init)\n",
    "                \n",
    "                # Extraire les informations clés du JSON\n",
    "                for key in [\"symbol\", \"high\", \"low\", \"previousClose\", \"totalVolume\", \"last\"]:\n",
    "                    if key in stock_data:\n",
    "                        extracted_content[f\"json_{key}\"] = stock_data[key]\n",
    "        except Exception as e:\n",
    "            extracted_content[\"json_error\"] = str(e)\n",
    "    \n",
    "    # Extraire le titre/nom de l'action\n",
    "    title_element = soup.find(\"h1\")\n",
    "    if title_element:\n",
    "        extracted_content[\"stock_name\"] = title_element.get_text(strip=True)\n",
    "    \n",
    "    # Trouver les éléments spécifiques à Boursorama\n",
    "    target_elements = [\n",
    "        {\"tag\": \"main\", \"id\": \"main-content\", \"key\": \"main_content\"},\n",
    "        {\"tag\": \"section\", \"class\": \"l-quotepage\", \"key\": \"quote_data\"},\n",
    "        {\"tag\": \"div\", \"class\": \"c-faceplate\", \"key\": \"faceplate\"},\n",
    "        {\"tag\": \"div\", \"class\": \"l-page__content\", \"key\": \"page_content\"},\n",
    "        {\"tag\": \"section\", \"class\": \"l-header__gigaban\", \"key\": \"header_data\"}\n",
    "    ]\n",
    "    \n",
    "    for element in target_elements:\n",
    "        tag = element[\"tag\"]\n",
    "        key = element[\"key\"]\n",
    "        \n",
    "        if \"id\" in element and element[\"id\"]:\n",
    "            found = soup.find(tag, id=element[\"id\"])\n",
    "        else:\n",
    "            found = soup.find(tag, class_=element[\"class\"])\n",
    "            \n",
    "        if found:\n",
    "            extracted_content[key] = found.get_text(strip=True)\n",
    "    \n",
    "    # Extraire les éléments spécifiques de prix et données financières\n",
    "    price_element = soup.find(class_=lambda c: c and \"c-instrument--last\" in str(c))\n",
    "    if price_element:\n",
    "        extracted_content[\"price\"] = price_element.get_text(strip=True)\n",
    "    \n",
    "    currency_element = soup.find(class_=lambda c: c and \"c-instrument--currency\" in str(c))\n",
    "    if currency_element:\n",
    "        extracted_content[\"currency\"] = currency_element.get_text(strip=True)\n",
    "    \n",
    "    variation_element = soup.find(class_=lambda c: c and \"c-instrument--variation\" in str(c))\n",
    "    if variation_element:\n",
    "        extracted_content[\"variation\"] = variation_element.get_text(strip=True)\n",
    "    \n",
    "    # Extraire les données du tableau d'indicateurs\n",
    "    indicators = {\n",
    "        \"ouverture\": \"ouverture\",\n",
    "        \"clôture veille\": \"clôture veille\",\n",
    "        \"plus haut\": \"+ haut\",\n",
    "        \"plus bas\": \"+ bas\",\n",
    "        \"volume\": \"volume\",\n",
    "        \"capital échangé\": \"capital échangé\",\n",
    "        \"valorisation\": \"valorisation\"\n",
    "    }\n",
    "    \n",
    "    for key, text in indicators.items():\n",
    "        indicator_row = soup.find(string=lambda s: s and text in s)\n",
    "        if indicator_row:\n",
    "            parent = indicator_row.parent\n",
    "            value_element = parent.find_next(\"td\") if parent else None\n",
    "            if value_element:\n",
    "                extracted_content[f\"indicator_{key}\"] = value_element.get_text(strip=True)\n",
    "    \n",
    "    # Extraire les codes ISIN et symboles\n",
    "    isin_match = soup.find(string=lambda s: s and re.search(r'[A-Z]{2}\\d{10}', s))\n",
    "    if isin_match:\n",
    "        isin_code = re.search(r'([A-Z]{2}\\d{10})', isin_match)\n",
    "        if isin_code:\n",
    "            extracted_content[\"isin\"] = isin_code.group(1)\n",
    "    \n",
    "    symbol_element = soup.find(attrs={\"data-ist\": True})\n",
    "    if symbol_element:\n",
    "        extracted_content[\"symbol\"] = symbol_element.get(\"data-ist\")\n",
    "    \n",
    "    # Chercher le marché\n",
    "    market_match = soup.find(string=lambda s: s and any(market in s for market in [\"NYSE\", \"NASDAQ\", \"EURONEXT\"]))\n",
    "    if market_match:\n",
    "        for market in [\"NYSE\", \"NASDAQ\", \"EURONEXT\"]:\n",
    "            if market in market_match:\n",
    "                extracted_content[\"market\"] = market\n",
    "                break\n",
    "    \n",
    "    # Format result\n",
    "    formatted_text = \"\"\n",
    "    for key, value in extracted_content.items():\n",
    "        formatted_text += f\"{key}:\\n{value}\\n\\n\"\n",
    "    \n",
    "    return formatted_text if formatted_text else soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boursorama_extractor(html):\n",
    "    \"\"\"\n",
    "    Extracteur spécifique pour Boursorama, utilisant les classes et IDs spécifiques\n",
    "    identifiés dans le HTML de Boursorama\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    \n",
    "    extracted_content = {}\n",
    "    \n",
    "    # Trouver les éléments spécifiques à Boursorama\n",
    "    target_elements = [\n",
    "        {\"tag\": \"main\", \"id\": \"main-content\", \"key\": \"main_content\"},\n",
    "        {\"tag\": \"section\", \"class\": \"l-quotepage\", \"key\": \"quote_data\"},\n",
    "        {\"tag\": \"div\", \"class\": \"c-faceplate\", \"key\": \"faceplate\"},\n",
    "        {\"tag\": \"div\", \"class\": \"l-page__content\", \"key\": \"page_content\"},\n",
    "        {\"tag\": \"section\", \"class\": \"l-header__gigaban\", \"key\": \"header_data\"}\n",
    "    ]\n",
    "    \n",
    "    for element in target_elements:\n",
    "        tag = element[\"tag\"]\n",
    "        key = element[\"key\"]\n",
    "        \n",
    "        if \"id\" in element and element[\"id\"]:\n",
    "            found = soup.find(tag, id=element[\"id\"])\n",
    "        else:\n",
    "            found = soup.find(tag, class_=element[\"class\"])\n",
    "            \n",
    "        if found:\n",
    "            extracted_content[key] = found.get_text(strip=True)\n",
    "    \n",
    "    # Chercher spécifiquement les données de prix/cotation\n",
    "    price_elements = soup.find_all(class_=lambda c: c and any(x in str(c) for x in \n",
    "                                                            [\"c-instrument\", \"c-quote\", \"c-faceplate\"]))\n",
    "    \n",
    "    for i, el in enumerate(price_elements):\n",
    "        key = f\"financial_data_{i}\"\n",
    "        extracted_content[key] = el.get_text(strip=True)\n",
    "    \n",
    "    # Format result\n",
    "    formatted_text = \"\"\n",
    "    for key, value in extracted_content.items():\n",
    "        formatted_text += f\"{key}:\\n{value}\\n\\n\"\n",
    "    \n",
    "    return formatted_text if formatted_text else soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def financial_site_extractor(html):\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    \n",
    "    # Cherche des conteneurs communs pour les données financières\n",
    "    content_selectors = [\n",
    "        {\"tag\": \"div\", \"class\": [\"c-faceplate\", \"main-content\", \"stock-summary\"]},\n",
    "        {\"tag\": \"main\", \"class\": None},\n",
    "        {\"tag\": \"div\", \"id\": [\"quote-summary\", \"quote-header\", \"quote-content\"]}\n",
    "    ]\n",
    "    \n",
    "    extracted_content = {}\n",
    "    \n",
    "    for selector in content_selectors:\n",
    "        tag = selector.get(\"tag\", \"div\")\n",
    "        # Vérifier si la clé \"class\" existe ET n'est pas None\n",
    "        if \"class\" in selector and selector[\"class\"] is not None:\n",
    "            for class_name in selector[\"class\"]:\n",
    "                content = soup.find(tag, class_=class_name)\n",
    "                if content:\n",
    "                    extracted_content[class_name] = content.get_text(strip=True)\n",
    "        # Vérifier si la clé \"id\" existe ET n'est pas None\n",
    "        elif \"id\" in selector and selector[\"id\"] is not None:\n",
    "            for id_name in selector[\"id\"]:\n",
    "                content = soup.find(tag, id=id_name)\n",
    "                if content:\n",
    "                    extracted_content[id_name] = content.get_text(strip=True)\n",
    "    \n",
    "    # Extrait spécifiquement les informations de prix si elles existent\n",
    "    price_selectors = [\n",
    "        {\"tag\": \"span\", \"class\": [\"c-instrument--last\", \"price\", \"quote-price\"]},\n",
    "        {\"tag\": \"div\", \"class\": [\"stock-price\", \"current-price\"]}\n",
    "    ]\n",
    "    \n",
    "    for selector in price_selectors:\n",
    "        tag = selector.get(\"tag\", \"div\")\n",
    "        if \"class\" in selector and selector[\"class\"] is not None:\n",
    "            for class_name in selector[\"class\"]:\n",
    "                price_element = soup.find(tag, class_=class_name)\n",
    "                if price_element:\n",
    "                    extracted_content[\"price\"] = price_element.get_text(strip=True)\n",
    "                    break\n",
    "    \n",
    "    # Si rien n'a été trouvé, essayer d'extraire quelques éléments génériques\n",
    "    if not extracted_content:\n",
    "        # Chercher le titre principal\n",
    "        title = soup.find(\"h1\")\n",
    "        if title:\n",
    "            extracted_content[\"title\"] = title.get_text(strip=True)\n",
    "        \n",
    "        # Chercher des éléments de classe contenant des mots-clés financiers\n",
    "        financial_classes = [\"price\", \"quote\", \"stock\", \"value\", \"cours\"]\n",
    "        for fc in financial_classes:\n",
    "            elements = soup.find_all(class_=lambda c: c and fc in c.lower())\n",
    "            for i, el in enumerate(elements):\n",
    "                extracted_content[f\"{fc}_{i}\"] = el.get_text(strip=True)\n",
    "    \n",
    "    # Convertir le dictionnaire en texte formaté pour le retour\n",
    "    formatted_text = \"\"\n",
    "    for key, value in extracted_content.items():\n",
    "        formatted_text += f\"{key}: {value}\\n\\n\"\n",
    "    \n",
    "    # Si toujours rien trouvé, retourner le texte brut\n",
    "    return formatted_text if formatted_text else soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contenu brut extrait :\n",
      "stock_name:\n",
      "CoursIQVIA HOLDINGS\n",
      "\n",
      "main_content:\n",
      "CoursActualitésAnalysesDurabilitéConsensusSociétéHistoriqueActionnairesCoursIQVIA HOLDINGS179,050USD-0,53%valeur indicative165,809\n",
      "                                            EURUS46266C1053 IQVNYSE données temps différéPolitique d'exécutionCotation sur les autres placesAutres places de cotationFermerChargement...ouverture179,450clôture veille180,010+ haut180,705+ bas176,740volume252 566capital échangé0,14%valorisation31 569 MUSDcapi. boursièreCapit...\n",
      "\n",
      "Contenu formaté :\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃ IQVIA HOLDINGS - COTATION BOURSORAMA             ┃\n",
      "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n",
      "\n",
      "📈 COURS ACTUEL: 179,050 USD (-0,53%)\n",
      "   Valeur indicative: 165,809 EUR\n",
      "\n",
      "🏛️ RÉFÉRENCES:\n",
      "   • Symbole: IQVIA\n",
      "   • ISIN: US46266\n",
      "   • Marché: NYSE (données temps différé)\n",
      "\n",
      "📊 INDICATEURS DE MARCHÉ:\n",
      "   • Ouverture: 179,450\n",
      "   • Clôture veille: 180,010\n",
      "   • Plus haut: 180,705\n",
      "   • Plus bas: 176,740\n",
      "\n",
      "📉 VOLUMES ET CAPITALISATION:\n",
      "   • Volume: 252 566\n",
      "   • Capital échangé: 0,14%\n",
      "   • Valorisation: 31 569 MUSD\n",
      "   • Capitalisation: 32 187 M\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_any_website(url):\n",
    "    \"\"\"\n",
    "    Charge les données de n'importe quel site web en adaptant l'extracteur\n",
    "    en fonction du domaine.\n",
    "    \n",
    "    Args:\n",
    "        url (str): L'URL de la page à scraper\n",
    "        \n",
    "    Returns:\n",
    "        list: Liste des documents extraits\n",
    "    \"\"\"\n",
    "    domain = urlparse(url).netloc\n",
    "    \n",
    "    # Choisir l'extracteur en fonction du domaine\n",
    "    if \"boursorama.com\" in domain:\n",
    "        # Utilisez l'extracteur spécifique à Boursorama\n",
    "        extractor = boursorama_extractor\n",
    "    elif any(x in domain for x in [\"finance.yahoo.com\", \"investing.com\"]):\n",
    "        extractor = financial_site_extractor\n",
    "    elif \"github.io\" in domain:\n",
    "        # Extracteur pour les sites de documentation\n",
    "        def doc_extractor(html):\n",
    "            soup = BeautifulSoup(html, \"lxml\")\n",
    "            content = soup.find(\"article\", class_=\"md-content__inner\")\n",
    "            return content.get_text() if content else soup.get_text()\n",
    "        extractor = doc_extractor\n",
    "    else:\n",
    "        # Extracteur générique par défaut\n",
    "        extractor = lambda html: BeautifulSoup(html, \"lxml\").get_text()\n",
    "    \n",
    "    try:\n",
    "        # Utiliser l'extracteur choisi\n",
    "        loader = RecursiveUrlLoader(\n",
    "            url,\n",
    "            max_depth=1,\n",
    "            extractor=extractor,\n",
    "        )\n",
    "        \n",
    "        # Charger les documents\n",
    "        docs = loader.load()\n",
    "        return docs\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du chargement du site {url}: {e}\")\n",
    "        # Méthode alternative en cas d'échec avec RecursiveUrlLoader\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            html_content = response.text\n",
    "            extracted_text = extractor(html_content)\n",
    "            \n",
    "            # Créer un document similaire à celui que RecursiveUrlLoader aurait renvoyé\n",
    "            from langchain.schema import Document\n",
    "            doc = Document(page_content=extracted_text, metadata={\"source\": url})\n",
    "            return [doc]\n",
    "        except Exception as e2:\n",
    "            print(f\"Échec complet du scraping: {e2}\")\n",
    "            return []\n",
    "\n",
    "# Exécution directe\n",
    "url_to_scrape = \"https://www.boursorama.com/cours/IQV/\"\n",
    "documents = load_any_website(url_to_scrape)\n",
    "\n",
    "# MODIFICATION - Remplacez cette partie par le code ci-dessous\n",
    "# if documents:\n",
    "#     print(\"\\nAperçu du contenu:\")\n",
    "#     print(documents[0].page_content[:500] + \"...\")\n",
    "# else:\n",
    "#     print(\"Aucun document extrait.\")\n",
    "\n",
    "# Afficher un aperçu du contenu extrait AVEC FORMATAGE\n",
    "if documents:\n",
    "    raw_content = documents[0].page_content\n",
    "    \n",
    "    # Afficher d'abord la version brute (optionnel)\n",
    "    print(\"\\nContenu brut extrait :\")\n",
    "    print(raw_content[:500] + \"...\")\n",
    "    \n",
    "    # Afficher la version formatée\n",
    "    print(\"\\nContenu formaté :\")\n",
    "    formatted_content = format_boursorama_output(raw_content)\n",
    "    print(formatted_content)\n",
    "else:\n",
    "    print(\"Aucun document extrait.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contenu brut extrait :\n",
      "stock_name:\n",
      "CoursCEGEDIM\n",
      "\n",
      "main_content:\n",
      "CoursActualitésAnalysesDurabilitéConsensusSociétéForumHistoriqueActionnairesCoursCEGEDIM13,3500EUR+0,75%indice de référenceCAC Mid & SmallFR0000053506 CGMEuronext Paris données temps réelPolitique d'exécutionCotation sur les autres placesAutres places de cotationFermerChargement...secteurServices informatiquesIndice de référenceCAC Mid & Smallouverture13,2500clôture veille13,2500+ haut13,3500+ bas13,2000volume2 597capital échangé0,02%valorisation188 MEURde...\n",
      "\n",
      "Contenu formaté :\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃ CEGEDIM HOLDINGS - COTATION BOURSORAMA             ┃\n",
      "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n",
      "\n",
      "📈 COURS ACTUEL:   (0,75%)\n",
      "   Valeur indicative:  EUR\n",
      "\n",
      "🏛️ RÉFÉRENCES:\n",
      "   • Symbole: \n",
      "   • ISIN: US3\n",
      "   • Marché:  (données temps différé)\n",
      "\n",
      "📊 INDICATEURS DE MARCHÉ:\n",
      "   • Ouverture: 13,2500\n",
      "   • Clôture veille: 13,2500\n",
      "   • Plus haut: 13,3500\n",
      "   • Plus bas: 13,2000\n",
      "\n",
      "📉 VOLUMES ET CAPITALISATION:\n",
      "   • Volume: 2 597\n",
      "   • Capital échangé: 0,02%\n",
      "   • Valorisation: N/A\n",
      "   • Capitalisation: N/A\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exécution directe\n",
    "url_to_scrape = \"https://www.boursorama.com/cours/1rPCGM/\"\n",
    "documents = load_any_website(url_to_scrape)\n",
    "\n",
    "# MODIFICATION - Remplacez cette partie par le code ci-dessous\n",
    "# if documents:\n",
    "#     print(\"\\nAperçu du contenu:\")\n",
    "#     print(documents[0].page_content[:500] + \"...\")\n",
    "# else:\n",
    "#     print(\"Aucun document extrait.\")\n",
    "\n",
    "# Afficher un aperçu du contenu extrait AVEC FORMATAGE\n",
    "if documents:\n",
    "    raw_content = documents[0].page_content\n",
    "    \n",
    "    # Afficher d'abord la version brute (optionnel)\n",
    "    print(\"\\nContenu brut extrait :\")\n",
    "    print(raw_content[:500] + \"...\")\n",
    "    \n",
    "    # Afficher la version formatée\n",
    "    print(\"\\nContenu formaté :\")\n",
    "    formatted_content = format_boursorama_output(raw_content)\n",
    "    print(formatted_content)\n",
    "else:\n",
    "    print(\"Aucun document extrait.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
