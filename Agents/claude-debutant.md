# Guide LightRAG pour D√©butants

Bienvenue dans ce guide destin√© aux personnes qui d√©couvrent LightRAG et la programmation en intelligence artificielle !

## C'est quoi LightRAG ?

Imagine que tu as une √©norme biblioth√®que de documents. LightRAG, c'est comme avoir un biblioth√©caire super intelligent qui :
- Lit et comprend tous tes documents
- Organise les informations de mani√®re intelligente dans un "graphe de connaissances"
- Peut r√©pondre √† tes questions en utilisant ces informations

C'est ce qu'on appelle un syst√®me **RAG** (Retrieval-Augmented Generation) : il r√©cup√®re les bonnes informations et g√©n√®re des r√©ponses pertinentes.

## De quoi as-tu besoin ?

### 1. Python

Python est un langage de programmation. Pour v√©rifier si tu l'as d√©j√† :

**Sur Windows** :
```bash
python --version
```

Tu devrais voir quelque chose comme `Python 3.10.x` ou plus r√©cent. Si ce n'est pas le cas, t√©l√©charge Python depuis https://www.python.org/downloads/

**Important** : Pendant l'installation de Python, coche la case "Add Python to PATH" !

### 2. Une cl√© API OpenAI

OpenAI, c'est l'entreprise qui a cr√©√© ChatGPT. Pour utiliser LightRAG, tu auras besoin d'une cl√© API :

1. Va sur https://platform.openai.com/
2. Cr√©e un compte ou connecte-toi
3. Va dans "API Keys" et cr√©e une nouvelle cl√©
4. **IMPORTANT** : Copie cette cl√© et garde-la en s√©curit√© (tu ne pourras la voir qu'une seule fois)

Note : Utiliser l'API OpenAI co√ªte de l'argent, mais c'est tr√®s peu cher pour d√©buter (quelques centimes pour des tests). Tu peux aussi utiliser des alternatives gratuites comme Ollama (expliqu√© plus bas).

### 3. Un √©diteur de code

Je te recommande **Visual Studio Code** (gratuit) : https://code.visualstudio.com/

## Installation pas √† pas

### √âtape 1 : Ouvrir un terminal

**Sur Windows** :
- Appuie sur `Windows + R`
- Tape `cmd` et appuie sur Entr√©e

**Sur Mac/Linux** :
- Cherche "Terminal" dans tes applications

### √âtape 2 : Cr√©er un dossier pour ton projet

```bash
# Va dans ton dossier Documents (ou o√π tu veux)
cd Documents

# Cr√©e un nouveau dossier
mkdir mon_projet_lightrag

# Entre dans ce dossier
cd mon_projet_lightrag
```

### √âtape 3 : T√©l√©charger LightRAG

```bash
git clone https://github.com/HKUDS/LightRAG.git
cd LightRAG
```

Si tu n'as pas Git, t√©l√©charge-le depuis https://git-scm.com/downloads

### √âtape 4 : Installer LightRAG

```bash
python -m pip install -e .
```

Cette commande va t√©l√©charger et installer tous les composants n√©cessaires. √áa peut prendre quelques minutes.

### √âtape 5 : V√©rifier que √ßa marche

```bash
python -c "import lightrag; print('√áa marche !')"
```

Si tu vois "√áa marche !", c'est bon !

## Ton premier programme LightRAG

### √âtape 1 : Cr√©er un fichier pour ta cl√© API

Cr√©e un fichier nomm√© `.env` dans le dossier LightRAG (attention au point au d√©but) :

```
OPENAI_API_KEY=sk-ta-cle-api-ici
```

Remplace `sk-ta-cle-api-ici` par ta vraie cl√© API OpenAI.

### √âtape 2 : Cr√©er ton premier script

Cr√©e un fichier `mon_premier_test.py` :

```python
import os
import asyncio
from lightrag import LightRAG, QueryParam
from lightrag.llm.openai import gpt_4o_mini_complete, openai_embed
from lightrag.utils import setup_logger

# Active les messages d'information
setup_logger("lightrag", level="INFO")

# Dossier o√π seront stock√©es les donn√©es
WORKING_DIR = "./mes_donnees"
if not os.path.exists(WORKING_DIR):
    os.mkdir(WORKING_DIR)

async def main():
    print("üöÄ D√©marrage de LightRAG...")

    # Cr√©er le syst√®me LightRAG
    rag = LightRAG(
        working_dir=WORKING_DIR,
        embedding_func=openai_embed,
        llm_model_func=gpt_4o_mini_complete,
    )

    # √âTAPE SUPER IMPORTANTE : Initialiser le syst√®me
    await rag.initialize_storages()
    print("‚úÖ LightRAG est pr√™t !")

    # Ajouter du texte √† la base de connaissances
    print("\nüìö Ajout d'informations...")
    texte = """
    Python est un langage de programmation cr√©√© par Guido van Rossum en 1991.
    Il est tr√®s populaire pour l'intelligence artificielle et l'analyse de donn√©es.
    Python est connu pour sa syntaxe simple et lisible.
    """
    await rag.ainsert(texte)
    print("‚úÖ Informations ajout√©es !")

    # Poser une question
    print("\n‚ùì Je pose une question...")
    question = "Qui a cr√©√© Python ?"
    reponse = await rag.aquery(
        question,
        param=QueryParam(mode="hybrid")
    )

    print(f"\nüí¨ Question : {question}")
    print(f"üìù R√©ponse : {reponse}")

    # Fermer proprement
    await rag.finalize_storages()
    print("\nüëã Termin√© !")

# Lancer le programme
if __name__ == "__main__":
    asyncio.run(main())
```

### √âtape 3 : Lancer ton programme

```bash
python mon_premier_test.py
```

Tu devrais voir des messages s'afficher et obtenir une r√©ponse √† ta question !

## Comprendre le code

D√©composons ce qui se passe :

```python
from lightrag import LightRAG, QueryParam
```
Cette ligne importe (charge) les outils dont on a besoin.

```python
rag = LightRAG(...)
```
On cr√©e notre "assistant intelligent".

```python
await rag.initialize_storages()
```
On pr√©pare l'endroit o√π seront stock√©es les informations. **Ne jamais oublier cette ligne !**

```python
await rag.ainsert(texte)
```
On donne du texte √† lire √† notre assistant. Il va l'analyser et cr√©er un graphe de connaissances.

```python
reponse = await rag.aquery(question, ...)
```
On pose une question et on r√©cup√®re la r√©ponse.

## Les diff√©rents modes de recherche

Quand tu poses une question, tu peux choisir comment chercher la r√©ponse :

```python
param=QueryParam(mode="naive")    # Simple et rapide
param=QueryParam(mode="local")    # Cherche dans le contexte proche
param=QueryParam(mode="global")   # Cherche dans toutes les connaissances
param=QueryParam(mode="hybrid")   # Combine local et global (recommand√© !)
```

## Exemple pratique : Analyser un livre

Cr√©ons un programme qui lit un livre et r√©pond √† des questions dessus :

```python
import os
import asyncio
from lightrag import LightRAG, QueryParam
from lightrag.llm.openai import gpt_4o_mini_complete, openai_embed
from lightrag.utils import setup_logger

setup_logger("lightrag", level="INFO")

WORKING_DIR = "./livres"
if not os.path.exists(WORKING_DIR):
    os.mkdir(WORKING_DIR)

async def analyser_livre():
    # Cr√©er LightRAG
    rag = LightRAG(
        working_dir=WORKING_DIR,
        embedding_func=openai_embed,
        llm_model_func=gpt_4o_mini_complete,
    )
    await rag.initialize_storages()

    # Lire un fichier texte
    print("üìñ Lecture du livre...")
    with open("mon_livre.txt", "r", encoding="utf-8") as f:
        contenu = f.read()

    # Analyser le livre
    print("üß† Analyse en cours...")
    await rag.ainsert(contenu)

    # Poser plusieurs questions
    questions = [
        "Quels sont les personnages principaux ?",
        "Quel est le th√®me principal du livre ?",
        "O√π se d√©roule l'histoire ?"
    ]

    for question in questions:
        print(f"\n‚ùì {question}")
        reponse = await rag.aquery(
            question,
            param=QueryParam(mode="hybrid")
        )
        print(f"üí¨ {reponse}")

    await rag.finalize_storages()

asyncio.run(analyser_livre())
```

Pour utiliser ce programme :
1. Cr√©e un fichier `mon_livre.txt` avec n'importe quel texte
2. Lance `python analyser_livre.py`

## Utiliser Ollama (alternative gratuite √† OpenAI)

Si tu ne veux pas payer pour OpenAI, tu peux utiliser **Ollama** qui fait tourner des mod√®les d'IA sur ton ordinateur (gratuit mais plus lent).

### Installation d'Ollama

1. T√©l√©charge Ollama : https://ollama.ai/
2. Installe-le
3. Ouvre un terminal et tape :

```bash
ollama pull qwen2
ollama pull nomic-embed-text
```

### Code avec Ollama

```python
from lightrag.llm.ollama import ollama_model_complete, ollama_embed
from lightrag.utils import wrap_embedding_func_with_attrs
import numpy as np

@wrap_embedding_func_with_attrs(embedding_dim=768, max_token_size=8192)
async def embedding_func(texts: list[str]) -> np.ndarray:
    return await ollama_embed.func(texts, embed_model="nomic-embed-text")

rag = LightRAG(
    working_dir=WORKING_DIR,
    llm_model_func=ollama_model_complete,
    llm_model_name='qwen2',
    llm_model_kwargs={"options": {"num_ctx": 32768}},
    embedding_func=embedding_func,
)
```

## Erreurs courantes et solutions

### "ModuleNotFoundError: No module named 'lightrag'"

**Probl√®me** : Python ne trouve pas LightRAG.

**Solution** :
```bash
cd LightRAG
python -m pip install -e .
```

### "AuthenticationError: Invalid API key"

**Probl√®me** : Ta cl√© API OpenAI n'est pas valide.

**Solution** :
- V√©rifie que tu as bien copi√© toute la cl√© (elle commence par `sk-`)
- V√©rifie que ton fichier `.env` est dans le bon dossier
- Assure-toi que tu as du cr√©dit sur ton compte OpenAI

### "AttributeError: __aenter__"

**Probl√®me** : Tu as oubli√© d'initialiser les storages.

**Solution** : Ajoute cette ligne apr√®s avoir cr√©√© `rag` :
```python
await rag.initialize_storages()
```

### Le programme est tr√®s lent

**C'est normal !** L'analyse de texte par IA prend du temps. La premi√®re fois est la plus longue car il doit tout analyser. Les fois suivantes, le syst√®me utilise un cache et c'est plus rapide.

## Conseils pour d√©buter

1. **Commence petit** : Teste avec de petits textes (quelques paragraphes) avant d'analyser de gros documents

2. **Sauvegarde ta cl√© API** : Ne la partage jamais et ne la mets pas dans ton code directement, utilise toujours le fichier `.env`

3. **Lis les messages d'erreur** : Ils te disent souvent exactement ce qui ne va pas

4. **Exp√©rimente** : Change les modes de recherche (`naive`, `local`, `global`, `hybrid`) et vois les diff√©rences

5. **Commence avec OpenAI** : C'est plus simple pour d√©buter. Tu pourras essayer Ollama plus tard

6. **Surveille tes co√ªts** : Va sur https://platform.openai.com/usage pour voir combien tu d√©penses

## Projet d'exercice

Essaie de cr√©er un programme qui :
1. Lit plusieurs fichiers texte (tes cours, par exemple)
2. Les analyse avec LightRAG
3. Cr√©e un petit quiz en posant des questions
4. Compare tes r√©ponses avec celles de l'IA

## Ressources pour aller plus loin

- **Documentation officielle** : https://github.com/HKUDS/LightRAG
- **Tutoriel vid√©o** : https://www.youtube.com/watch?v=g21royNJ4fw
- **Discord** : https://discord.gg/yF2MmDJyGJ (pour poser des questions)
- **Cours Python gratuit** : https://www.codecademy.com/learn/learn-python-3

## Glossaire (mots techniques expliqu√©s)

- **API** : Interface de Programmation d'Application. C'est comme une prise √©lectrique pour les programmes.
- **Async/Await** : Mots-cl√©s Python pour les op√©rations asynchrones (qui peuvent prendre du temps).
- **Embedding** : Transformation du texte en nombres que l'ordinateur peut comprendre.
- **LLM** : Large Language Model. Un mod√®le d'IA entra√Æn√© sur √©norm√©ment de texte.
- **Query** : Requ√™te, question qu'on pose au syst√®me.
- **RAG** : Retrieval-Augmented Generation. R√©cup√©ration d'infos + g√©n√©ration de r√©ponse.
- **Storage** : Stockage, endroit o√π sont sauvegard√©es les donn√©es.

## Besoin d'aide ?

Si tu bloques :
1. Relis cette documentation
2. V√©rifie que tu as bien suivi toutes les √©tapes
3. Cherche ton message d'erreur sur Google
4. Demande sur le Discord de LightRAG
5. Regarde les exemples dans le dossier `examples/`

## Un dernier conseil

N'aie pas peur de faire des erreurs ! La programmation, c'est beaucoup d'essais et d'erreurs. M√™me les d√©veloppeurs professionnels passent la majorit√© de leur temps √† d√©bugger (corriger des erreurs).

Bonne chance et amuse-toi bien avec LightRAG ! üöÄ
