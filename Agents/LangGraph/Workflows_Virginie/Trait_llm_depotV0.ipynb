{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf11dd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Classificateur m√©dical avec analyse s√©mantique am√©lior√©e\n",
    "Format simple - sans classes ni d√©pendances externes\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Configuration\n",
    "BASE_DIR = os.path.abspath(r\"C:\\Users\\kosmo\\pycode\\Iqvia_process\")\n",
    "CHEMIN_SOURCE = os.path.join(BASE_DIR, \"ProcessEx\")\n",
    "CHEMIN_DEPOTS = os.path.join(BASE_DIR, \"Depots\")\n",
    "\n",
    "# Initialiser le LLM\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not api_key:\n",
    "    print(\"‚ö†Ô∏è ATTENTION: Cl√© API non trouv√©e dans les variables d'environnement\")\n",
    "    api_key = \"votre_cl√©_api_openai_ici\"  # √Ä remplacer par votre vraie cl√©\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.1,  # L√©g√®re cr√©ativit√© pour nuances s√©mantiques\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "def detection_mots_cles_medicaux(titre: str) -> dict:\n",
    "    \"\"\"D√©tection fallback par mots-cl√©s enrichie\"\"\"\n",
    "    titre_lower = titre.lower()\n",
    "    \n",
    "    # Dictionnaire enrichi avec contextes s√©mantiques\n",
    "    termes_contextes = {\n",
    "        # Pathologies oncologiques\n",
    "        'cancer': ('oncologie', 'clinique'), 'tumeur': ('oncologie', 'clinique'), \n",
    "        'oncologie': ('oncologie', 'clinique'), 'prostate': ('oncologie', 'clinique'),\n",
    "        'sein': ('oncologie', 'clinique'), 'poumon': ('oncologie', 'clinique'),\n",
    "        'm√©tastase': ('oncologie', 'clinique'), 'chimioth√©rapie': ('oncologie', 'traitement'),\n",
    "        \n",
    "        # Pathologies endocriniennes\n",
    "        'diab√®te': ('diabetologie', 'clinique'), 'diabete': ('diabetologie', 'clinique'), \n",
    "        'glyc√©mie': ('diabetologie', 'clinique'), 'insuline': ('diabetologie', 'traitement'),\n",
    "        'hba1c': ('diabetologie', 'diagnostic'),\n",
    "        \n",
    "        # Pathologies cardiovasculaires\n",
    "        'cardiaque': ('cardiologie', 'clinique'), 'coeur': ('cardiologie', 'clinique'), \n",
    "        'c≈ìur': ('cardiologie', 'clinique'), 'hypertension': ('cardiologie', 'clinique'),\n",
    "        'infarctus': ('cardiologie', 'urgence'), 'arythmie': ('cardiologie', 'clinique'),\n",
    "        \n",
    "        # Pathologies neurologiques\n",
    "        'alzheimer': ('neurologie', 'clinique'), 'parkinson': ('neurologie', 'clinique'), \n",
    "        'neurologie': ('neurologie', 'clinique'), '√©pilepsie': ('neurologie', 'clinique'),\n",
    "        'avc': ('neurologie', 'urgence'), 'scl√©rose': ('neurologie', 'clinique'),\n",
    "        \n",
    "        # Pathologies respiratoires\n",
    "        'asthme': ('pneumologie', 'clinique'), 'pneumonie': ('pneumologie', 'urgence'), \n",
    "        'bronchite': ('pneumologie', 'clinique'), 'bpco': ('pneumologie', 'clinique'),\n",
    "        \n",
    "        # Pathologies dermatologiques\n",
    "        'ecz√©ma': ('dermatologie', 'clinique'), 'eczema': ('dermatologie', 'clinique'), \n",
    "        'psoriasis': ('dermatologie', 'clinique'), 'dermatite': ('dermatologie', 'clinique'),\n",
    "        \n",
    "        # Contextes non-pathologiques\n",
    "        'formation': ('formation', 'commercial'), 'training': ('formation', 'commercial'),\n",
    "        'vente': ('commercial', 'business'), 'marketing': ('commercial', 'business'),\n",
    "        '√©tude': ('recherche', 'scientifique'), 'essai': ('recherche', 'scientifique'),\n",
    "        'protocole': ('recherche', 'scientifique'), 'phase': ('recherche', 'scientifique'),\n",
    "        'r√©glementation': ('reglementaire', 'administratif'), 'autorisation': ('reglementaire', 'administratif'),\n",
    "        'surveillance': ('pharmacovigilance', 'securite'), 'observance': ('pharmacovigilance', 'therapeutique')\n",
    "    }\n",
    "    \n",
    "    termes_detectes = []\n",
    "    contextes_detectes = []\n",
    "    \n",
    "    for terme, (domaine, contexte) in termes_contextes.items():\n",
    "        if terme in titre_lower:\n",
    "            termes_detectes.append(terme)\n",
    "            contextes_detectes.append((domaine, contexte))\n",
    "    \n",
    "    if termes_detectes:\n",
    "        # Prendre le premier domaine d√©tect√©\n",
    "        domaine_principal, contexte_principal = contextes_detectes[0]\n",
    "        confiance = \"haute\" if len(termes_detectes) > 1 else \"moyenne\"\n",
    "        \n",
    "        # D√©terminer si c'est m√©dical\n",
    "        domaines_medicaux = ['oncologie', 'diabetologie', 'cardiologie', 'neurologie', 'pneumologie', 'dermatologie']\n",
    "        est_medical = domaine_principal in domaines_medicaux\n",
    "        \n",
    "        return {\n",
    "            \"contient_maladie\": est_medical,\n",
    "            \"maladies_detectees\": termes_detectes,\n",
    "            \"categorie_medicale\": domaine_principal,\n",
    "            \"contexte_principal\": contexte_principal,\n",
    "            \"confiance\": confiance,\n",
    "            \"titre_normalise\": titre,\n",
    "            \"score_semantique\": 0.7 if confiance == \"haute\" else 0.5\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        \"contient_maladie\": False,\n",
    "        \"maladies_detectees\": [],\n",
    "        \"categorie_medicale\": \"aucune\",\n",
    "        \"contexte_principal\": \"autre\",\n",
    "        \"confiance\": \"faible\",\n",
    "        \"titre_normalise\": titre,\n",
    "        \"score_semantique\": 0.2\n",
    "    }\n",
    "\n",
    "def analyser_titre_avec_llm_semantique(titre: str) -> dict:\n",
    "    \"\"\"Analyse s√©mantique avanc√©e avec LLM - prompt enrichi\"\"\"\n",
    "    try:\n",
    "        analysis_prompt_template = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"Tu es un expert en analyse s√©mantique m√©dicale et business pharmaceutique. \n",
    "            Ton r√¥le est de comprendre le CONTEXTE et l'INTENTION derri√®re chaque titre, pas seulement chercher des mots-cl√©s.\n",
    "            \n",
    "            Tu ma√Ætrises ces domaines :\n",
    "            - CLINIQUE : pathologies, diagnostics, traitements, soins patients\n",
    "            - RECHERCHE : √©tudes, essais, protocoles, d√©veloppement\n",
    "            - COMMERCIAL : formation √©quipes, marketing, ventes, business\n",
    "            - R√âGLEMENTAIRE : autorisations, compliance, pharmacovigilance\n",
    "            - FORMATION : training, √©ducation, guidelines\n",
    "            \"\"\"),\n",
    "            (\"human\", \"\"\"\n",
    "Analyse s√©mantique COMPL√àTE du titre : \"{titre}\"\n",
    "\n",
    "Ne te contente pas de chercher des mots-cl√©s ! Analyse le CONTEXTE :\n",
    "\n",
    "EXEMPLES D'ANALYSE S√âMANTIQUE :\n",
    "- \"Formation √©quipe vente oncologie Q1 2025\" ‚Üí CONTEXTE=commercial, DOMAINE=oncologie, TYPE=formation\n",
    "- \"Suivi patients diab√®te h√¥pital\" ‚Üí CONTEXTE=clinique, DOMAINE=diabetologie, TYPE=suivi_medical  \n",
    "- \"Protocole √©tude phase III cancer poumon\" ‚Üí CONTEXTE=recherche, DOMAINE=oncologie, TYPE=essai_clinique\n",
    "- \"Rapport surveillance post-marketing\" ‚Üí CONTEXTE=reglementaire, DOMAINE=pharmacovigilance, TYPE=surveillance\n",
    "- \"Pr√©sentation r√©sultats Q4 r√©gion\" ‚Üí CONTEXTE=commercial, DOMAINE=business, TYPE=reporting\n",
    "\n",
    "MISSION : Identifie le CONTEXTE principal, le DOMAINE concern√©, et la FINALIT√â du document.\n",
    "\n",
    "R√©ponds UNIQUEMENT en JSON valide :\n",
    "{{\n",
    "    \"contexte_principal\": \"clinique/recherche/commercial/reglementaire/formation/autre\",\n",
    "    \"domaine_medical\": \"oncologie/cardiologie/neurologie/diabetologie/pneumologie/dermatologie/pharmacovigilance/business/aucun\",\n",
    "    \"type_document\": \"formation/etude/rapport/suivi/presentation/protocole/guide/autre\",\n",
    "    \"population_cible\": \"patients/professionnels/equipes_vente/chercheurs/regulateurs/mixte\",\n",
    "    \"maladies_detectees\": [\"terme1\", \"terme2\"],\n",
    "    \"contient_maladie\": true/false,\n",
    "    \"confiance\": \"haute/moyenne/faible\",\n",
    "    \"score_semantique\": 0.8,\n",
    "    \"justification\": \"Explication courte du contexte d√©tect√©\",\n",
    "    \"titre_normalise\": \"{titre}\"\n",
    "}}\n",
    "            \"\"\")\n",
    "        ])\n",
    "        \n",
    "        prompt_value = analysis_prompt_template.invoke({\"titre\": titre})\n",
    "        response = llm.invoke(prompt_value.to_messages())\n",
    "        content = response.content.strip()\n",
    "        \n",
    "        # Nettoyer le JSON\n",
    "        if \"```json\" in content:\n",
    "            content = content.split(\"```json\")[1].split(\"```\")[0]\n",
    "        elif \"```\" in content:\n",
    "            content = content.split(\"```\")[1].split(\"```\")[0]\n",
    "        \n",
    "        resultat = json.loads(content.strip())\n",
    "        \n",
    "        # Validation et enrichissement\n",
    "        if \"categorie_medicale\" not in resultat:\n",
    "            resultat[\"categorie_medicale\"] = resultat.get(\"domaine_medical\", \"aucune\")\n",
    "        \n",
    "        # Calculer score s√©mantique si absent\n",
    "        if \"score_semantique\" not in resultat or not isinstance(resultat[\"score_semantique\"], (int, float)):\n",
    "            contexte = resultat.get(\"contexte_principal\", \"autre\")\n",
    "            domaine = resultat.get(\"domaine_medical\", \"aucun\")\n",
    "            \n",
    "            score = 0.3  # Base\n",
    "            if contexte != \"autre\": score += 0.2\n",
    "            if domaine != \"aucun\": score += 0.2\n",
    "            if len(resultat.get(\"maladies_detectees\", [])) > 0: score += 0.2\n",
    "            if resultat.get(\"confiance\") == \"haute\": score += 0.1\n",
    "            \n",
    "            resultat[\"score_semantique\"] = min(0.95, score)\n",
    "        \n",
    "        return resultat\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur LLM s√©mantique pour '{titre[:30]}...': {e}\")\n",
    "        return detection_mots_cles_medicaux(titre)\n",
    "\n",
    "def rechercher_fichiers_filtres():\n",
    "    \"\"\"Phase 1: Recherche et filtre les fichiers par extension, date et taille\"\"\"\n",
    "    print(\"üîç PHASE 1: Recherche et filtrage des fichiers...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    if not os.path.exists(CHEMIN_SOURCE):\n",
    "        print(f\"‚ùå Erreur: {CHEMIN_SOURCE} n'existe pas\")\n",
    "        return []\n",
    "    \n",
    "    # D√©finition des filtres\n",
    "    DATE_LIMITE = datetime.now() - timedelta(days=365)  # Fichiers de moins d'un an\n",
    "    TAILLE_MIN_OCTETS = 1 * 1024         # 1 KB minimum (pour √©viter fichiers vides)\n",
    "    TAILLE_MAX_OCTETS = 50 * 1024 * 1024  # 50 MB maximum\n",
    "    TAILLE_CLASSIFICATION = 3000 * 1024   # 2 MB - Seuil pour classification s√©mantique\n",
    "    \n",
    "    print(f\"üìÖ Filtre date: fichiers modifi√©s apr√®s le {DATE_LIMITE.strftime('%d/%m/%Y')}\")\n",
    "    print(f\"üìè Filtre taille: entre {TAILLE_MIN_OCTETS//1024} KB et {TAILLE_MAX_OCTETS//1024//1024} MB\")\n",
    "    print(f\"üß† Classification s√©mantique: fichiers > {TAILLE_CLASSIFICATION//1024} KB seulement\")\n",
    "    print(f\"üìÅ Fichiers ‚â§ {TAILLE_CLASSIFICATION//1024} KB ‚Üí dossier AUTRES automatiquement\")\n",
    "    print()\n",
    "    \n",
    "    fichiers_trouves = []\n",
    "    dossiers_stats = {}\n",
    "    stats_filtrage = {\n",
    "        'total_examines': 0,\n",
    "        'rejetes_extension': 0,\n",
    "        'rejetes_taille': 0, \n",
    "        'rejetes_date': 0,\n",
    "        'rejetes_acces': 0,\n",
    "        'acceptes': 0\n",
    "    }\n",
    "    \n",
    "    for item in os.listdir(CHEMIN_SOURCE):\n",
    "        item_path = os.path.join(CHEMIN_SOURCE, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            print(f\"üìÇ Analyse du dossier: {item}\")\n",
    "            count_dossier = 0\n",
    "            \n",
    "            for root, dirs, files in os.walk(item_path):\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    stats_filtrage['total_examines'] += 1\n",
    "                    \n",
    "                    # V√©rification de l'extension\n",
    "                    if not file.lower().endswith(('.ppt', '.pptx', '.pdf')):\n",
    "                        stats_filtrage['rejetes_extension'] += 1\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        # R√©cup√©ration des m√©tadonn√©es\n",
    "                        taille = os.path.getsize(file_path)\n",
    "                        date_mod = datetime.fromtimestamp(os.path.getmtime(file_path))\n",
    "                        \n",
    "                        # Filtrage par taille\n",
    "                        if not (TAILLE_MIN_OCTETS <= taille <= TAILLE_MAX_OCTETS):\n",
    "                            stats_filtrage['rejetes_taille'] += 1\n",
    "                            continue\n",
    "                        \n",
    "                        # Filtrage par date  \n",
    "                        if date_mod < DATE_LIMITE:\n",
    "                            stats_filtrage['rejetes_date'] += 1\n",
    "                            continue\n",
    "                        \n",
    "                        # Fichier accept√©\n",
    "                        fichier_info = {\n",
    "                            'chemin': file_path,\n",
    "                            'nom': file,\n",
    "                            'taille': taille,\n",
    "                            'date_modification': date_mod,\n",
    "                            'taille_mb': round(taille / (1024*1024), 2),\n",
    "                            'taille_kb': round(taille / 1024, 1),\n",
    "                            'age_jours': (datetime.now() - date_mod).days,\n",
    "                            'classification_semantique': taille >= TAILLE_CLASSIFICATION  # True si > 2MB\n",
    "                        }\n",
    "                        \n",
    "                        fichiers_trouves.append(fichier_info)\n",
    "                        count_dossier += 1\n",
    "                        stats_filtrage['acceptes'] += 1\n",
    "                        \n",
    "                    except (OSError, PermissionError) as e:\n",
    "                        stats_filtrage['rejetes_acces'] += 1\n",
    "                        print(f\"   ‚ö†Ô∏è Ignor√© (acc√®s refus√©): {os.path.basename(file_path)}\")\n",
    "            \n",
    "            dossiers_stats[item] = count_dossier\n",
    "            print(f\"   ‚úÖ {count_dossier} fichier(s) retenu(s) apr√®s filtrage\")\n",
    "    \n",
    "    # Affichage des statistiques d√©taill√©es\n",
    "    print(f\"\\nüìä STATISTIQUES DE FILTRAGE:\")\n",
    "    print(f\"   ‚Ä¢ Fichiers examin√©s: {stats_filtrage['total_examines']}\")\n",
    "    print(f\"   ‚Ä¢ ‚ùå Rejet√©s - extension: {stats_filtrage['rejetes_extension']}\")\n",
    "    print(f\"   ‚Ä¢ ‚ùå Rejet√©s - taille: {stats_filtrage['rejetes_taille']}\")\n",
    "    print(f\"   ‚Ä¢ ‚ùå Rejet√©s - date: {stats_filtrage['rejetes_date']}\")\n",
    "    print(f\"   ‚Ä¢ ‚ùå Rejet√©s - acc√®s: {stats_filtrage['rejetes_acces']}\")\n",
    "    print(f\"   ‚Ä¢ ‚úÖ RETENUS: {stats_filtrage['acceptes']}\")\n",
    "    \n",
    "    print(f\"\\nüìÅ R√âPARTITION PAR DOSSIER:\")\n",
    "    for dossier, count in dossiers_stats.items():\n",
    "        print(f\"   ‚Ä¢ {dossier}: {count} fichier(s)\")\n",
    "    \n",
    "    return fichiers_trouves\n",
    "\n",
    "def trier_fichiers_par_criteres(fichiers_info):\n",
    "    \"\"\"Trie les fichiers par diff√©rents crit√®res et affiche des statistiques\"\"\"\n",
    "    print(f\"\\nüìà PHASE 1.5: Analyse et tri des fichiers retenus...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    if not fichiers_info:\n",
    "        print(\"‚ùå Aucun fichier √† analyser\")\n",
    "        return fichiers_info\n",
    "    \n",
    "    # Tri par taille (d√©croissant)\n",
    "    fichiers_par_taille = sorted(fichiers_info, key=lambda x: x['taille'], reverse=True)\n",
    "    print(f\"üìè Top 5 fichiers les plus volumineux:\")\n",
    "    for i, f in enumerate(fichiers_par_taille[:5], 1):\n",
    "        print(f\"   {i}. {f['nom'][:50]}... ({f['taille_mb']} MB)\")\n",
    "    \n",
    "    # Tri par date (plus r√©cent d'abord) \n",
    "    fichiers_par_date = sorted(fichiers_info, key=lambda x: x['date_modification'], reverse=True)\n",
    "    print(f\"\\nüìÖ Top 5 fichiers les plus r√©cents:\")\n",
    "    for i, f in enumerate(fichiers_par_date[:5], 1):\n",
    "        date_str = f['date_modification'].strftime('%d/%m/%Y')\n",
    "        print(f\"   {i}. {f['nom'][:50]}... ({date_str}, {f['age_jours']} jours)\")\n",
    "    \n",
    "    # Statistiques de r√©partition\n",
    "    tailles = [f['taille_mb'] for f in fichiers_info]\n",
    "    ages = [f['age_jours'] for f in fichiers_info]\n",
    "    \n",
    "    print(f\"\\nüìä STATISTIQUES DESCRIPTIVES:\")\n",
    "    print(f\"   Taille - Moyenne: {sum(tailles)/len(tailles):.1f} MB, Max: {max(tailles):.1f} MB, Min: {min(tailles):.1f} MB\")\n",
    "    print(f\"   √Çge - Moyenne: {sum(ages)//len(ages)} jours, Max: {max(ages)} jours, Min: {min(ages)} jours\")\n",
    "    \n",
    "    # R√©partition par tranches de taille et √©ligibilit√© classification\n",
    "    tranches_taille = {'< 1MB': 0, '1-2MB': 0, '2-5MB': 0, '5-20MB': 0, '> 20MB': 0}\n",
    "    eligibles_classification = 0\n",
    "    \n",
    "    for f in fichiers_info:\n",
    "        mb = f['taille_mb']\n",
    "        if mb < 1: tranches_taille['< 1MB'] += 1\n",
    "        elif mb < 2: tranches_taille['1-2MB'] += 1  \n",
    "        elif mb < 5: tranches_taille['2-5MB'] += 1\n",
    "        elif mb < 20: tranches_taille['5-20MB'] += 1\n",
    "        else: tranches_taille['> 20MB'] += 1\n",
    "        \n",
    "        if f['classification_semantique']:\n",
    "            eligibles_classification += 1\n",
    "    \n",
    "    print(f\"\\nüìè R√âPARTITION PAR TAILLE:\")\n",
    "    for tranche, count in tranches_taille.items():\n",
    "        pct = (count / len(fichiers_info) * 100) if fichiers_info else 0\n",
    "        print(f\"   ‚Ä¢ {tranche}: {count} fichiers ({pct:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nüß† √âLIGIBILIT√â CLASSIFICATION S√âMANTIQUE:\")\n",
    "    print(f\"   ‚Ä¢ Fichiers > 2MB (analys√©s): {eligibles_classification}\")\n",
    "    print(f\"   ‚Ä¢ Fichiers ‚â§ 2MB (‚Üí AUTRES): {len(fichiers_info) - eligibles_classification}\")\n",
    "    \n",
    "    return fichiers_info\n",
    "\n",
    "def copier_fichiers(fichiers_info):\n",
    "    \"\"\"Phase 2: Copie vers Depots avec informations enrichies\"\"\"\n",
    "    print(f\"\\nüìã PHASE 2: Copie vers {CHEMIN_DEPOTS}...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Cr√©er le dossier Depots\n",
    "    os.makedirs(CHEMIN_DEPOTS, exist_ok=True)\n",
    "    print(f\"‚úÖ Dossier Depots pr√™t\")\n",
    "    \n",
    "    copied = 0\n",
    "    taille_totale = 0\n",
    "    \n",
    "    for fichier_info in fichiers_info:\n",
    "        file_path = fichier_info['chemin']\n",
    "        file_name = fichier_info['nom']\n",
    "        destination = os.path.join(CHEMIN_DEPOTS, file_name)\n",
    "        \n",
    "        try:\n",
    "            shutil.copy(file_path, destination)\n",
    "            copied += 1\n",
    "            taille_totale += fichier_info['taille']\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erreur copie {file_name}: {e}\")\n",
    "    \n",
    "    print(f\"‚úÖ {copied}/{len(fichiers_info)} fichiers copi√©s\")\n",
    "    print(f\"üì¶ Taille totale copi√©e: {taille_totale/(1024*1024):.1f} MB\")\n",
    "    return copied\n",
    "\n",
    "def analyser_et_classer_semantique():\n",
    "    \"\"\"Phase 3: Analyse s√©mantique LLM et classification avanc√©e (> 2MB seulement)\"\"\"\n",
    "    print(f\"\\nüß† PHASE 3: Analyse s√©mantique et classification...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Mode LLM ou fallback\n",
    "    use_llm = api_key != \"votre_cl√©_api_openai_ici\"\n",
    "    print(f\"Mode: {'üî• LLM S√©mantique' if use_llm else 'üîß Mots-cl√©s enrichis'}\")\n",
    "    \n",
    "    fichiers_a_analyser = [f for f in os.listdir(CHEMIN_DEPOTS) \n",
    "                          if f.lower().endswith(('.ppt', '.pptx', '.pdf'))]\n",
    "    \n",
    "    # R√©cup√©rer les infos de taille des fichiers copi√©s\n",
    "    fichiers_avec_taille = []\n",
    "    for file_name in fichiers_a_analyser:\n",
    "        file_path = os.path.join(CHEMIN_DEPOTS, file_name)\n",
    "        try:\n",
    "            taille = os.path.getsize(file_path)\n",
    "            fichiers_avec_taille.append({\n",
    "                'nom': file_name,\n",
    "                'taille': taille,\n",
    "                'taille_mb': round(taille / (1024*1024), 2),\n",
    "                'taille_kb': round(taille / 1024, 1),\n",
    "                'eligible_classification': taille >= (3000 * 1024)  # > 2MB\n",
    "            })\n",
    "        except:\n",
    "            # Si erreur, on consid√®re comme petit fichier\n",
    "            fichiers_avec_taille.append({\n",
    "                'nom': file_name,\n",
    "                'taille': 0,\n",
    "                'taille_mb': 0,\n",
    "                'taille_kb': 0,\n",
    "                'eligible_classification': False\n",
    "            })\n",
    "    \n",
    "    analyses = []\n",
    "    medicaux = 0\n",
    "    contextes_stats = {}\n",
    "    petits_fichiers = 0\n",
    "    \n",
    "    print(f\"üìä R√©partition:\")\n",
    "    eligibles = sum(1 for f in fichiers_avec_taille if f['eligible_classification'])\n",
    "    print(f\"   ‚Ä¢ Fichiers > 2MB (analyse s√©mantique): {eligibles}\")\n",
    "    print(f\"   ‚Ä¢ Fichiers ‚â§ 2MB (‚Üí AUTRES direct): {len(fichiers_avec_taille) - eligibles}\")\n",
    "    print()\n",
    "    \n",
    "    for i, fichier_info in enumerate(fichiers_avec_taille, 1):\n",
    "        file_name = fichier_info['nom']\n",
    "        titre = os.path.splitext(file_name)[0]\n",
    "        taille_str = f\"{fichier_info['taille_kb']} KB\" if fichier_info['taille_mb'] < 1 else f\"{fichier_info['taille_mb']} MB\"\n",
    "        \n",
    "        print(f\"[{i:2d}/{len(fichiers_avec_taille)}] {file_name[:40]}... ({taille_str})\")\n",
    "        \n",
    "        # V√©rifier si √©ligible √† la classification s√©mantique\n",
    "        if not fichier_info['eligible_classification']:\n",
    "            # Fichier ‚â§ 2MB ‚Üí AUTRES directement\n",
    "            analyse_simple = {\n",
    "                'fichier': file_name,\n",
    "                'maladies_detectees': [],\n",
    "                'categorie_medicale': 'aucune',\n",
    "                'contexte_principal': 'autre',\n",
    "                'type_document': 'petit_fichier',\n",
    "                'population_cible': 'aucune',\n",
    "                'confiance': 'automatique',\n",
    "                'contient_maladie': False,\n",
    "                'score_semantique': 0.1,\n",
    "                'justification': f'Fichier petit ({taille_str}) ‚Üí AUTRES automatiquement',\n",
    "                'taille_mb': fichier_info['taille_mb']\n",
    "            }\n",
    "            \n",
    "            analyses.append(analyse_simple)\n",
    "            petits_fichiers += 1\n",
    "            print(f\"     ‚Üí AUTRES/ (taille: {taille_str})\")\n",
    "            \n",
    "        else:\n",
    "            # Fichier > 2MB ‚Üí Analyse s√©mantique compl√®te\n",
    "            if use_llm:\n",
    "                resultat = analyser_titre_avec_llm_semantique(titre)\n",
    "            else:\n",
    "                resultat = detection_mots_cles_medicaux(titre)\n",
    "            \n",
    "            # Enrichir l'analyse\n",
    "            contexte = resultat.get('contexte_principal', 'autre')\n",
    "            contextes_stats[contexte] = contextes_stats.get(contexte, 0) + 1\n",
    "            \n",
    "            analyse_complete = {\n",
    "                'fichier': file_name,\n",
    "                'maladies_detectees': resultat.get('maladies_detectees', []),\n",
    "                'categorie_medicale': resultat.get('categorie_medicale', 'aucune'),\n",
    "                'contexte_principal': contexte,\n",
    "                'type_document': resultat.get('type_document', 'autre'),\n",
    "                'population_cible': resultat.get('population_cible', 'aucune'),\n",
    "                'confiance': resultat.get('confiance', 'faible'),\n",
    "                'contient_maladie': resultat.get('contient_maladie', False),\n",
    "                'score_semantique': resultat.get('score_semantique', 0.3),\n",
    "                'justification': resultat.get('justification', 'Classification s√©mantique'),\n",
    "                'taille_mb': fichier_info['taille_mb']\n",
    "            }\n",
    "            \n",
    "            analyses.append(analyse_complete)\n",
    "            \n",
    "            if resultat.get(\"contient_maladie\", False):\n",
    "                medicaux += 1\n",
    "                score = resultat.get('score_semantique', 0)\n",
    "                maladies = '|'.join(resultat.get('maladies_detectees', []))\n",
    "                print(f\"     ‚Üí {contexte.upper()}_{resultat.get('categorie_medicale', 'autre').upper()}/ ({maladies}) [score: {score:.2f}]\")\n",
    "            else:\n",
    "                score = resultat.get('score_semantique', 0)\n",
    "                print(f\"     ‚Üí {contexte.upper()}/ [score: {score:.2f}]\")\n",
    "        \n",
    "        # Classer le fichier physiquement\n",
    "        ancien_chemin = os.path.join(CHEMIN_DEPOTS, file_name)\n",
    "        \n",
    "        if fichier_info['eligible_classification'] and analyses[-1].get(\"contient_maladie\", False):\n",
    "            # Fichier m√©dical > 2MB\n",
    "            resultat = analyses[-1]\n",
    "            categorie = resultat[\"categorie_medicale\"]\n",
    "            contexte = resultat[\"contexte_principal\"]\n",
    "            dossier_medical = os.path.join(CHEMIN_DEPOTS, f\"{contexte.upper()}_{categorie.upper()}\")\n",
    "            os.makedirs(dossier_medical, exist_ok=True)\n",
    "            nouveau_chemin = os.path.join(dossier_medical, file_name)\n",
    "        elif fichier_info['eligible_classification']:\n",
    "            # Fichier non-m√©dical > 2MB\n",
    "            resultat = analyses[-1]\n",
    "            contexte = resultat[\"contexte_principal\"]\n",
    "            if contexte in ['commercial', 'formation', 'reglementaire']:\n",
    "                dossier_contexte = os.path.join(CHEMIN_DEPOTS, f\"{contexte.upper()}\")\n",
    "            else:\n",
    "                dossier_contexte = os.path.join(CHEMIN_DEPOTS, \"AUTRES\")\n",
    "            os.makedirs(dossier_contexte, exist_ok=True)\n",
    "            nouveau_chemin = os.path.join(dossier_contexte, file_name)\n",
    "        else:\n",
    "            # Fichier ‚â§ 2MB ‚Üí AUTRES\n",
    "            dossier_autres = os.path.join(CHEMIN_DEPOTS, \"AUTRES\")\n",
    "            os.makedirs(dossier_autres, exist_ok=True)\n",
    "            nouveau_chemin = os.path.join(dossier_autres, file_name)\n",
    "        \n",
    "        # D√©placer\n",
    "        try:\n",
    "            shutil.move(ancien_chemin, nouveau_chemin)\n",
    "        except Exception as e:\n",
    "            print(f\"     ‚ùå Erreur d√©placement: {e}\")\n",
    "    \n",
    "    print(f\"\\nüìä R√âSULTATS S√âMANTIQUES:\")\n",
    "    print(f\"   ‚Ä¢ {medicaux}/{len(analyses)} fichiers m√©dicaux class√©s\")\n",
    "    print(f\"   ‚Ä¢ {petits_fichiers} petits fichiers (‚â§ 2MB) ‚Üí AUTRES\")\n",
    "    print(f\"   ‚Ä¢ {eligibles} fichiers analys√©s s√©mantiquement\")\n",
    "    if contextes_stats:\n",
    "        print(f\"   ‚Ä¢ Contextes d√©tect√©s: {list(contextes_stats.keys())}\")\n",
    "        for ctx, count in contextes_stats.items():\n",
    "            print(f\"     - {ctx}: {count} fichiers\")\n",
    "    \n",
    "    return analyses\n",
    "\n",
    "def generer_rapport_semantique(analyses):\n",
    "    \"\"\"Phase 4: G√©n√©ration du rapport avec analyse s√©mantique\"\"\"\n",
    "    print(f\"\\nüìù PHASE 4: G√©n√©ration du rapport s√©mantique...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    fichiers_medicaux = sum(1 for a in analyses if a['contient_maladie'])\n",
    "    categories = {}\n",
    "    contextes = {}\n",
    "    scores_moyens = {}\n",
    "    \n",
    "    for a in analyses:\n",
    "        # Stats par cat√©gorie m√©dicale\n",
    "        if a['contient_maladie']:\n",
    "            cat = a['categorie_medicale']\n",
    "            categories[cat] = categories.get(cat, 0) + 1\n",
    "        \n",
    "        # Stats par contexte\n",
    "        ctx = a['contexte_principal']\n",
    "        contextes[ctx] = contextes.get(ctx, 0) + 1\n",
    "        \n",
    "        # Scores s√©mantiques moyens\n",
    "        if ctx not in scores_moyens:\n",
    "            scores_moyens[ctx] = []\n",
    "        scores_moyens[ctx].append(a.get('score_semantique', 0.3))\n",
    "    \n",
    "    # Calculer moyennes\n",
    "    for ctx in scores_moyens:\n",
    "        scores_moyens[ctx] = sum(scores_moyens[ctx]) / len(scores_moyens[ctx])\n",
    "    \n",
    "    rapport = f\"\"\"# üìä Rapport d'Analyse S√©mantique de Fichiers M√©dicaux\n",
    "\n",
    "**Date d'analyse :** {datetime.now().strftime(\"%d/%m/%Y √† %H:%M:%S\")}  \n",
    "**Dossier analys√© :** `{CHEMIN_DEPOTS}`\n",
    "**M√©thode :** Analyse s√©mantique LLM + Classification contextuelle\n",
    "\n",
    "---\n",
    "\n",
    "## üìà R√©sum√© Statistique\n",
    "\n",
    "| M√©trique | Valeur |\n",
    "|----------|--------|\n",
    "| **Fichiers analys√©s** | {len(analyses)} |\n",
    "| **Fichiers m√©dicaux** | {fichiers_medicaux} |\n",
    "| **Fichiers non-m√©dicaux** | {len(analyses) - fichiers_medicaux} |\n",
    "| **Cat√©gories m√©dicales** | {len(categories)} |\n",
    "| **Contextes d√©tect√©s** | {len(contextes)} |\n",
    "| **Score s√©mantique moyen** | {sum(a.get('score_semantique', 0.3) for a in analyses) / len(analyses):.2f} |\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ R√©partition par Contextes\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    for ctx, count in sorted(contextes.items()):\n",
    "        pct = (count / len(analyses) * 100)\n",
    "        score_ctx = scores_moyens.get(ctx, 0)\n",
    "        rapport += f\"- **{ctx.title()}** : {count} fichier(s) ({pct:.1f}%) - Score: {score_ctx:.2f}\\n\"\n",
    "    \n",
    "    rapport += \"\\n---\\n\\n## üè• Sp√©cialit√©s M√©dicales D√©tect√©es\\n\\n\"\n",
    "    \n",
    "    if categories:\n",
    "        for cat, count in sorted(categories.items()):\n",
    "            pct = (count / fichiers_medicaux * 100) if fichiers_medicaux > 0 else 0\n",
    "            rapport += f\"- **{cat.title()}** : {count} fichier(s) ({pct:.1f}%)\\n\"\n",
    "    else:\n",
    "        rapport += \"Aucune cat√©gorie m√©dicale d√©tect√©e.\\n\"\n",
    "    \n",
    "    rapport += \"\\n---\\n\\n## üìã Analyse D√©taill√©e par Fichier\\n\\n\"\n",
    "    \n",
    "    # Trier par score s√©mantique d√©croissant\n",
    "    analyses_triees = sorted(analyses, key=lambda x: x.get('score_semantique', 0), reverse=True)\n",
    "    \n",
    "    for analyse in analyses_triees:\n",
    "        contexte = analyse['contexte_principal']\n",
    "        categorie = analyse['categorie_medicale']\n",
    "        \n",
    "        if analyse['contient_maladie']:\n",
    "            dossier = f\"{contexte.upper()}_{categorie.upper()}\"\n",
    "        else:\n",
    "            dossier = contexte.upper() if contexte in ['commercial', 'formation', 'reglementaire'] else \"AUTRES\"\n",
    "        \n",
    "        score = analyse.get('score_semantique', 0)\n",
    "        justification = analyse.get('justification', 'N/A')\n",
    "        \n",
    "        rapport += f\"\"\"### üìÑ {analyse['fichier']}\n",
    "- **Contexte :** {contexte}\n",
    "- **Domaine m√©dical :** {categorie}\n",
    "- **Type document :** {analyse.get('type_document', 'N/A')}\n",
    "- **Population cible :** {analyse.get('population_cible', 'N/A')}\n",
    "- **Termes d√©tect√©s :** {', '.join(analyse['maladies_detectees']) if analyse['maladies_detectees'] else 'Aucun'}\n",
    "- **Score s√©mantique :** {score:.2f}/1.0\n",
    "- **Confiance :** {analyse['confiance']}\n",
    "- **Dossier :** `{dossier}/`\n",
    "- **Justification :** {justification}\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    rapport += f\"\"\"---\n",
    "\n",
    "## ‚öôÔ∏è Technologie & M√©thodologie\n",
    "\n",
    "### Analyse S√©mantique\n",
    "- **LLM :** ChatOpenAI GPT-4o-mini (temp√©rature: 0.1)\n",
    "- **Approche :** Compr√©hension contextuelle vs simple recherche de mots-cl√©s\n",
    "- **Scoring :** √âvaluation de coh√©rence s√©mantique (0.0 √† 1.0)\n",
    "- **Fallback :** D√©tection enrichie par mots-cl√©s contextuels\n",
    "\n",
    "### Classification Hi√©rarchique\n",
    "- **Structure :** CONTEXTE_DOMAINE/ pour fichiers m√©dicaux\n",
    "- **Contextes :** {', '.join(sorted(contextes.keys()))}\n",
    "- **Crit√®res :** Finalit√© du document, population cible, type de contenu\n",
    "\n",
    "### M√©triques de Qualit√©\n",
    "- **Confiance moyenne :** {sum(1 for a in analyses if a['confiance'] == 'haute') / len(analyses) * 100:.1f}% haute confiance\n",
    "- **Classifications incertaines :** {sum(1 for a in analyses if a.get('score_semantique', 0) < 0.5)} fichiers (score < 0.5)\n",
    "\n",
    "---\n",
    "\n",
    "*Rapport g√©n√©r√© par analyse s√©mantique LLM - Classification intelligente par contexte et intention üß†*\n",
    "\"\"\"\n",
    "    \n",
    "    # Sauvegarder\n",
    "    chemin_rapport = os.path.join(CHEMIN_DEPOTS, \"RAPPORT_SEMANTIQUE.md\")\n",
    "    with open(chemin_rapport, 'w', encoding='utf-8') as f:\n",
    "        f.write(rapport)\n",
    "    \n",
    "    print(f\"‚úÖ Rapport s√©mantique sauv√©: {chemin_rapport}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Fonction principale - workflow s√©mantique simple\"\"\"\n",
    "    print(\"üöÄ CLASSIFICATEUR M√âDICAL S√âMANTIQUE\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Source: {CHEMIN_SOURCE}\")\n",
    "    print(f\"Destination: {CHEMIN_DEPOTS}\")\n",
    "    print(\"üß† Analyse contextuelle et intentionnelle\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Workflow en 4 √©tapes avec analyse s√©mantique et filtrage\n",
    "    fichiers_info = rechercher_fichiers_filtres()\n",
    "    if not fichiers_info:\n",
    "        print(\"‚ùå Aucun fichier trouv√© apr√®s filtrage - Arr√™t\")\n",
    "        return\n",
    "    \n",
    "    trier_fichiers_par_criteres(fichiers_info)\n",
    "    copier_fichiers(fichiers_info)\n",
    "    analyses = analyser_et_classer_semantique()\n",
    "    generer_rapport_semantique(analyses)\n",
    "    \n",
    "    print(\"\\n\" + \"üéâ\" * 20)\n",
    "    print(\"‚úÖ TERMIN√â - Classification s√©mantique r√©ussie !\")\n",
    "    print(\"üß† Analyse contextuelle vs mots-cl√©s simples\")\n",
    "    print(\"üìä Structure hi√©rarchique par intention\")\n",
    "    print(\"üéâ\" * 20)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
