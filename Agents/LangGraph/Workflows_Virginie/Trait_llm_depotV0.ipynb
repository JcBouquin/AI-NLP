{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf11dd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Classificateur médical avec analyse sémantique améliorée\n",
    "Format simple - sans classes ni dépendances externes\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Configuration\n",
    "BASE_DIR = os.path.abspath(r\"C:\\Users\\kosmo\\pycode\\Iqvia_process\")\n",
    "CHEMIN_SOURCE = os.path.join(BASE_DIR, \"ProcessEx\")\n",
    "CHEMIN_DEPOTS = os.path.join(BASE_DIR, \"Depots\")\n",
    "\n",
    "# Initialiser le LLM\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not api_key:\n",
    "    print(\"⚠️ ATTENTION: Clé API non trouvée dans les variables d'environnement\")\n",
    "    api_key = \"votre_clé_api_openai_ici\"  # À remplacer par votre vraie clé\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.1,  # Légère créativité pour nuances sémantiques\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "def detection_mots_cles_medicaux(titre: str) -> dict:\n",
    "    \"\"\"Détection fallback par mots-clés enrichie\"\"\"\n",
    "    titre_lower = titre.lower()\n",
    "    \n",
    "    # Dictionnaire enrichi avec contextes sémantiques\n",
    "    termes_contextes = {\n",
    "        # Pathologies oncologiques\n",
    "        'cancer': ('oncologie', 'clinique'), 'tumeur': ('oncologie', 'clinique'), \n",
    "        'oncologie': ('oncologie', 'clinique'), 'prostate': ('oncologie', 'clinique'),\n",
    "        'sein': ('oncologie', 'clinique'), 'poumon': ('oncologie', 'clinique'),\n",
    "        'métastase': ('oncologie', 'clinique'), 'chimiothérapie': ('oncologie', 'traitement'),\n",
    "        \n",
    "        # Pathologies endocriniennes\n",
    "        'diabète': ('diabetologie', 'clinique'), 'diabete': ('diabetologie', 'clinique'), \n",
    "        'glycémie': ('diabetologie', 'clinique'), 'insuline': ('diabetologie', 'traitement'),\n",
    "        'hba1c': ('diabetologie', 'diagnostic'),\n",
    "        \n",
    "        # Pathologies cardiovasculaires\n",
    "        'cardiaque': ('cardiologie', 'clinique'), 'coeur': ('cardiologie', 'clinique'), \n",
    "        'cœur': ('cardiologie', 'clinique'), 'hypertension': ('cardiologie', 'clinique'),\n",
    "        'infarctus': ('cardiologie', 'urgence'), 'arythmie': ('cardiologie', 'clinique'),\n",
    "        \n",
    "        # Pathologies neurologiques\n",
    "        'alzheimer': ('neurologie', 'clinique'), 'parkinson': ('neurologie', 'clinique'), \n",
    "        'neurologie': ('neurologie', 'clinique'), 'épilepsie': ('neurologie', 'clinique'),\n",
    "        'avc': ('neurologie', 'urgence'), 'sclérose': ('neurologie', 'clinique'),\n",
    "        \n",
    "        # Pathologies respiratoires\n",
    "        'asthme': ('pneumologie', 'clinique'), 'pneumonie': ('pneumologie', 'urgence'), \n",
    "        'bronchite': ('pneumologie', 'clinique'), 'bpco': ('pneumologie', 'clinique'),\n",
    "        \n",
    "        # Pathologies dermatologiques\n",
    "        'eczéma': ('dermatologie', 'clinique'), 'eczema': ('dermatologie', 'clinique'), \n",
    "        'psoriasis': ('dermatologie', 'clinique'), 'dermatite': ('dermatologie', 'clinique'),\n",
    "        \n",
    "        # Contextes non-pathologiques\n",
    "        'formation': ('formation', 'commercial'), 'training': ('formation', 'commercial'),\n",
    "        'vente': ('commercial', 'business'), 'marketing': ('commercial', 'business'),\n",
    "        'étude': ('recherche', 'scientifique'), 'essai': ('recherche', 'scientifique'),\n",
    "        'protocole': ('recherche', 'scientifique'), 'phase': ('recherche', 'scientifique'),\n",
    "        'réglementation': ('reglementaire', 'administratif'), 'autorisation': ('reglementaire', 'administratif'),\n",
    "        'surveillance': ('pharmacovigilance', 'securite'), 'observance': ('pharmacovigilance', 'therapeutique')\n",
    "    }\n",
    "    \n",
    "    termes_detectes = []\n",
    "    contextes_detectes = []\n",
    "    \n",
    "    for terme, (domaine, contexte) in termes_contextes.items():\n",
    "        if terme in titre_lower:\n",
    "            termes_detectes.append(terme)\n",
    "            contextes_detectes.append((domaine, contexte))\n",
    "    \n",
    "    if termes_detectes:\n",
    "        # Prendre le premier domaine détecté\n",
    "        domaine_principal, contexte_principal = contextes_detectes[0]\n",
    "        confiance = \"haute\" if len(termes_detectes) > 1 else \"moyenne\"\n",
    "        \n",
    "        # Déterminer si c'est médical\n",
    "        domaines_medicaux = ['oncologie', 'diabetologie', 'cardiologie', 'neurologie', 'pneumologie', 'dermatologie']\n",
    "        est_medical = domaine_principal in domaines_medicaux\n",
    "        \n",
    "        return {\n",
    "            \"contient_maladie\": est_medical,\n",
    "            \"maladies_detectees\": termes_detectes,\n",
    "            \"categorie_medicale\": domaine_principal,\n",
    "            \"contexte_principal\": contexte_principal,\n",
    "            \"confiance\": confiance,\n",
    "            \"titre_normalise\": titre,\n",
    "            \"score_semantique\": 0.7 if confiance == \"haute\" else 0.5\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        \"contient_maladie\": False,\n",
    "        \"maladies_detectees\": [],\n",
    "        \"categorie_medicale\": \"aucune\",\n",
    "        \"contexte_principal\": \"autre\",\n",
    "        \"confiance\": \"faible\",\n",
    "        \"titre_normalise\": titre,\n",
    "        \"score_semantique\": 0.2\n",
    "    }\n",
    "\n",
    "def analyser_titre_avec_llm_semantique(titre: str) -> dict:\n",
    "    \"\"\"Analyse sémantique avancée avec LLM - prompt enrichi\"\"\"\n",
    "    try:\n",
    "        analysis_prompt_template = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"Tu es un expert en analyse sémantique médicale et business pharmaceutique. \n",
    "            Ton rôle est de comprendre le CONTEXTE et l'INTENTION derrière chaque titre, pas seulement chercher des mots-clés.\n",
    "            \n",
    "            Tu maîtrises ces domaines :\n",
    "            - CLINIQUE : pathologies, diagnostics, traitements, soins patients\n",
    "            - RECHERCHE : études, essais, protocoles, développement\n",
    "            - COMMERCIAL : formation équipes, marketing, ventes, business\n",
    "            - RÉGLEMENTAIRE : autorisations, compliance, pharmacovigilance\n",
    "            - FORMATION : training, éducation, guidelines\n",
    "            \"\"\"),\n",
    "            (\"human\", \"\"\"\n",
    "Analyse sémantique COMPLÈTE du titre : \"{titre}\"\n",
    "\n",
    "Ne te contente pas de chercher des mots-clés ! Analyse le CONTEXTE :\n",
    "\n",
    "EXEMPLES D'ANALYSE SÉMANTIQUE :\n",
    "- \"Formation équipe vente oncologie Q1 2025\" → CONTEXTE=commercial, DOMAINE=oncologie, TYPE=formation\n",
    "- \"Suivi patients diabète hôpital\" → CONTEXTE=clinique, DOMAINE=diabetologie, TYPE=suivi_medical  \n",
    "- \"Protocole étude phase III cancer poumon\" → CONTEXTE=recherche, DOMAINE=oncologie, TYPE=essai_clinique\n",
    "- \"Rapport surveillance post-marketing\" → CONTEXTE=reglementaire, DOMAINE=pharmacovigilance, TYPE=surveillance\n",
    "- \"Présentation résultats Q4 région\" → CONTEXTE=commercial, DOMAINE=business, TYPE=reporting\n",
    "\n",
    "MISSION : Identifie le CONTEXTE principal, le DOMAINE concerné, et la FINALITÉ du document.\n",
    "\n",
    "Réponds UNIQUEMENT en JSON valide :\n",
    "{{\n",
    "    \"contexte_principal\": \"clinique/recherche/commercial/reglementaire/formation/autre\",\n",
    "    \"domaine_medical\": \"oncologie/cardiologie/neurologie/diabetologie/pneumologie/dermatologie/pharmacovigilance/business/aucun\",\n",
    "    \"type_document\": \"formation/etude/rapport/suivi/presentation/protocole/guide/autre\",\n",
    "    \"population_cible\": \"patients/professionnels/equipes_vente/chercheurs/regulateurs/mixte\",\n",
    "    \"maladies_detectees\": [\"terme1\", \"terme2\"],\n",
    "    \"contient_maladie\": true/false,\n",
    "    \"confiance\": \"haute/moyenne/faible\",\n",
    "    \"score_semantique\": 0.8,\n",
    "    \"justification\": \"Explication courte du contexte détecté\",\n",
    "    \"titre_normalise\": \"{titre}\"\n",
    "}}\n",
    "            \"\"\")\n",
    "        ])\n",
    "        \n",
    "        prompt_value = analysis_prompt_template.invoke({\"titre\": titre})\n",
    "        response = llm.invoke(prompt_value.to_messages())\n",
    "        content = response.content.strip()\n",
    "        \n",
    "        # Nettoyer le JSON\n",
    "        if \"```json\" in content:\n",
    "            content = content.split(\"```json\")[1].split(\"```\")[0]\n",
    "        elif \"```\" in content:\n",
    "            content = content.split(\"```\")[1].split(\"```\")[0]\n",
    "        \n",
    "        resultat = json.loads(content.strip())\n",
    "        \n",
    "        # Validation et enrichissement\n",
    "        if \"categorie_medicale\" not in resultat:\n",
    "            resultat[\"categorie_medicale\"] = resultat.get(\"domaine_medical\", \"aucune\")\n",
    "        \n",
    "        # Calculer score sémantique si absent\n",
    "        if \"score_semantique\" not in resultat or not isinstance(resultat[\"score_semantique\"], (int, float)):\n",
    "            contexte = resultat.get(\"contexte_principal\", \"autre\")\n",
    "            domaine = resultat.get(\"domaine_medical\", \"aucun\")\n",
    "            \n",
    "            score = 0.3  # Base\n",
    "            if contexte != \"autre\": score += 0.2\n",
    "            if domaine != \"aucun\": score += 0.2\n",
    "            if len(resultat.get(\"maladies_detectees\", [])) > 0: score += 0.2\n",
    "            if resultat.get(\"confiance\") == \"haute\": score += 0.1\n",
    "            \n",
    "            resultat[\"score_semantique\"] = min(0.95, score)\n",
    "        \n",
    "        return resultat\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur LLM sémantique pour '{titre[:30]}...': {e}\")\n",
    "        return detection_mots_cles_medicaux(titre)\n",
    "\n",
    "def rechercher_fichiers_filtres():\n",
    "    \"\"\"Phase 1: Recherche et filtre les fichiers par extension, date et taille\"\"\"\n",
    "    print(\"🔍 PHASE 1: Recherche et filtrage des fichiers...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    if not os.path.exists(CHEMIN_SOURCE):\n",
    "        print(f\"❌ Erreur: {CHEMIN_SOURCE} n'existe pas\")\n",
    "        return []\n",
    "    \n",
    "    # Définition des filtres\n",
    "    DATE_LIMITE = datetime.now() - timedelta(days=365)  # Fichiers de moins d'un an\n",
    "    TAILLE_MIN_OCTETS = 1 * 1024         # 1 KB minimum (pour éviter fichiers vides)\n",
    "    TAILLE_MAX_OCTETS = 50 * 1024 * 1024  # 50 MB maximum\n",
    "    TAILLE_CLASSIFICATION = 3000 * 1024   # 2 MB - Seuil pour classification sémantique\n",
    "    \n",
    "    print(f\"📅 Filtre date: fichiers modifiés après le {DATE_LIMITE.strftime('%d/%m/%Y')}\")\n",
    "    print(f\"📏 Filtre taille: entre {TAILLE_MIN_OCTETS//1024} KB et {TAILLE_MAX_OCTETS//1024//1024} MB\")\n",
    "    print(f\"🧠 Classification sémantique: fichiers > {TAILLE_CLASSIFICATION//1024} KB seulement\")\n",
    "    print(f\"📁 Fichiers ≤ {TAILLE_CLASSIFICATION//1024} KB → dossier AUTRES automatiquement\")\n",
    "    print()\n",
    "    \n",
    "    fichiers_trouves = []\n",
    "    dossiers_stats = {}\n",
    "    stats_filtrage = {\n",
    "        'total_examines': 0,\n",
    "        'rejetes_extension': 0,\n",
    "        'rejetes_taille': 0, \n",
    "        'rejetes_date': 0,\n",
    "        'rejetes_acces': 0,\n",
    "        'acceptes': 0\n",
    "    }\n",
    "    \n",
    "    for item in os.listdir(CHEMIN_SOURCE):\n",
    "        item_path = os.path.join(CHEMIN_SOURCE, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            print(f\"📂 Analyse du dossier: {item}\")\n",
    "            count_dossier = 0\n",
    "            \n",
    "            for root, dirs, files in os.walk(item_path):\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    stats_filtrage['total_examines'] += 1\n",
    "                    \n",
    "                    # Vérification de l'extension\n",
    "                    if not file.lower().endswith(('.ppt', '.pptx', '.pdf')):\n",
    "                        stats_filtrage['rejetes_extension'] += 1\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        # Récupération des métadonnées\n",
    "                        taille = os.path.getsize(file_path)\n",
    "                        date_mod = datetime.fromtimestamp(os.path.getmtime(file_path))\n",
    "                        \n",
    "                        # Filtrage par taille\n",
    "                        if not (TAILLE_MIN_OCTETS <= taille <= TAILLE_MAX_OCTETS):\n",
    "                            stats_filtrage['rejetes_taille'] += 1\n",
    "                            continue\n",
    "                        \n",
    "                        # Filtrage par date  \n",
    "                        if date_mod < DATE_LIMITE:\n",
    "                            stats_filtrage['rejetes_date'] += 1\n",
    "                            continue\n",
    "                        \n",
    "                        # Fichier accepté\n",
    "                        fichier_info = {\n",
    "                            'chemin': file_path,\n",
    "                            'nom': file,\n",
    "                            'taille': taille,\n",
    "                            'date_modification': date_mod,\n",
    "                            'taille_mb': round(taille / (1024*1024), 2),\n",
    "                            'taille_kb': round(taille / 1024, 1),\n",
    "                            'age_jours': (datetime.now() - date_mod).days,\n",
    "                            'classification_semantique': taille >= TAILLE_CLASSIFICATION  # True si > 2MB\n",
    "                        }\n",
    "                        \n",
    "                        fichiers_trouves.append(fichier_info)\n",
    "                        count_dossier += 1\n",
    "                        stats_filtrage['acceptes'] += 1\n",
    "                        \n",
    "                    except (OSError, PermissionError) as e:\n",
    "                        stats_filtrage['rejetes_acces'] += 1\n",
    "                        print(f\"   ⚠️ Ignoré (accès refusé): {os.path.basename(file_path)}\")\n",
    "            \n",
    "            dossiers_stats[item] = count_dossier\n",
    "            print(f\"   ✅ {count_dossier} fichier(s) retenu(s) après filtrage\")\n",
    "    \n",
    "    # Affichage des statistiques détaillées\n",
    "    print(f\"\\n📊 STATISTIQUES DE FILTRAGE:\")\n",
    "    print(f\"   • Fichiers examinés: {stats_filtrage['total_examines']}\")\n",
    "    print(f\"   • ❌ Rejetés - extension: {stats_filtrage['rejetes_extension']}\")\n",
    "    print(f\"   • ❌ Rejetés - taille: {stats_filtrage['rejetes_taille']}\")\n",
    "    print(f\"   • ❌ Rejetés - date: {stats_filtrage['rejetes_date']}\")\n",
    "    print(f\"   • ❌ Rejetés - accès: {stats_filtrage['rejetes_acces']}\")\n",
    "    print(f\"   • ✅ RETENUS: {stats_filtrage['acceptes']}\")\n",
    "    \n",
    "    print(f\"\\n📁 RÉPARTITION PAR DOSSIER:\")\n",
    "    for dossier, count in dossiers_stats.items():\n",
    "        print(f\"   • {dossier}: {count} fichier(s)\")\n",
    "    \n",
    "    return fichiers_trouves\n",
    "\n",
    "def trier_fichiers_par_criteres(fichiers_info):\n",
    "    \"\"\"Trie les fichiers par différents critères et affiche des statistiques\"\"\"\n",
    "    print(f\"\\n📈 PHASE 1.5: Analyse et tri des fichiers retenus...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    if not fichiers_info:\n",
    "        print(\"❌ Aucun fichier à analyser\")\n",
    "        return fichiers_info\n",
    "    \n",
    "    # Tri par taille (décroissant)\n",
    "    fichiers_par_taille = sorted(fichiers_info, key=lambda x: x['taille'], reverse=True)\n",
    "    print(f\"📏 Top 5 fichiers les plus volumineux:\")\n",
    "    for i, f in enumerate(fichiers_par_taille[:5], 1):\n",
    "        print(f\"   {i}. {f['nom'][:50]}... ({f['taille_mb']} MB)\")\n",
    "    \n",
    "    # Tri par date (plus récent d'abord) \n",
    "    fichiers_par_date = sorted(fichiers_info, key=lambda x: x['date_modification'], reverse=True)\n",
    "    print(f\"\\n📅 Top 5 fichiers les plus récents:\")\n",
    "    for i, f in enumerate(fichiers_par_date[:5], 1):\n",
    "        date_str = f['date_modification'].strftime('%d/%m/%Y')\n",
    "        print(f\"   {i}. {f['nom'][:50]}... ({date_str}, {f['age_jours']} jours)\")\n",
    "    \n",
    "    # Statistiques de répartition\n",
    "    tailles = [f['taille_mb'] for f in fichiers_info]\n",
    "    ages = [f['age_jours'] for f in fichiers_info]\n",
    "    \n",
    "    print(f\"\\n📊 STATISTIQUES DESCRIPTIVES:\")\n",
    "    print(f\"   Taille - Moyenne: {sum(tailles)/len(tailles):.1f} MB, Max: {max(tailles):.1f} MB, Min: {min(tailles):.1f} MB\")\n",
    "    print(f\"   Âge - Moyenne: {sum(ages)//len(ages)} jours, Max: {max(ages)} jours, Min: {min(ages)} jours\")\n",
    "    \n",
    "    # Répartition par tranches de taille et éligibilité classification\n",
    "    tranches_taille = {'< 1MB': 0, '1-2MB': 0, '2-5MB': 0, '5-20MB': 0, '> 20MB': 0}\n",
    "    eligibles_classification = 0\n",
    "    \n",
    "    for f in fichiers_info:\n",
    "        mb = f['taille_mb']\n",
    "        if mb < 1: tranches_taille['< 1MB'] += 1\n",
    "        elif mb < 2: tranches_taille['1-2MB'] += 1  \n",
    "        elif mb < 5: tranches_taille['2-5MB'] += 1\n",
    "        elif mb < 20: tranches_taille['5-20MB'] += 1\n",
    "        else: tranches_taille['> 20MB'] += 1\n",
    "        \n",
    "        if f['classification_semantique']:\n",
    "            eligibles_classification += 1\n",
    "    \n",
    "    print(f\"\\n📏 RÉPARTITION PAR TAILLE:\")\n",
    "    for tranche, count in tranches_taille.items():\n",
    "        pct = (count / len(fichiers_info) * 100) if fichiers_info else 0\n",
    "        print(f\"   • {tranche}: {count} fichiers ({pct:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n🧠 ÉLIGIBILITÉ CLASSIFICATION SÉMANTIQUE:\")\n",
    "    print(f\"   • Fichiers > 2MB (analysés): {eligibles_classification}\")\n",
    "    print(f\"   • Fichiers ≤ 2MB (→ AUTRES): {len(fichiers_info) - eligibles_classification}\")\n",
    "    \n",
    "    return fichiers_info\n",
    "\n",
    "def copier_fichiers(fichiers_info):\n",
    "    \"\"\"Phase 2: Copie vers Depots avec informations enrichies\"\"\"\n",
    "    print(f\"\\n📋 PHASE 2: Copie vers {CHEMIN_DEPOTS}...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Créer le dossier Depots\n",
    "    os.makedirs(CHEMIN_DEPOTS, exist_ok=True)\n",
    "    print(f\"✅ Dossier Depots prêt\")\n",
    "    \n",
    "    copied = 0\n",
    "    taille_totale = 0\n",
    "    \n",
    "    for fichier_info in fichiers_info:\n",
    "        file_path = fichier_info['chemin']\n",
    "        file_name = fichier_info['nom']\n",
    "        destination = os.path.join(CHEMIN_DEPOTS, file_name)\n",
    "        \n",
    "        try:\n",
    "            shutil.copy(file_path, destination)\n",
    "            copied += 1\n",
    "            taille_totale += fichier_info['taille']\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erreur copie {file_name}: {e}\")\n",
    "    \n",
    "    print(f\"✅ {copied}/{len(fichiers_info)} fichiers copiés\")\n",
    "    print(f\"📦 Taille totale copiée: {taille_totale/(1024*1024):.1f} MB\")\n",
    "    return copied\n",
    "\n",
    "def analyser_et_classer_semantique():\n",
    "    \"\"\"Phase 3: Analyse sémantique LLM et classification avancée (> 2MB seulement)\"\"\"\n",
    "    print(f\"\\n🧠 PHASE 3: Analyse sémantique et classification...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Mode LLM ou fallback\n",
    "    use_llm = api_key != \"votre_clé_api_openai_ici\"\n",
    "    print(f\"Mode: {'🔥 LLM Sémantique' if use_llm else '🔧 Mots-clés enrichis'}\")\n",
    "    \n",
    "    fichiers_a_analyser = [f for f in os.listdir(CHEMIN_DEPOTS) \n",
    "                          if f.lower().endswith(('.ppt', '.pptx', '.pdf'))]\n",
    "    \n",
    "    # Récupérer les infos de taille des fichiers copiés\n",
    "    fichiers_avec_taille = []\n",
    "    for file_name in fichiers_a_analyser:\n",
    "        file_path = os.path.join(CHEMIN_DEPOTS, file_name)\n",
    "        try:\n",
    "            taille = os.path.getsize(file_path)\n",
    "            fichiers_avec_taille.append({\n",
    "                'nom': file_name,\n",
    "                'taille': taille,\n",
    "                'taille_mb': round(taille / (1024*1024), 2),\n",
    "                'taille_kb': round(taille / 1024, 1),\n",
    "                'eligible_classification': taille >= (3000 * 1024)  # > 2MB\n",
    "            })\n",
    "        except:\n",
    "            # Si erreur, on considère comme petit fichier\n",
    "            fichiers_avec_taille.append({\n",
    "                'nom': file_name,\n",
    "                'taille': 0,\n",
    "                'taille_mb': 0,\n",
    "                'taille_kb': 0,\n",
    "                'eligible_classification': False\n",
    "            })\n",
    "    \n",
    "    analyses = []\n",
    "    medicaux = 0\n",
    "    contextes_stats = {}\n",
    "    petits_fichiers = 0\n",
    "    \n",
    "    print(f\"📊 Répartition:\")\n",
    "    eligibles = sum(1 for f in fichiers_avec_taille if f['eligible_classification'])\n",
    "    print(f\"   • Fichiers > 2MB (analyse sémantique): {eligibles}\")\n",
    "    print(f\"   • Fichiers ≤ 2MB (→ AUTRES direct): {len(fichiers_avec_taille) - eligibles}\")\n",
    "    print()\n",
    "    \n",
    "    for i, fichier_info in enumerate(fichiers_avec_taille, 1):\n",
    "        file_name = fichier_info['nom']\n",
    "        titre = os.path.splitext(file_name)[0]\n",
    "        taille_str = f\"{fichier_info['taille_kb']} KB\" if fichier_info['taille_mb'] < 1 else f\"{fichier_info['taille_mb']} MB\"\n",
    "        \n",
    "        print(f\"[{i:2d}/{len(fichiers_avec_taille)}] {file_name[:40]}... ({taille_str})\")\n",
    "        \n",
    "        # Vérifier si éligible à la classification sémantique\n",
    "        if not fichier_info['eligible_classification']:\n",
    "            # Fichier ≤ 2MB → AUTRES directement\n",
    "            analyse_simple = {\n",
    "                'fichier': file_name,\n",
    "                'maladies_detectees': [],\n",
    "                'categorie_medicale': 'aucune',\n",
    "                'contexte_principal': 'autre',\n",
    "                'type_document': 'petit_fichier',\n",
    "                'population_cible': 'aucune',\n",
    "                'confiance': 'automatique',\n",
    "                'contient_maladie': False,\n",
    "                'score_semantique': 0.1,\n",
    "                'justification': f'Fichier petit ({taille_str}) → AUTRES automatiquement',\n",
    "                'taille_mb': fichier_info['taille_mb']\n",
    "            }\n",
    "            \n",
    "            analyses.append(analyse_simple)\n",
    "            petits_fichiers += 1\n",
    "            print(f\"     → AUTRES/ (taille: {taille_str})\")\n",
    "            \n",
    "        else:\n",
    "            # Fichier > 2MB → Analyse sémantique complète\n",
    "            if use_llm:\n",
    "                resultat = analyser_titre_avec_llm_semantique(titre)\n",
    "            else:\n",
    "                resultat = detection_mots_cles_medicaux(titre)\n",
    "            \n",
    "            # Enrichir l'analyse\n",
    "            contexte = resultat.get('contexte_principal', 'autre')\n",
    "            contextes_stats[contexte] = contextes_stats.get(contexte, 0) + 1\n",
    "            \n",
    "            analyse_complete = {\n",
    "                'fichier': file_name,\n",
    "                'maladies_detectees': resultat.get('maladies_detectees', []),\n",
    "                'categorie_medicale': resultat.get('categorie_medicale', 'aucune'),\n",
    "                'contexte_principal': contexte,\n",
    "                'type_document': resultat.get('type_document', 'autre'),\n",
    "                'population_cible': resultat.get('population_cible', 'aucune'),\n",
    "                'confiance': resultat.get('confiance', 'faible'),\n",
    "                'contient_maladie': resultat.get('contient_maladie', False),\n",
    "                'score_semantique': resultat.get('score_semantique', 0.3),\n",
    "                'justification': resultat.get('justification', 'Classification sémantique'),\n",
    "                'taille_mb': fichier_info['taille_mb']\n",
    "            }\n",
    "            \n",
    "            analyses.append(analyse_complete)\n",
    "            \n",
    "            if resultat.get(\"contient_maladie\", False):\n",
    "                medicaux += 1\n",
    "                score = resultat.get('score_semantique', 0)\n",
    "                maladies = '|'.join(resultat.get('maladies_detectees', []))\n",
    "                print(f\"     → {contexte.upper()}_{resultat.get('categorie_medicale', 'autre').upper()}/ ({maladies}) [score: {score:.2f}]\")\n",
    "            else:\n",
    "                score = resultat.get('score_semantique', 0)\n",
    "                print(f\"     → {contexte.upper()}/ [score: {score:.2f}]\")\n",
    "        \n",
    "        # Classer le fichier physiquement\n",
    "        ancien_chemin = os.path.join(CHEMIN_DEPOTS, file_name)\n",
    "        \n",
    "        if fichier_info['eligible_classification'] and analyses[-1].get(\"contient_maladie\", False):\n",
    "            # Fichier médical > 2MB\n",
    "            resultat = analyses[-1]\n",
    "            categorie = resultat[\"categorie_medicale\"]\n",
    "            contexte = resultat[\"contexte_principal\"]\n",
    "            dossier_medical = os.path.join(CHEMIN_DEPOTS, f\"{contexte.upper()}_{categorie.upper()}\")\n",
    "            os.makedirs(dossier_medical, exist_ok=True)\n",
    "            nouveau_chemin = os.path.join(dossier_medical, file_name)\n",
    "        elif fichier_info['eligible_classification']:\n",
    "            # Fichier non-médical > 2MB\n",
    "            resultat = analyses[-1]\n",
    "            contexte = resultat[\"contexte_principal\"]\n",
    "            if contexte in ['commercial', 'formation', 'reglementaire']:\n",
    "                dossier_contexte = os.path.join(CHEMIN_DEPOTS, f\"{contexte.upper()}\")\n",
    "            else:\n",
    "                dossier_contexte = os.path.join(CHEMIN_DEPOTS, \"AUTRES\")\n",
    "            os.makedirs(dossier_contexte, exist_ok=True)\n",
    "            nouveau_chemin = os.path.join(dossier_contexte, file_name)\n",
    "        else:\n",
    "            # Fichier ≤ 2MB → AUTRES\n",
    "            dossier_autres = os.path.join(CHEMIN_DEPOTS, \"AUTRES\")\n",
    "            os.makedirs(dossier_autres, exist_ok=True)\n",
    "            nouveau_chemin = os.path.join(dossier_autres, file_name)\n",
    "        \n",
    "        # Déplacer\n",
    "        try:\n",
    "            shutil.move(ancien_chemin, nouveau_chemin)\n",
    "        except Exception as e:\n",
    "            print(f\"     ❌ Erreur déplacement: {e}\")\n",
    "    \n",
    "    print(f\"\\n📊 RÉSULTATS SÉMANTIQUES:\")\n",
    "    print(f\"   • {medicaux}/{len(analyses)} fichiers médicaux classés\")\n",
    "    print(f\"   • {petits_fichiers} petits fichiers (≤ 2MB) → AUTRES\")\n",
    "    print(f\"   • {eligibles} fichiers analysés sémantiquement\")\n",
    "    if contextes_stats:\n",
    "        print(f\"   • Contextes détectés: {list(contextes_stats.keys())}\")\n",
    "        for ctx, count in contextes_stats.items():\n",
    "            print(f\"     - {ctx}: {count} fichiers\")\n",
    "    \n",
    "    return analyses\n",
    "\n",
    "def generer_rapport_semantique(analyses):\n",
    "    \"\"\"Phase 4: Génération du rapport avec analyse sémantique\"\"\"\n",
    "    print(f\"\\n📝 PHASE 4: Génération du rapport sémantique...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    fichiers_medicaux = sum(1 for a in analyses if a['contient_maladie'])\n",
    "    categories = {}\n",
    "    contextes = {}\n",
    "    scores_moyens = {}\n",
    "    \n",
    "    for a in analyses:\n",
    "        # Stats par catégorie médicale\n",
    "        if a['contient_maladie']:\n",
    "            cat = a['categorie_medicale']\n",
    "            categories[cat] = categories.get(cat, 0) + 1\n",
    "        \n",
    "        # Stats par contexte\n",
    "        ctx = a['contexte_principal']\n",
    "        contextes[ctx] = contextes.get(ctx, 0) + 1\n",
    "        \n",
    "        # Scores sémantiques moyens\n",
    "        if ctx not in scores_moyens:\n",
    "            scores_moyens[ctx] = []\n",
    "        scores_moyens[ctx].append(a.get('score_semantique', 0.3))\n",
    "    \n",
    "    # Calculer moyennes\n",
    "    for ctx in scores_moyens:\n",
    "        scores_moyens[ctx] = sum(scores_moyens[ctx]) / len(scores_moyens[ctx])\n",
    "    \n",
    "    rapport = f\"\"\"# 📊 Rapport d'Analyse Sémantique de Fichiers Médicaux\n",
    "\n",
    "**Date d'analyse :** {datetime.now().strftime(\"%d/%m/%Y à %H:%M:%S\")}  \n",
    "**Dossier analysé :** `{CHEMIN_DEPOTS}`\n",
    "**Méthode :** Analyse sémantique LLM + Classification contextuelle\n",
    "\n",
    "---\n",
    "\n",
    "## 📈 Résumé Statistique\n",
    "\n",
    "| Métrique | Valeur |\n",
    "|----------|--------|\n",
    "| **Fichiers analysés** | {len(analyses)} |\n",
    "| **Fichiers médicaux** | {fichiers_medicaux} |\n",
    "| **Fichiers non-médicaux** | {len(analyses) - fichiers_medicaux} |\n",
    "| **Catégories médicales** | {len(categories)} |\n",
    "| **Contextes détectés** | {len(contextes)} |\n",
    "| **Score sémantique moyen** | {sum(a.get('score_semantique', 0.3) for a in analyses) / len(analyses):.2f} |\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Répartition par Contextes\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    for ctx, count in sorted(contextes.items()):\n",
    "        pct = (count / len(analyses) * 100)\n",
    "        score_ctx = scores_moyens.get(ctx, 0)\n",
    "        rapport += f\"- **{ctx.title()}** : {count} fichier(s) ({pct:.1f}%) - Score: {score_ctx:.2f}\\n\"\n",
    "    \n",
    "    rapport += \"\\n---\\n\\n## 🏥 Spécialités Médicales Détectées\\n\\n\"\n",
    "    \n",
    "    if categories:\n",
    "        for cat, count in sorted(categories.items()):\n",
    "            pct = (count / fichiers_medicaux * 100) if fichiers_medicaux > 0 else 0\n",
    "            rapport += f\"- **{cat.title()}** : {count} fichier(s) ({pct:.1f}%)\\n\"\n",
    "    else:\n",
    "        rapport += \"Aucune catégorie médicale détectée.\\n\"\n",
    "    \n",
    "    rapport += \"\\n---\\n\\n## 📋 Analyse Détaillée par Fichier\\n\\n\"\n",
    "    \n",
    "    # Trier par score sémantique décroissant\n",
    "    analyses_triees = sorted(analyses, key=lambda x: x.get('score_semantique', 0), reverse=True)\n",
    "    \n",
    "    for analyse in analyses_triees:\n",
    "        contexte = analyse['contexte_principal']\n",
    "        categorie = analyse['categorie_medicale']\n",
    "        \n",
    "        if analyse['contient_maladie']:\n",
    "            dossier = f\"{contexte.upper()}_{categorie.upper()}\"\n",
    "        else:\n",
    "            dossier = contexte.upper() if contexte in ['commercial', 'formation', 'reglementaire'] else \"AUTRES\"\n",
    "        \n",
    "        score = analyse.get('score_semantique', 0)\n",
    "        justification = analyse.get('justification', 'N/A')\n",
    "        \n",
    "        rapport += f\"\"\"### 📄 {analyse['fichier']}\n",
    "- **Contexte :** {contexte}\n",
    "- **Domaine médical :** {categorie}\n",
    "- **Type document :** {analyse.get('type_document', 'N/A')}\n",
    "- **Population cible :** {analyse.get('population_cible', 'N/A')}\n",
    "- **Termes détectés :** {', '.join(analyse['maladies_detectees']) if analyse['maladies_detectees'] else 'Aucun'}\n",
    "- **Score sémantique :** {score:.2f}/1.0\n",
    "- **Confiance :** {analyse['confiance']}\n",
    "- **Dossier :** `{dossier}/`\n",
    "- **Justification :** {justification}\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    rapport += f\"\"\"---\n",
    "\n",
    "## ⚙️ Technologie & Méthodologie\n",
    "\n",
    "### Analyse Sémantique\n",
    "- **LLM :** ChatOpenAI GPT-4o-mini (température: 0.1)\n",
    "- **Approche :** Compréhension contextuelle vs simple recherche de mots-clés\n",
    "- **Scoring :** Évaluation de cohérence sémantique (0.0 à 1.0)\n",
    "- **Fallback :** Détection enrichie par mots-clés contextuels\n",
    "\n",
    "### Classification Hiérarchique\n",
    "- **Structure :** CONTEXTE_DOMAINE/ pour fichiers médicaux\n",
    "- **Contextes :** {', '.join(sorted(contextes.keys()))}\n",
    "- **Critères :** Finalité du document, population cible, type de contenu\n",
    "\n",
    "### Métriques de Qualité\n",
    "- **Confiance moyenne :** {sum(1 for a in analyses if a['confiance'] == 'haute') / len(analyses) * 100:.1f}% haute confiance\n",
    "- **Classifications incertaines :** {sum(1 for a in analyses if a.get('score_semantique', 0) < 0.5)} fichiers (score < 0.5)\n",
    "\n",
    "---\n",
    "\n",
    "*Rapport généré par analyse sémantique LLM - Classification intelligente par contexte et intention 🧠*\n",
    "\"\"\"\n",
    "    \n",
    "    # Sauvegarder\n",
    "    chemin_rapport = os.path.join(CHEMIN_DEPOTS, \"RAPPORT_SEMANTIQUE.md\")\n",
    "    with open(chemin_rapport, 'w', encoding='utf-8') as f:\n",
    "        f.write(rapport)\n",
    "    \n",
    "    print(f\"✅ Rapport sémantique sauvé: {chemin_rapport}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Fonction principale - workflow sémantique simple\"\"\"\n",
    "    print(\"🚀 CLASSIFICATEUR MÉDICAL SÉMANTIQUE\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Source: {CHEMIN_SOURCE}\")\n",
    "    print(f\"Destination: {CHEMIN_DEPOTS}\")\n",
    "    print(\"🧠 Analyse contextuelle et intentionnelle\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Workflow en 4 étapes avec analyse sémantique et filtrage\n",
    "    fichiers_info = rechercher_fichiers_filtres()\n",
    "    if not fichiers_info:\n",
    "        print(\"❌ Aucun fichier trouvé après filtrage - Arrêt\")\n",
    "        return\n",
    "    \n",
    "    trier_fichiers_par_criteres(fichiers_info)\n",
    "    copier_fichiers(fichiers_info)\n",
    "    analyses = analyser_et_classer_semantique()\n",
    "    generer_rapport_semantique(analyses)\n",
    "    \n",
    "    print(\"\\n\" + \"🎉\" * 20)\n",
    "    print(\"✅ TERMINÉ - Classification sémantique réussie !\")\n",
    "    print(\"🧠 Analyse contextuelle vs mots-clés simples\")\n",
    "    print(\"📊 Structure hiérarchique par intention\")\n",
    "    print(\"🎉\" * 20)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
