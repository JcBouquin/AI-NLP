# PDF Analysis System with LangGraph

## Overview

This project implements a document analysis system using LangGraph to process administrative PDF documents, specifically oriented towards the identification and extraction of identified terms. The system consists of two complementary workflows that automate the entire document analysis process.

## System Architecture

### Workflow 1: Primary PDF Analysis
**Pipeline:** `Extraction → Analysis → Export`

The first workflow constitutes the core of the document analysis system. It processes PDF document pages with contextual segmentation.

#### Functionality
1. **Extraction**: PDF reading and preprocessing with automatic text cleaning
2. **Analysis**: LLM model application to identify delegation of authority patterns
3. **Export**: Generation of structured synthesis files

#### Batch Processing
A distinctive feature of this workflow lies in its **reduced batch processing** approach. Instead of analyzing the entire document in a single operation, the system segments processing into chunks of 2 pages (configurable to 3 or more).

**Advantages of this approach:**
- **Hallucination elimination**: Context reduction enables the LLM to maintain precision
- **Increased reliability**: Zero interpretation errors observed vs. some rare hallucinations in global processing
- **Quality control**: Validation possible chunk by chunk

**Limitation:**
- Requires multiple workflow executions to process a complete document

### Workflow 2: Secondary Synthesis Analysis
**Pipeline:** `Reading → Formatting → Statistics → Export`

The second workflow leverages results from the first to produce in-depth analyses.

#### Functionality
1. **Reading**: Ingestion of synthesis file generated by Workflow 1
2. **Formatting**: Extraction and structuring of key data
3. **Statistics**: Quantitative analysis and pattern identification
4. **Export**: Generation of statistical reports

## Prompts

### Chain of Thought (CoT)
The system implements prompting techniques based on Chains of Thought. This approach guides the LLM model through a structured thinking process.

**CoT variants used:**
- **Step-back Prompting**: Decomposition of complex tasks into elementary steps
- **Thread of Thought**: Maintaining logical consistency across analyses
- **Analogical Prompting**: Learning through similar examples to improve generalization
- **Memory of Thought**: Preservation of reasoning context between analysis steps
- **Active Prompting**: Dynamic adaptation of questions based on previous responses
- **Contrastive Prompting**: Use of positive and negative examples to refine understanding

### Analogical Prompting
Analogical prompting was used for the main analysis node. This technique consists of providing the model with concrete examples similar to the target use case, enabling generalization through analogy.

**Principle:**
- Presentation of typical examples with their complete resolution
- Guidance by example rather than abstract instruction
- Significant improvement in extraction precision

## Outputs: 3 MD Files

### Workflow 1
- **Synthesis file**: `{pdf_name}_synthese_{timestamp}.md`
- Consolidation of all chunk-based analyses
- Hierarchical structure with complete metadata

### Workflow 2
- **Formatted report**: `{synthesis}_formatted_{timestamp}.md`
- **Statistical analysis**: `{synthesis}_statistics_{timestamp}.md`
- Automatic timestamping for traceability

## Operational Advantages

### Precision
- **Reduced error rate** through batch processing
- **Multi-level validation** with sequential workflows
- **Terminological consistency** via analogical prompting

### Scalability
- **Modular architecture** enabling adaptation to different document types
- **Parallelizable processing** of chunks for future optimization
- **Extensibility** of statistical analyses

### Traceability
- **Systematic timestamping** of all outputs
- **Preservation of intermediate files** for audit purposes
- **Complete metadata** on processing parameters

## Configuration and Usage

### Main Parameters
```python
pdf_filename = "document.pdf"  # Document to analyze
start_page = 102               # Starting page
end_page = 118                 # Ending page
step = 2                       # Batch size (recommended: 2-3)
```

### Execution
```python
# Workflow 1 - PDF Analysis
result = process_pdf(pdf_filename, start_page, end_page)

# Workflow 2 - Synthesis Analysis (automatic after Workflow 1)
synthesis_result = process_synthesis_analysis(synthesis_file_path)
```

## Technologies Used

- **LangGraph**: Workflow orchestration
- **LangChain**: LLM interface and prompt management
- **OpenAI GPT-4o-mini**: Linguistic analysis engine
- **PDFPlumber**: PDF text extraction
- **Python**: Development environment
