{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "HlX4eDQQgE0p"
   },
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END ,state\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage,AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U langgraph langsmith\n",
    "! pip install langchain_community\n",
    "! pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration de la clé API\n",
    "os.environ['OPENAI_API_KEY'] = \"sHruNnPRcA\"\n",
    "\n",
    "\n",
    "# Création du modèle LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thread-of-Thought (ThoT) Prompting: An Optimized Method for Guiding LLM Reasoning\n",
    "\n",
    "Thread-of-Thought Prompting, introduced by Zhou et al. (2023), is a refined approach that improves how we induce structured reasoning in language models (LLMs).\n",
    "\n",
    "## How Does ThoT Prompting Work?\n",
    "\n",
    "Imagine guiding someone through a complex labyrinth. Instead of simply saying \"let's think step by step,\" you would provide more detailed instructions to analyze each intersection, evaluate options, and make informed decisions at each stage.\n",
    "\n",
    "ThoT Prompting perfects this guidance method by replacing the classic thought inducer with a more elaborate directive:\n",
    "\n",
    "1. **Improved inducer**: Instead of the simple \"Let's think step by step,\" ThoT uses \"Walk me through this context in manageable parts step by step, summarizing and analyzing as we go.\"\n",
    "\n",
    "2. **Structured sequential processing**: This formulation encourages the model to break down complex information, consolidate its understanding progressively, and build more coherent reasoning.\n",
    "\n",
    "## Why Is This Particularly Effective?\n",
    "\n",
    "This approach proves remarkably effective in situations where the model must navigate through voluminous and complex contexts. By guiding the LLM to process information in digestible segments, it allows the model to:\n",
    "\n",
    "* Better handle voluminous information\n",
    "* Maintain reasoning coherence throughout the process\n",
    "* Avoid getting lost in irrelevant details\n",
    "* Build progressive and cumulative understanding\n",
    "\n",
    "The results are particularly impressive in:\n",
    "* Question-answering tasks on long texts\n",
    "* Information retrieval contexts\n",
    "* Analysis of complex documents\n",
    "\n",
    "It's like giving a student not only the instruction to solve a problem but also a precise methodology to structure their thinking and synthesize as they go.\n",
    "\n",
    "This method could transform how we interact with LLMs by helping them approach complex problems with a more structured methodology that's closer to expert human reasoning.\n",
    "\n",
    "The next time you ask an AI a complex question, try using this improved thought inducer to get a more thorough and better-structured response!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du prompt\n",
    "thot_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "    Generate Thread-of-Thought (ThoT) prompts based on user questions.\n",
    "    \n",
    "    (ThoT) is a part of Chain-of-Thought (CoT) prompting leverages few-shot prompting to encourage the LLM to express its thought process before delivering its final answer.\n",
    "    \n",
    "    This technique enhances the LLM's performance in reasoning tasks.\n",
    "    \n",
    "    A CoT prompt includes an exemplar featuring a question, a reasoning path, and the correct answer.\n",
    "    Thread-of-Thought (ThoT) is a specialized form of CoT.\n",
    "    The ThoT process includes the following steps:\n",
    "    1. High-level prompt: \"Walk me through this context in manageable parts step by step, summarizing and analyzing as we go.\"\n",
    "    2. Summarize and analyze: Break down the question's context into manageable parts, summarizing and analyzing each part.\n",
    "    3. Answer the original question: Provide a final answer based on the analysis.\n",
    "    \n",
    "    Please structure your response in the following format:\n",
    "    \n",
    "    Step 1: [High-level prompt]\n",
    "    Step 2: [Summarize and analyze each part]\n",
    "    Step 3: [Final Answer]\n",
    "    \n",
    "    Example:\n",
    "    Question: \"What are the main causes of climate change?\"\n",
    "    \n",
    "    Step 1: Walk me through this context in manageable parts step by step, summarizing and analyzing as we go.\n",
    "    \n",
    "    Step 2: \n",
    "    Thread 1 - Understanding the concept of climate change:\n",
    "    Climate change refers to significant, long-term changes in the global climate. The Earth's average surface temperature has increased by about 1.1°C since the pre-industrial era. This increase might seem small, but even minor changes in average global temperature can drastically affect weather patterns, ecosystems, and human societies.\n",
    "    \n",
    "    Thread 2 - Examining fossil fuel combustion:\n",
    "    The primary driver of climate change is the burning of fossil fuels (coal, oil, and natural gas). When we analyze this process, fossil fuels release carbon dioxide (CO2) that has been stored underground for millions of years. This CO2 enters the atmosphere and enhances the greenhouse effect. Transportation, electricity generation, and industrial processes are the major sectors contributing to these emissions. The data shows that CO2 concentrations have increased from about 280 parts per million (ppm) in pre-industrial times to over 415 ppm today.\n",
    "    \n",
    "    Thread 3 - Analyzing deforestation impacts:\n",
    "    Forests act as carbon sinks, absorbing CO2 from the atmosphere. When forests are cleared (often for agriculture, timber, or urban development), this stored carbon is released back into the atmosphere. Additionally, fewer trees mean reduced capacity to remove CO2 from the air. Tropical deforestation alone accounts for about 10% of human-caused greenhouse gas emissions. Satellite imagery reveals we lose approximately 10 million hectares of forest annually.\n",
    "    \n",
    "    Thread 4 - Exploring agricultural and industrial activities:\n",
    "    Beyond CO2, other greenhouse gases play significant roles. Methane (CH4), released from livestock, rice paddies, and landfills, has a warming potential 25 times greater than CO2 over a 100-year period. Nitrous oxide (N2O) from fertilizers and industrial processes is about 300 times more potent than CO2. Industrial processes also emit fluorinated gases with extremely high warming potentials, some thousands of times more potent than CO2.\n",
    "    \n",
    "    Thread 5 - Connecting the mechanisms:\n",
    "    These greenhouse gases function by allowing sunlight to enter the atmosphere but trapping the reflected heat, similar to how a greenhouse operates. This trapped heat leads to rising global temperatures, which in turn causes melting ice caps, rising sea levels, altered precipitation patterns, and increased frequency of extreme weather events. Climate models demonstrate that the observed warming cannot be explained by natural factors alone and correlates strongly with human activities.\n",
    "    \n",
    "    Step 3: The main causes of climate change are human activities, primarily the burning of fossil fuels (releasing CO2), deforestation (reducing carbon absorption and releasing stored carbon), and agricultural/industrial processes (emitting methane, nitrous oxide, and other potent greenhouse gases). These activities intensify the greenhouse effect by increasing atmospheric concentrations of heat-trapping gases, leading to global warming and its associated impacts on our planet's climate systems.\n",
    "    \"\"\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "    (\"assistant\", \"\"\"\n",
    "    Walk me through this context in manageable parts step by step, summarizing and analyzing as we go:\n",
    "    \n",
    "    Thread 1 - [First logical component of analysis]:\n",
    "    [Detailed examination of the first aspect of the question, breaking down key concepts, analyzing relationships, and providing relevant context and examples]\n",
    "    \n",
    "    Thread 2 - [Second logical component of analysis]:\n",
    "    [Detailed examination of the second aspect, building upon previous insights while introducing new perspectives and data points]\n",
    "    \n",
    "    Thread 3 - [Third logical component of analysis]:\n",
    "    [Detailed examination of the third aspect, further deepening the analysis with additional considerations and potentially addressing counterpoints]\n",
    "    \n",
    "    [Additional threads as needed depending on question complexity]\n",
    "    \n",
    "    Thread n - [Final integrative component]:\n",
    "    [Synthesis of all threads, connecting insights across the different components of analysis and drawing overarching conclusions]\n",
    "    \n",
    "    Final Answer: [Concise, comprehensive answer that integrates the complete analysis while directly addressing the original question]\n",
    "    \"\"\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Thread-of-Thought (ThoT) Prompting approach is especially well-suited for questions that involve analyzing complex, multi-faceted information where breaking down the context into digestible parts adds significant value. Here are types of questions that would benefit from this approach:\n",
    "\n",
    "### Text Analysis and Comprehension\n",
    "- Analysis of long, complex documents or articles\n",
    "- Literature review questions requiring synthesis of multiple sources\n",
    "- Case study breakdowns in business, law, or medicine\n",
    "- Historical event analysis with multiple perspectives or causes\n",
    "\n",
    "### Complex Systems Understanding\n",
    "- Questions about interconnected systems (economic, ecological, political)\n",
    "- Multi-step processes with various components and effects\n",
    "- Technology stack or architecture explanations\n",
    "- Supply chain or workflow analysis questions\n",
    "\n",
    "### Research Questions\n",
    "- Scientific studies with complex methodologies\n",
    "- Multi-variable research problems\n",
    "- Interdisciplinary questions crossing multiple domains\n",
    "- Questions requiring evidence analysis from multiple sources\n",
    "\n",
    "### Concrete Examples of Questions\n",
    "\n",
    "1. \"Can you analyze this research paper on climate change adaptation strategies and highlight the key findings, methodologies, and implications?\"\n",
    "\n",
    "2. \"How do the various economic, social, and political factors interact to create housing affordability challenges in urban centers?\"\n",
    "\n",
    "3. \"What were the complex causes that led to the financial crisis of 2008, and how did these factors interact with each other?\"\n",
    "\n",
    "4. \"Based on this patient case file, what are the possible diagnoses, their evidence, and recommended next steps?\"\n",
    "\n",
    "5. \"Analyze this legal contract and explain the key clauses, potential risks, and obligations for each party.\"\n",
    "\n",
    "6. \"How do the different components of this business model work together, and what are the strategic advantages they create?\"\n",
    "\n",
    "7. \"Explain how this software architecture functions, breaking down each component and how they interact with each other.\"\n",
    "\n",
    "ThoT Prompting is particularly effective for these types of questions because:\n",
    "\n",
    "- It encourages progressive understanding of complex information\n",
    "- It helps maintain focus when dealing with large amounts of information\n",
    "- The summarization component ensures key insights aren't lost\n",
    "- The step-by-step approach prevents overwhelming the reader with too much information at once\n",
    "- The analysis element promotes deeper understanding rather than mere description\n",
    "\n",
    "This approach transforms what might otherwise be an unwieldy wall of information into a structured, digestible analysis that builds progressively toward comprehensive understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION:\n",
      "Explain Jean-Jacques Rousseau.\n",
      "\n",
      "FINAL ANSWER (STEP 3):\n",
      "Jean-Jacques Rousseau was a pivotal Enlightenment thinker whose works explored the nature of human beings, society, and governance. He argued that humans are born good but are corrupted by societal influences, advocating for a social contract as the basis for legitimate political authority. His ideas on education and the importance of the general will have profoundly influenced modern political philosophy and educational practices. Rousseau's legacy continues to resonate in discussions about democracy, individual rights, and the role of society in shaping human behavior.\n",
      "\n",
      "(Complete results saved in 'thot_result.txt')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from typing import Optional, TypedDict, Annotated\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "\n",
    "# Function to generate the ThoT prompt and extract the final answer (Step 3)\n",
    "def generate_thot_node(state):\n",
    "    question = state['messages'][-1].content  # Get the last question\n",
    "    prompt_value = thot_prompt_template.invoke({\"question\": question})\n",
    "    messages = prompt_value.to_messages()\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    # Keep the full response for processing\n",
    "    full_response = response.content\n",
    "    \n",
    "    # Extract the final answer from Step 3\n",
    "    final_answer_pattern = r'Step 3:([\\s\\S]*?)(?=$|Step \\d:)'\n",
    "    final_answer_match = re.search(final_answer_pattern, full_response)\n",
    "    \n",
    "    if final_answer_match:\n",
    "        final_solution = final_answer_match.group(1).strip()\n",
    "    else:\n",
    "        # Alternative pattern\n",
    "        alternative_pattern = r'Step 3: \\[Final Answer\\]([\\s\\S]*?)(?=$|Step \\d:)'\n",
    "        alternative_match = re.search(alternative_pattern, full_response)\n",
    "        \n",
    "        if alternative_match:\n",
    "            final_solution = alternative_match.group(1).strip()\n",
    "        else:\n",
    "            final_solution = \"Final solution not found in the expected format.\"\n",
    "    \n",
    "    # Save both the question, final answer, and full processing to a text file\n",
    "    with open('thot_result.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=== QUESTION ===\\n\\n\")\n",
    "        f.write(question)\n",
    "        f.write(\"\\n\\n=== FINAL ANSWER (STEP 3) ===\\n\\n\")\n",
    "        f.write(final_solution)\n",
    "        f.write(\"\\n\\n=== COMPLETE PROCESSING (FOR REFERENCE) ===\\n\\n\")\n",
    "        f.write(full_response)\n",
    "    \n",
    "    # Return only the final answer in messages, plus the original question for reference\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=final_solution)],\n",
    "        \"question\": question,\n",
    "        \"full_response\": full_response\n",
    "    }\n",
    "\n",
    "# Definition of state\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    question: Optional[str]\n",
    "    full_response: Optional[str]\n",
    "\n",
    "# Graph creation\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"generate_thot\", generate_thot_node)\n",
    "\n",
    "# Graph configuration\n",
    "graph_builder.set_entry_point(\"generate_thot\")\n",
    "graph_builder.add_edge(\"generate_thot\", END)\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "# Usage example\n",
    "inputs = {\n",
    "    \"messages\": [HumanMessage(content=\"Explain Jean-Jacques Rousseau.\")],\n",
    "    \"question\": None,\n",
    "    \"full_response\": None\n",
    "}\n",
    "\n",
    "# Print the question at the beginning\n",
    "print(\"QUESTION:\")\n",
    "print(inputs[\"messages\"][0].content)\n",
    "print(\"\\nFINAL ANSWER (STEP 3):\")\n",
    "\n",
    "# Graph execution - only display Step 3\n",
    "original_question = \"\"\n",
    "for output in graph.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        if key == \"generate_thot\":\n",
    "            messages = value['messages']\n",
    "            for message in messages:\n",
    "                if isinstance(message, AIMessage):\n",
    "                    print(message.content)\n",
    "            \n",
    "            # Store question for reference\n",
    "            if \"question\" in value:\n",
    "                original_question = value[\"question\"]\n",
    "\n",
    "# Print confirmation that results were saved\n",
    "print(\"\\n(Complete results saved in 'thot_result.txt')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMTfAweIg6gbCMdDfdaZ1ZF",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
