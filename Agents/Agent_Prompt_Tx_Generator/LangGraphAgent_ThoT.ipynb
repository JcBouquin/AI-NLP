{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HlX4eDQQgE0p"
   },
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END ,state\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage,AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U langgraph langsmith\n",
    "! pip install langchain_community\n",
    "! pip install langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5EuyBDehnu31"
   },
   "source": [
    "### ThoT Building Prompt Generator  \n",
    "\n",
    "Based on \"The Prompt Report: A Systematic Survey of Prompting Techniques.\",\n",
    "a detailed vocabulary of 33 vocabulary terms, a taxonomy of 58 LLM prompting techniques, and 40 techniques for other modalities.\n",
    "\n",
    "**Thread-of-Thought (ThoT)** Prompting (Zhouet al., 2023)\n",
    "\n",
    "consists of an improved thought in\u0002ducer for CoT reasoning. Instead of \"Let’s think step by step,\" it uses \"Walk me through this context in manageable parts step by step, summarizing and analyzing as we go.\" This thought inducer works\n",
    "well in question-answering and retrieval settings,especially when dealing with large, complex con\u0002texts.ThoT is a part of CoT (chain of thoughts)\n",
    "\n",
    "**Chain-of-Thought (CoT)** is a prompt engineering framework that enables reasoning\n",
    "capabilities through intermediate steps. There are various sub-techniques of CoT including\n",
    "self-consistency, active-prompt, and multimodal CoT that each have strengths and\n",
    "weaknesses depending on the specific application\n",
    "\n",
    "\n",
    "\n",
    "#### **Goal**\n",
    "\n",
    "The main idea is to develop automated **prompt generator agents**. These agents will be designed to:\n",
    "\n",
    "* Analyze a given question.\n",
    "* Generate an optimized prompt using various prompting techniques.\n",
    "\n",
    "The development of these agents relies on:\n",
    "\n",
    "* Recent prompt techniques, defined and classified in the document **\"The Prompt Report: A Systematic Survey of Prompting Techniques\"**.\n",
    "\n",
    "#### **Functionality**\n",
    "\n",
    "1.  **Question Reception:** The agent receives a question as input.\n",
    "2.  **Question Analysis:** The agent analyzes the question to understand its intent and requirements.\n",
    "3.  **Prompt Approach Selection:** Based on the analysis and the techniques from \"The Prompt Report,\" the agent selects the most appropriate prompting approach.\n",
    "4.  **Prompt Generation:** The agent generates an optimized prompt using the selected approach.\n",
    "\n",
    "#### **Expected Benefits**\n",
    "\n",
    "* Facilitate the creation of complex prompts.\n",
    "* Optimize the efficiency of AI models.\n",
    "* Make the use of AI more accessible.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration de la clé API\n",
    "os.environ['OPENAI_API_KEY'] = \"sk-proj-rPBnsXimJy GIZTWPKAtav6nWikZPSewB3oeo055nFcLW9rnMorepgfeAZNQQz5FUUwrtmQsA\"\n",
    "\n",
    "\n",
    "# Création du modèle LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du prompt\n",
    "thot_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "    Generate Thread-of-Thought (ThoT) prompts based on user questions.\n",
    "    \n",
    "    (ThoT) is a part of Chain-of-Thought (CoT) prompting leverages few-shot prompting to encourage the LLM to express its thought process before delivering its final answer.\n",
    "    \n",
    "    This technique enhances the LLM's performance in reasoning tasks.\n",
    "    \n",
    "    A CoT prompt includes an exemplar featuring a question, a reasoning path, and the correct answer.\n",
    "    Thread-of-Thought (ThoT) is a specialized form of CoT.\n",
    "    The ThoT process includes the following steps:\n",
    "    1. High-level prompt: \"Walk me through this context in manageable parts step by step, summarizing and analyzing as we go.\"\n",
    "    2. Summarize and analyze: Break down the question's context into manageable parts, summarizing and analyzing each part.\n",
    "    3. Answer the original question: Provide a final answer based on the analysis.\n",
    "    \n",
    "    Please structure your response in the following format:\n",
    "    \n",
    "    Step 1: [High-level prompt]\n",
    "    Step 2: [Summarize and analyze each part]\n",
    "    Step 3: [Final Answer]\n",
    "    \n",
    "    Example:\n",
    "    Question: \"What are the main causes of climate change?\"\n",
    "    \n",
    "    Step 1: Walk me through this context in manageable parts step by step, summarizing and analyzing as we go.\n",
    "    \n",
    "    Step 2: \n",
    "    Thread 1 - Understanding the concept of climate change:\n",
    "    Climate change refers to significant, long-term changes in the global climate. The Earth's average surface temperature has increased by about 1.1°C since the pre-industrial era. This increase might seem small, but even minor changes in average global temperature can drastically affect weather patterns, ecosystems, and human societies.\n",
    "    \n",
    "    Thread 2 - Examining fossil fuel combustion:\n",
    "    The primary driver of climate change is the burning of fossil fuels (coal, oil, and natural gas). When we analyze this process, fossil fuels release carbon dioxide (CO2) that has been stored underground for millions of years. This CO2 enters the atmosphere and enhances the greenhouse effect. Transportation, electricity generation, and industrial processes are the major sectors contributing to these emissions. The data shows that CO2 concentrations have increased from about 280 parts per million (ppm) in pre-industrial times to over 415 ppm today.\n",
    "    \n",
    "    Thread 3 - Analyzing deforestation impacts:\n",
    "    Forests act as carbon sinks, absorbing CO2 from the atmosphere. When forests are cleared (often for agriculture, timber, or urban development), this stored carbon is released back into the atmosphere. Additionally, fewer trees mean reduced capacity to remove CO2 from the air. Tropical deforestation alone accounts for about 10% of human-caused greenhouse gas emissions. Satellite imagery reveals we lose approximately 10 million hectares of forest annually.\n",
    "    \n",
    "    Thread 4 - Exploring agricultural and industrial activities:\n",
    "    Beyond CO2, other greenhouse gases play significant roles. Methane (CH4), released from livestock, rice paddies, and landfills, has a warming potential 25 times greater than CO2 over a 100-year period. Nitrous oxide (N2O) from fertilizers and industrial processes is about 300 times more potent than CO2. Industrial processes also emit fluorinated gases with extremely high warming potentials, some thousands of times more potent than CO2.\n",
    "    \n",
    "    Thread 5 - Connecting the mechanisms:\n",
    "    These greenhouse gases function by allowing sunlight to enter the atmosphere but trapping the reflected heat, similar to how a greenhouse operates. This trapped heat leads to rising global temperatures, which in turn causes melting ice caps, rising sea levels, altered precipitation patterns, and increased frequency of extreme weather events. Climate models demonstrate that the observed warming cannot be explained by natural factors alone and correlates strongly with human activities.\n",
    "    \n",
    "    Step 3: The main causes of climate change are human activities, primarily the burning of fossil fuels (releasing CO2), deforestation (reducing carbon absorption and releasing stored carbon), and agricultural/industrial processes (emitting methane, nitrous oxide, and other potent greenhouse gases). These activities intensify the greenhouse effect by increasing atmospheric concentrations of heat-trapping gases, leading to global warming and its associated impacts on our planet's climate systems.\n",
    "    \"\"\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "    (\"assistant\", \"\"\"\n",
    "    Walk me through this context in manageable parts step by step, summarizing and analyzing as we go:\n",
    "    \n",
    "    Thread 1 - [First logical component of analysis]:\n",
    "    [Detailed examination of the first aspect of the question, breaking down key concepts, analyzing relationships, and providing relevant context and examples]\n",
    "    \n",
    "    Thread 2 - [Second logical component of analysis]:\n",
    "    [Detailed examination of the second aspect, building upon previous insights while introducing new perspectives and data points]\n",
    "    \n",
    "    Thread 3 - [Third logical component of analysis]:\n",
    "    [Detailed examination of the third aspect, further deepening the analysis with additional considerations and potentially addressing counterpoints]\n",
    "    \n",
    "    [Additional threads as needed depending on question complexity]\n",
    "    \n",
    "    Thread n - [Final integrative component]:\n",
    "    [Synthesis of all threads, connecting insights across the different components of analysis and drawing overarching conclusions]\n",
    "    \n",
    "    Final Answer: [Concise, comprehensive answer that integrates the complete analysis while directly addressing the original question]\n",
    "    \"\"\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION:\n",
      "Explain Jean-Jacques Rousseau.\n",
      "\n",
      "FINAL ANSWER (STEP 3):\n",
      "Jean-Jacques Rousseau was a pivotal Enlightenment thinker whose ideas on the social contract, the nature of humanity, education, and inequality have had a lasting impact on political philosophy and educational theory. He believed that humans are inherently good but are corrupted by society, advocating for a political system based on the general will and emphasizing the importance of natural education. His critiques of social inequality continue to resonate in modern discussions about justice and governance.\n",
      "\n",
      "(Complete results saved in 'thot_result.txt')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from typing import Optional, TypedDict, Annotated\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "\n",
    "# Function to generate the ThoT prompt and extract the final answer (Step 3)\n",
    "def generate_thot_node(state):\n",
    "    question = state['messages'][-1].content  # Get the last question\n",
    "    prompt_value = thot_prompt_template.invoke({\"question\": question})\n",
    "    messages = prompt_value.to_messages()\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    # Keep the full response for processing\n",
    "    full_response = response.content\n",
    "    \n",
    "    # Extract the final answer from Step 3\n",
    "    final_answer_pattern = r'Step 3:([\\s\\S]*?)(?=$|Step \\d:)'\n",
    "    final_answer_match = re.search(final_answer_pattern, full_response)\n",
    "    \n",
    "    if final_answer_match:\n",
    "        final_solution = final_answer_match.group(1).strip()\n",
    "    else:\n",
    "        # Alternative pattern\n",
    "        alternative_pattern = r'Step 3: \\[Final Answer\\]([\\s\\S]*?)(?=$|Step \\d:)'\n",
    "        alternative_match = re.search(alternative_pattern, full_response)\n",
    "        \n",
    "        if alternative_match:\n",
    "            final_solution = alternative_match.group(1).strip()\n",
    "        else:\n",
    "            final_solution = \"Final solution not found in the expected format.\"\n",
    "    \n",
    "    # Save both the question, final answer, and full processing to a text file\n",
    "    with open('thot_result.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=== QUESTION ===\\n\\n\")\n",
    "        f.write(question)\n",
    "        f.write(\"\\n\\n=== FINAL ANSWER (STEP 3) ===\\n\\n\")\n",
    "        f.write(final_solution)\n",
    "        f.write(\"\\n\\n=== COMPLETE PROCESSING (FOR REFERENCE) ===\\n\\n\")\n",
    "        f.write(full_response)\n",
    "    \n",
    "    # Return only the final answer in messages, plus the original question for reference\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=final_solution)],\n",
    "        \"question\": question,\n",
    "        \"full_response\": full_response\n",
    "    }\n",
    "\n",
    "# Definition of state\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    question: Optional[str]\n",
    "    full_response: Optional[str]\n",
    "\n",
    "# Graph creation\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"generate_thot\", generate_thot_node)\n",
    "\n",
    "# Graph configuration\n",
    "graph_builder.set_entry_point(\"generate_thot\")\n",
    "graph_builder.add_edge(\"generate_thot\", END)\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "# Usage example\n",
    "inputs = {\n",
    "    \"messages\": [HumanMessage(content=\"Explain Jean-Jacques Rousseau.\")],\n",
    "    \"question\": None,\n",
    "    \"full_response\": None\n",
    "}\n",
    "\n",
    "# Print the question at the beginning\n",
    "print(\"QUESTION:\")\n",
    "print(inputs[\"messages\"][0].content)\n",
    "print(\"\\nFINAL ANSWER (STEP 3):\")\n",
    "\n",
    "# Graph execution - only display Step 3\n",
    "original_question = \"\"\n",
    "for output in graph.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        if key == \"generate_thot\":\n",
    "            messages = value['messages']\n",
    "            for message in messages:\n",
    "                if isinstance(message, AIMessage):\n",
    "                    print(message.content)\n",
    "            \n",
    "            # Store question for reference\n",
    "            if \"question\" in value:\n",
    "                original_question = value[\"question\"]\n",
    "\n",
    "# Print confirmation that results were saved\n",
    "print(\"\\n(Complete results saved in 'thot_result.txt')\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMTfAweIg6gbCMdDfdaZ1ZF",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
