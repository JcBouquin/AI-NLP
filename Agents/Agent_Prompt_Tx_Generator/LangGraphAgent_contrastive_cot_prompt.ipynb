{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U langgraph langsmith\n",
    "! pip install langchain_community\n",
    "! pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END ,state\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage,AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration de la clé API\n",
    "os.environ['OPENAI_API_KEY'] = \"sk-pro c5xEwhMZOsYA6xKN4HruNnPRcA\"\n",
    "\n",
    "\n",
    "\n",
    "# Création du modèle LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrastive Prompting (CoT): Learning from Mistakes to Improve LLMs\n",
    "\n",
    "Contrastive Prompting (Contrastive Chain-of-Thought), introduced by Chia et al. (2023), is an ingenious method that enriches the learning of language models (LLMs) by showing them both correct and incorrect reasoning.\n",
    "\n",
    "## How Does Contrastive Prompting Work?\n",
    "\n",
    "Imagine you're teaching a student. Instead of only showing examples of correct answers, you also deliberately present common reasoning errors so they learn to avoid them.\n",
    "\n",
    "Contrastive Prompting follows this pedagogical logic in two key steps:\n",
    "\n",
    "1. **Demonstration of contrasts**: The LLM is provided with examples that contain both incorrect and correct reasoning chains for the same problem.\n",
    "\n",
    "2. **Identification of pitfalls**: These contrastive examples allow the model to recognize typical errors, false reasoning, and logical traps to avoid.\n",
    "\n",
    " This approach leverages a fundamental principle of human learning: we often learn better from our mistakes than from our successes. By explicitly exposing the model to erroneous reasoning, it's allowed to develop a form of \"critical discernment.\"\n",
    "\n",
    "Domain  such as:\n",
    "* Arithmetic reasoning\n",
    "* Factual questions\n",
    "* Complex problem solving\n",
    "\n",
    "It's like teaching a student not only the correct method for solving an equation but also the common errors that lead to false solutions.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrastive_cot_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "    Generate Contrastive Chain-of-Thought (CoT) Prompting based on user questions.\n",
    "    \n",
    "    Contrastive CoT Prompting is an advanced form of Chain-of-Thought that includes both correct and incorrect reasoning paths to help the model distinguish between valid and invalid approaches.\n",
    "    \n",
    "    This technique significantly improves performance on arithmetic reasoning and factual QA tasks by demonstrating both how to reason correctly and how not to reason.\n",
    "    \n",
    "    The Contrastive CoT process includes the following steps:\n",
    "    1. Problem understanding: Clearly state the problem and identify key information.\n",
    "    2. Incorrect reasoning path: Show a plausible but flawed reasoning process that leads to an incorrect answer.\n",
    "    3. Error identification: Identify the specific mistakes or logical errors in the incorrect approach.\n",
    "    4. Correct reasoning path: Demonstrate the proper reasoning process step by step.\n",
    "    5. Final answer with justification: Provide the correct answer with clear justification.\n",
    "    \n",
    "    Please structure your response in the following format:\n",
    "    \n",
    "    Step 1: [Problem understanding]\n",
    "    Step 2: [Incorrect reasoning path]\n",
    "    Step 3: [Error identification]\n",
    "    Step 4: [Correct reasoning path]\n",
    "    Step 5: [Final answer with justification]\n",
    "    \n",
    "    Example:\n",
    "    Question: \"A store sells notebooks for $2.50 each. If you buy 6 notebooks, how much change will you receive from a $20 bill?\"\n",
    "    \n",
    "    Step 1: Problem understanding:\n",
    "    I need to calculate how much change I'll receive after buying 6 notebooks at $2.50 each with a $20 bill. This requires figuring out the total cost of the notebooks and then subtracting that from $20.\n",
    "    \n",
    "    Step 2: Incorrect reasoning path:\n",
    "    To find the cost of 6 notebooks, I'll multiply:\n",
    "    6 × $2.50 = $12.50\n",
    "    Then the change would be:\n",
    "    $20 - $12.50 = $7.50\n",
    "    So I would receive $7.50 in change.\n",
    "    \n",
    "    Step 3: Error identification:\n",
    "    Wait, I made a calculation error. When multiplying 6 by $2.50:\n",
    "    6 × $2.50 = 6 × 2.5 = 12 + 3 = $15.00, not $12.50\n",
    "    The error was in the multiplication step, where I incorrectly calculated 6 × $2.50 as $12.50.\n",
    "    \n",
    "    Step 4: Correct reasoning path:\n",
    "    Let's solve this correctly:\n",
    "    Cost of one notebook = $2.50\n",
    "    Cost of 6 notebooks = 6 × $2.50 = $15.00\n",
    "    I give the cashier a $20 bill\n",
    "    Change = $20.00 - $15.00 = $5.00\n",
    "    \n",
    "    Step 5: The correct answer is $5.00 in change. This is justified because 6 notebooks at $2.50 each costs $15.00 in total (6 × $2.50 = $15.00), and when paying with a $20 bill, the change is $20.00 - $15.00 = $5.00.\n",
    "    \"\"\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "    (\"assistant\", \"\"\"\n",
    "    Step 1: Problem understanding:\n",
    "    [Clearly state the problem and identify the key information, variables, and what is being asked. Make sure to highlight any relevant details or constraints.]\n",
    "    \n",
    "    Step 2: Incorrect reasoning path:\n",
    "    [Present a plausible but flawed approach to solving the problem:\n",
    "    - Show reasonable-looking steps that someone might actually follow\n",
    "    - Carry the reasoning through to an incorrect conclusion\n",
    "    - Make the mistake subtle enough to be educational (not an obvious arithmetic error)]\n",
    "    \n",
    "    Step 3: Error identification:\n",
    "    [Identify and explain the specific errors in the incorrect reasoning:\n",
    "    - Pinpoint exactly where and how the reasoning went wrong\n",
    "    - Explain why this approach is problematic or leads to an incorrect result\n",
    "    - Clarify any misconceptions demonstrated in the incorrect approach]\n",
    "    \n",
    "    Step 4: Correct reasoning path:\n",
    "    [Demonstrate the proper way to solve the problem:\n",
    "    1. [First step in the correct solution process]\n",
    "    2. [Second step in the correct solution process]\n",
    "    3. [Continue with additional steps as needed]\n",
    "    - Ensure each step is logical and builds on previous steps\n",
    "    - Show all work clearly]\n",
    "    \n",
    "    Step 5: [State the final answer clearly and concisely, followed by a justification that highlights why this approach leads to the correct solution and how it avoids the pitfalls identified in Step 3]\n",
    "    \"\"\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Contrastive Chain-of-Thought (CoT) Prompting, the most suitable questions are those where distinguishing between correct and incorrect reasoning paths significantly enhances model performance. Here are types of questions that would be particularly well-suited to this approach:\n",
    "\n",
    "### Mathematical and Arithmetic Problems\n",
    "- Word problems with common calculation errors\n",
    "- Multi-step calculations where order of operations matters\n",
    "- Percentage, ratio, and fraction problems\n",
    "- Financial calculations with multiple variables\n",
    "\n",
    "### Logical Reasoning Tasks\n",
    "- Deductive reasoning problems with potential fallacies\n",
    "- Questions involving causal relationships\n",
    "- Syllogisms and formal logic problems\n",
    "- Problems requiring avoidance of common cognitive biases\n",
    "\n",
    "### Factual Question Answering\n",
    "- Questions with commonly confused facts or entities\n",
    "- Multi-part factual questions requiring verification at each step\n",
    "- Questions where precision in terminology matters\n",
    "- Historical or scientific questions with common misconceptions\n",
    "\n",
    "### Concrete Examples of Questions\n",
    "\n",
    "1. \"If a shirt originally costs $80 and is discounted by 25%, then has a 'buy one get one half off' promotion applied when purchasing two, what is the average price per shirt?\"\n",
    "   - Showcasing correct vs. incorrect discount application order\n",
    "\n",
    "2. \"A baker has 3/4 cup of flour and needs 2 1/2 cups. How much more flour does the baker need?\"\n",
    "   - Demonstrating proper vs. improper fraction subtraction\n",
    "\n",
    "3. \"If all dolphins are mammals, and all mammals are warm-blooded, what valid conclusion can we draw about dolphins?\"\n",
    "   - Contrasting valid logical deduction vs. invalid logical fallacies\n",
    "\n",
    "4. \"The population of a bacteria culture doubles every 30 minutes. If we start with 100 bacteria, how many will we have after 3 hours?\"\n",
    "   - Showing exponential growth calculation vs. linear calculation errors\n",
    "\n",
    "5. \"Who was the first person to reach the South Pole, and in what year did this occur?\"\n",
    "   - Contrasting accurate factual recall vs. common historical confusion\n",
    "\n",
    "Contrastive CoT Prompting is particularly effective for these types of questions because:\n",
    "\n",
    "- It explicitly demonstrates both correct reasoning and common pitfalls\n",
    "- It helps the model recognize and avoid typical reasoning errors\n",
    "- It builds an internal \"error detector\" for flawed reasoning paths\n",
    "- It enhances discrimination between superficially similar but conceptually different approaches\n",
    "- It mimics effective teaching strategies that highlight both what to do and what to avoid\n",
    "\n",
    "This approach is especially powerful for problems with common, identifiable error patterns where seeing the contrast between correct and incorrect reasoning provides more instructional value than seeing only correct solutions. The method effectively teaches models to recognize and avoid reasoning traps, much like how humans learn from both successes and failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION:\n",
      "Who was the first person to reach the South Pole, and in what year did this occur?\n",
      "\n",
      "FINAL ANSWER (STEP 5):\n",
      "The correct answer is Roald Amundsen, who was the first person to reach the South Pole on December 14, 1911. This is justified because historical records clearly indicate that Amundsen's expedition arrived at the South Pole before Scott's, making him the first to achieve this milestone.\n",
      "\n",
      "(Complete results saved in 'contrastive_cot_result.txt')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from typing import Optional, TypedDict, Annotated\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "\n",
    "# Function to generate the Contrastive Chain of Thought prompt and extract the final answer (Step 5)\n",
    "def generate_contrastive_cot_node(state):\n",
    "    question = state['messages'][-1].content  # Get the last question\n",
    "    prompt_value = contrastive_cot_prompt_template.invoke({\"question\": question})\n",
    "    messages = prompt_value.to_messages()\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    # Keep the full response for processing\n",
    "    full_response = response.content\n",
    "    \n",
    "    # Extract the final answer from Step 5\n",
    "    final_answer_pattern = r'Step 5:([\\s\\S]*?)(?=$|Step \\d:)'\n",
    "    final_answer_match = re.search(final_answer_pattern, full_response)\n",
    "    \n",
    "    if final_answer_match:\n",
    "        final_solution = final_answer_match.group(1).strip()\n",
    "    else:\n",
    "        # Alternative pattern\n",
    "        alternative_pattern = r'Step 5: \\[Final answer with justification\\]([\\s\\S]*?)(?=$|Step \\d:)'\n",
    "        alternative_match = re.search(alternative_pattern, full_response)\n",
    "        \n",
    "        if alternative_match:\n",
    "            final_solution = alternative_match.group(1).strip()\n",
    "        else:\n",
    "            final_solution = \"Final solution not found in the expected format.\"\n",
    "    \n",
    "    # Save both the question, final answer, and full processing to a text file\n",
    "    with open('contrastive_cot_result.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=== QUESTION ===\\n\\n\")\n",
    "        f.write(question)\n",
    "        f.write(\"\\n\\n=== FINAL ANSWER (STEP 5) ===\\n\\n\")\n",
    "        f.write(final_solution)\n",
    "        f.write(\"\\n\\n=== COMPLETE PROCESSING (FOR REFERENCE) ===\\n\\n\")\n",
    "        f.write(full_response)\n",
    "    \n",
    "    # Return only the final answer in messages, plus the original question for reference\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=final_solution)],\n",
    "        \"question\": question,\n",
    "        \"full_response\": full_response\n",
    "    }\n",
    "\n",
    "# Definition of state\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    question: Optional[str]\n",
    "    full_response: Optional[str]\n",
    "\n",
    "# Graph creation\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"generate_contrastive_cot\", generate_contrastive_cot_node)\n",
    "\n",
    "# Graph configuration\n",
    "graph_builder.set_entry_point(\"generate_contrastive_cot\")\n",
    "graph_builder.add_edge(\"generate_contrastive_cot\", END)\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "# Usage example\n",
    "inputs = {\n",
    "    \"messages\": [HumanMessage(content=\"Who was the first person to reach the South Pole, and in what year did this occur?\")],\n",
    "    \"question\": None,\n",
    "    \"full_response\": None\n",
    "}\n",
    "\n",
    "# Print the question at the beginning\n",
    "print(\"QUESTION:\")\n",
    "print(inputs[\"messages\"][0].content)\n",
    "print(\"\\nFINAL ANSWER (STEP 5):\")\n",
    "\n",
    "# Graph execution - only display Step 5\n",
    "original_question = \"\"\n",
    "for output in graph.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        if key == \"generate_contrastive_cot\":\n",
    "            messages = value['messages']\n",
    "            for message in messages:\n",
    "                if isinstance(message, AIMessage):\n",
    "                    print(message.content)\n",
    "            \n",
    "            # Store question for reference\n",
    "            if \"question\" in value:\n",
    "                original_question = value[\"question\"]\n",
    "\n",
    "# Print confirmation that results were saved\n",
    "print(\"\\n(Complete results saved in 'contrastive_cot_result.txt')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
