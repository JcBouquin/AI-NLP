{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO2V5aq6O3flsloWCd0wzDW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"faabc1472d6d4e9795a290037f90e99a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5c73d60bb36b4e819708ff0349434113","IPY_MODEL_ecf1559a2a24480796ad5b3b1465722d","IPY_MODEL_fcc03dc880ad456fbd1b0451f9eaaee0"],"layout":"IPY_MODEL_9a3b1c2ec08d44fab2f65992c9035d91"}},"5c73d60bb36b4e819708ff0349434113":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c560ea30a0d4f0783772ada91cc256b","placeholder":"​","style":"IPY_MODEL_f56129f764434e779ff0430296b9fa8b","value":"Downloading (…)ve/main/spiece.model: 100%"}},"ecf1559a2a24480796ad5b3b1465722d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fdf36fb3c9ee426ead86bae5d88bc281","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6ee4c748cf694803add3504030095382","value":791656}},"fcc03dc880ad456fbd1b0451f9eaaee0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c82da88689b4f4eb2ef0ae007b8ef48","placeholder":"​","style":"IPY_MODEL_d4b8deb61a4842058ff0553c8fc08ef1","value":" 792k/792k [00:00&lt;00:00, 1.00MB/s]"}},"9a3b1c2ec08d44fab2f65992c9035d91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c560ea30a0d4f0783772ada91cc256b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f56129f764434e779ff0430296b9fa8b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fdf36fb3c9ee426ead86bae5d88bc281":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ee4c748cf694803add3504030095382":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3c82da88689b4f4eb2ef0ae007b8ef48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4b8deb61a4842058ff0553c8fc08ef1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a7543e3d39674ddd871644c5bcccad64":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_84ae8fdddcb040b3bf08925ca3fc2edc","IPY_MODEL_204bf6e978ad456d84767a43a85b3f2b","IPY_MODEL_c0d0f62c489c4c24b40f4b375f4df256"],"layout":"IPY_MODEL_b1079b38352046a4aea76d541f69bf18"}},"84ae8fdddcb040b3bf08925ca3fc2edc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b04c429038b442acbef157c15c5f4e72","placeholder":"​","style":"IPY_MODEL_416a77b95e01485ca9e09642eff8d156","value":"Downloading (…)okenizer_config.json: 100%"}},"204bf6e978ad456d84767a43a85b3f2b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e6d8994d33d4a36b546f0236fd3afe1","max":2324,"min":0,"orientation":"horizontal","style":"IPY_MODEL_27cb17ec8faf45d68fba30b5aa36aa43","value":2324}},"c0d0f62c489c4c24b40f4b375f4df256":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9882dc11411a42fcb106d11f5e75759a","placeholder":"​","style":"IPY_MODEL_5631a073f6094aa396502a790316287c","value":" 2.32k/2.32k [00:00&lt;00:00, 75.9kB/s]"}},"b1079b38352046a4aea76d541f69bf18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b04c429038b442acbef157c15c5f4e72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"416a77b95e01485ca9e09642eff8d156":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e6d8994d33d4a36b546f0236fd3afe1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27cb17ec8faf45d68fba30b5aa36aa43":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9882dc11411a42fcb106d11f5e75759a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5631a073f6094aa396502a790316287c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qLtxRDUU0gId","executionInfo":{"status":"ok","timestamp":1683708586558,"user_tz":-120,"elapsed":21718,"user":{"displayName":"Jean-Christophe Bouquin","userId":"01239462757709491259"}},"outputId":"f9f3c919-74c8-4c69-bd2d-b7c634316668"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.11.0 (from transformers)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","source":["!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GumND4fl2auB","executionInfo":{"status":"ok","timestamp":1683708594731,"user_tz":-120,"elapsed":8176,"user":{"displayName":"Jean-Christophe Bouquin","userId":"01239462757709491259"}},"outputId":"4deed3e1-5d3f-4a11-a5b8-e0408dedb392"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"I6rWviBy2nG8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["La classe T5Tokenizer est une classe d'encodage de texte qui fait partie de la bibliothèque Hugging Face Transformers. Elle est conçue pour fonctionner avec les modèles de traitement de langage naturel basés sur l'architecture T5 (Text-to-Text Transfer Transformer). Cette classe permet de convertir des chaînes de texte en identifiants de jetons, qui peuvent être compris par les modèles T5. Les jetons sont les unités de base de la représentation du texte dans les modèles de traitement de langage naturel.\n","\n","La méthode encode de la classe T5Tokenizer prend en entrée une chaîne de texte et retourne un tensor PyTorch contenant les identifiants de jetons correspondants. La méthode peut également prendre en charge d'autres arguments optionnels pour contrôler le traitement du texte, tels que max_length, qui définit la longueur maximale de la séquence encodée, ou truncation, qui spécifie si le texte doit être tronqué si sa longueur dépasse max_length.\n","\n","La méthode encode de la classe T5Tokenizer accepte plusieurs arguments optionnels qui permettent de contrôler le processus d'encodage du texte. Voici une liste des principaux arguments que vous pouvez spécifier :\n","\n","La méthode encode de la classe T5Tokenizer accepte plusieurs arguments optionnels qui permettent de contrôler le processus d'encodage du texte. Voici une liste des principaux arguments que vous pouvez spécifier :\n","\n","**text** : la chaîne de texte à encoder (obligatoire).\n","\n","**add_special_tokens** : si True, ajoute les jetons spéciaux [CLS] et [SEP] au début et à la fin de la séquence encodée. Par défaut, c'est True.\n","\n","**padding** : si 'max_length', remplit les séquences plus courtes avec des jetons de remplissage pour qu'elles aient la même longueur que la séquence la plus longue dans le lot. Vous pouvez également spécifier 'longest' pour remplir avec la longueur de séquence la plus longue de la séquence en entrée ou False pour ne pas faire de remplissage. Par défaut, c'est False.\n","\n","**truncation** : si True, tronque les séquences qui dépassent la longueur maximale spécifiée. Par défaut, c'est False.\n","\n","**max_length** : la longueur maximale de la séquence encodée. Les séquences plus longues sont tronquées ou remplies en fonction de l'argument truncation et padding. Par défaut, c'est 512.\n","\n","return_tensors : le format de sortie de la méthode. Peut être 'pt' pour un tensor PyTorch ou 'tf' pour un tenseur TensorFlow. Par défaut, c'est None.\n","\n","Il est important de noter que les hyperparamètres peuvent varier en fonction de la classe du tokenizer et du modèle T5 utilisé. Certains modèles T5 peuvent avoir des hyperparamètres spécifiques à leur architecture. Il est donc conseillé de consulter la documentation du modèle et du tokenizer pour connaître les arguments acceptés par la méthode encode.\n","\n","\n"],"metadata":{"id":"tWGJULth20F2"}},{"cell_type":"markdown","source":["La classe T5Tokenizer hérite de la classe Tokenizer, qui est la classe de base pour tous les tokenizers de la bibliothèque Hugging Face Transformers. Voici quelques-unes des méthodes les plus couramment utilisées de la classe Tokenizer  \n","\n","**encode** : Encode une chaîne de texte en identifiants de jetons. Cette méthode retourne un tensor de PyTorch ou de TensorFlow selon l'argument return_tensors.\n","\n","**decode** : Décode une liste d'identifiants de jetons en une chaîne de texte.\n","\n","**convert_tokens_to_string** : Convertit une liste de jetons en une chaîne de texte.\n","\n","**convert_tokens_to_ids** : Convertit une liste de jetons en une liste d'identifiants de jetons.\n","\n","**convert_ids_to_tokens** : Convertit une liste d'identifiants de jetons en une liste de jetons.\n","\n","get_vocab : Renvoie le dictionnaire de vocabulaire du tokenizer, où les clés sont les jetons et les valeurs sont les identifiants de jetons.\n","\n","Il est important de noter que chaque classe de tokenizer peut avoir des méthodes spécifiques à son architecture et à son implémentation. Il est donc conseillé de consulter la documentation de la classe de tokenizer spécifique que vous utilisez pour connaître toutes les méthodes disponibles.\n","\n","\n","\n","\n","les méthodes  mentionnées ci dessus sont des méthodes de base de la classe Tokenizer, qui sont également disponibles pour le tokenizer T5Tokenizer spécifique. Toutefois, il existe également des méthodes spécifiques à la classe T5Tokenizer qui sont utilisées pour des tâches spécifiques liées à l'architecture T5.\n","\n","Voici quelques exemples de méthodes spécifiques à la classe T5Tokenizer :\n","\n","**get_special_tokens_mask** : Renvoie un tensor de 0 et 1 qui indique les jetons spéciaux [PAD], [CLS], [SEP], [MASK] et [EOD].\n","\n","**add_tokens** : Ajoute une liste de jetons à la liste de vocabulaire existante.\n","\n","**add_special_tokens** : Ajoute les jetons spéciaux [PAD], [CLS], [SEP], [MASK] et [EOD] à la liste de vocabulaire existante.\n","\n","**get_vocab_size** : Renvoie la taille du vocabulaire, c'est-à-dire le nombre de jetons uniques dans la liste de vocabulaire.\n","\n","Il est important de noter que chaque classe de tokenizer peut avoir des méthodes spécifiques à son architecture et à son implémentation. Il est donc conseillé de consulter la documentation de la classe de tokenizer spécifique que vous utilisez pour connaître toutes les méthodes disponibles."],"metadata":{"id":"tnFWsdSY7udl"}},{"cell_type":"markdown","source":["enfin il faut savoir qu'en plus de T5Tokenizer et T5ForConditionalGeneration, il existe plusieurs autres classes liées à T5 que vous pouvez importer depuis la bibliothèque Hugging Face Transformers. Voici quelques-unes des classes les plus couramment utilisées :\n","\n","**T5Config** : la classe de configuration pour les modèles T5. Elle définit les hyperparamètres pour l'architecture du modèle, tels que la taille du vocabulaire, la taille des couches, le nombre de têtes d'attention, etc.\n","**T5EncoderModel** : une version du modèle T5 qui ne génère pas de texte mais produit des représentations de texte encodées.\n","**T5DecoderModel** : une version du modèle T5 qui ne prend pas de texte en entrée mais génère du texte à partir de représentations encodées.\n","T5Model : une classe générique pour les modèles T5 qui peut être utilisée comme encodeur ou décodeur, ou les deux.\n","**T5ForConditionalGeneration** : la classe de modèle T5 qui est utilisée pour la génération de texte conditionnelle.\n","Il est important de noter que chaque classe T5 a ses propres arguments d'initialisation et méthodes spécifiques. Il est donc recommandé de consulter la documentation officielle de Hugging Face Transformers pour en savoir plus sur les différentes classes disponibles et leurs fonctionnalités."],"metadata":{"id":"tS-fbkx_-Kme"}},{"cell_type":"code","source":["#Voici un exemple d'utilisation de la méthode encode : ici le model est le \n","\n","from transformers import T5Tokenizer\n","\n","tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n","texte = \"Bonjour, comment ça va ?\"\n","identifiants_jetons = tokenizer.encode(texte)\n","print(identifiants_jetons)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":98,"referenced_widgets":["faabc1472d6d4e9795a290037f90e99a","5c73d60bb36b4e819708ff0349434113","ecf1559a2a24480796ad5b3b1465722d","fcc03dc880ad456fbd1b0451f9eaaee0","9a3b1c2ec08d44fab2f65992c9035d91","5c560ea30a0d4f0783772ada91cc256b","f56129f764434e779ff0430296b9fa8b","fdf36fb3c9ee426ead86bae5d88bc281","6ee4c748cf694803add3504030095382","3c82da88689b4f4eb2ef0ae007b8ef48","d4b8deb61a4842058ff0553c8fc08ef1","a7543e3d39674ddd871644c5bcccad64","84ae8fdddcb040b3bf08925ca3fc2edc","204bf6e978ad456d84767a43a85b3f2b","c0d0f62c489c4c24b40f4b375f4df256","b1079b38352046a4aea76d541f69bf18","b04c429038b442acbef157c15c5f4e72","416a77b95e01485ca9e09642eff8d156","7e6d8994d33d4a36b546f0236fd3afe1","27cb17ec8faf45d68fba30b5aa36aa43","9882dc11411a42fcb106d11f5e75759a","5631a073f6094aa396502a790316287c"]},"id":"IV3ZvDlZ2_Rm","executionInfo":{"status":"ok","timestamp":1683708713582,"user_tz":-120,"elapsed":2745,"user":{"displayName":"Jean-Christophe Bouquin","userId":"01239462757709491259"}},"outputId":"30227053-27e7-483e-e341-7abb2a7dcb87"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"faabc1472d6d4e9795a290037f90e99a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7543e3d39674ddd871644c5bcccad64"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[21845, 6, 1670, 3664, 409, 3, 58, 1]\n"]}]},{"cell_type":"code","source":["from transformers import T5Tokenizer, T5ForConditionalGeneration\n","tokenizer = T5Tokenizer.from_pretrained(\"plguillou/t5-base-fr-sum-cnndm\")\n","model = T5ForConditionalGeneration.from_pretrained(\"plguillou/t5-base-fr-sum-cnndm\")"],"metadata":{"id":"t6bdqfOZ52pl","executionInfo":{"status":"ok","timestamp":1683709493974,"user_tz":-120,"elapsed":10061,"user":{"displayName":"Jean-Christophe Bouquin","userId":"01239462757709491259"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["La méthode **generate** est une méthode du modèle **T5ForConditionalGeneration** qui permet de générer une séquence de texte à partir d'une séquence d'entrée. Elle utilise le modèle T5 entraîné pour effectuer une génération de texte en fonction de la séquence d'entrée.\n","\n","La méthode generate prend en entrée un tensor contenant les identifiants de jetons de la séquence d'entrée et retourne un tensor contenant les identifiants de jetons de la séquence générée. "],"metadata":{"id":"sO_FmIB54qpU"}},{"cell_type":"code","source":["# Exemple de texte à résumer\n","texte = \"Le Mont-Saint-Michel est un îlot rocheux granitique d'environ un kilomètre carré, situé à l'embouchure du fleuve Couesnon dans le département de la Manche en Normandie. Il est célèbre pour sa baie, l'une des plus grandes marées d'Europe continentale et sa silhouette gothique emblématique de l'abbaye du Mont-Saint-Michel.\"\n","\n","# Encode le texte pour obtenir les identifiants de jetons\n","inputs = tokenizer.encode(texte, return_tensors=\"pt\", max_length=512, truncation=True)\n","\n","# Génère le résumé avec le modèle\n","summary_ids = model.generate(inputs, num_beams=4, length_penalty=2.0, max_length=150, min_length=40, no_repeat_ngram_size=3)\n","\n","# Décode les identifiants de jetons en texte\n","summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","\n","print(\"Résumé : \", summary)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iVS73Gnk2i57","executionInfo":{"status":"ok","timestamp":1683710947091,"user_tz":-120,"elapsed":26666,"user":{"displayName":"Jean-Christophe Bouquin","userId":"01239462757709491259"}},"outputId":"a54e94be-fa9c-4799-a889-c41d64f5cb25"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Résumé :  Le Mont-Saint-Michel est un îlot rocheux granitique d'environ un kilomètre carré. Il est célèbre pour sa baie, l'une des plus grandes marées en Europe continentale. L'abbaye du Mont Saint-Michel a une silhouette gothique emblématique.\n"]}]},{"cell_type":"markdown","source":[" Dans cet exemple, la méthode **generate** est appelée sur le modèle **T5ForConditionalGeneration** avec la séquence d'entrée encodée inputs. Les arguments **num_beams**, **length_penalty**, **max_length**, **min_length** et no_repeat_ngram_size sont des hyperparamètres du modèle qui contrôlent la génération du texte. Vous pouvez ajuster ces hyperparamètres en fonction de vos besoins pour obtenir des résultats de génération de texte différents.\n","\n","Il est important de noter que la méthode generate peut être utilisée avec différents modèles de la bibliothèque Hugging Face Transformers, pas seulement avec T5ForConditionalGeneration. Toutefois, les arguments de la méthode et leur signification peuvent varier en fonction du modèle que vous utilisez."],"metadata":{"id":"Hf5kZUbQ9LQ0"}},{"cell_type":"code","source":[],"metadata":{"id":"IDPQPn84-zbv"},"execution_count":null,"outputs":[]}]}