{
  "doc-e38bb9258f55d121381a68b77dbad24d": {
    "status": "processed",
    "chunks_count": 11,
    "chunks_list": [
      "chunk-dc4869b2865a9a053d992bbbdd8111e3",
      "chunk-5670b97cac4fa5638ba7afec771b74a8",
      "chunk-a4bfe3834a3a1fae1b473b574f4f8b49",
      "chunk-e9f27034d9712faa74c3195b10f7b76e",
      "chunk-a2f1a956b437fd5cdafc179f99aba025",
      "chunk-292b2c4e27f94c258f6dfc74c228920f",
      "chunk-9ab50d3a732fc9ec76f98f4af89f1844",
      "chunk-cb4558101a7d0732e0b0f406c610255c",
      "chunk-e721c558783dbd23774614190d304ec4",
      "chunk-fd676ea25004fcc9cfc7f86a04f71fad",
      "chunk-2e88d22e757b745c1d8aafe1aef24015"
    ],
    "content_summary": "Retrieval-Augmented Generation (RAG) systems enhance large language models (LLMs) by integrating external knowledge sources, enabling more accurate and contextually relevant responses tailored to user needs. However, existing RAG systems have signifi...",
    "content_length": 49201,
    "created_at": "2025-12-14T12:04:20.920988+00:00",
    "updated_at": "2025-12-14T12:13:53.254128+00:00",
    "file_path": "unknown_source",
    "track_id": "insert_20251214_130420_9c133587",
    "metadata": {
      "processing_start_time": 1765714242,
      "processing_end_time": 1765714433
    }
  }
}