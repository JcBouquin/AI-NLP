# üìã Exemple : Gestionnaire de T√¢ches avec DeepMCPAgent

Cet exemple d√©montre comment utiliser **DeepMCPAgent** pour cr√©er un agent IA qui g√®re des t√¢ches via un serveur MCP.

## üéØ Ce que cet exemple montre

- ‚úÖ Cr√©ation d'un serveur MCP avec plusieurs outils personnalis√©s
- ‚úÖ D√©couverte automatique des outils par DeepMCPAgent
- ‚úÖ Utilisation d'un agent LangChain avec ces outils
- ‚úÖ Mode d√©mo automatique et mode interactif
- ‚úÖ Tra√ßage des appels d'outils en temps r√©el

## üöÄ Installation

Assurez-vous d'avoir install√© les d√©pendances :

```bash
pip install "deepmcpagent[deep,examples]"
pip install python-dotenv langchain-openai rich
```

## üìù Configuration

Cr√©ez un fichier `.env` √† la racine du projet avec votre cl√© API :

```env
OPENAI_API_KEY=votre_cle_openai_ici
```

> üí° **Astuce** : Vous pouvez utiliser d'autres mod√®les (Anthropic, Ollama, etc.) en modifiant `example_task_manager.py`

## ‚ñ∂Ô∏è Utilisation

### √âtape 1 : D√©marrer le serveur MCP

Dans un **premier terminal**, lancez le serveur MCP :

```bash
python examples/servers/task_manager_server.py
```

Vous devriez voir :
```
üöÄ D√©marrage du serveur TaskManager MCP sur http://127.0.0.1:8001/mcp
üìã Outils disponibles: create_task, list_tasks, update_task, delete_task, get_task_stats
```

**‚ö†Ô∏è Important** : Gardez ce terminal ouvert pendant l'ex√©cution de l'exemple !

### √âtape 2 : Lancer l'exemple

Dans un **second terminal**, lancez l'exemple :

```bash
python examples/example_task_manager.py
```

## üéÆ Modes d'utilisation

### Mode D√©mo (par d√©faut)

L'exemple ex√©cute automatiquement plusieurs requ√™tes pour d√©montrer les capacit√©s :

1. Cr√©ation de 3 t√¢ches avec diff√©rentes priorit√©s
2. Liste des t√¢ches en attente
3. Mise √† jour d'une t√¢che (marquer comme "en cours")
4. Affichage des statistiques

### Mode Interactif

Choisissez `interactive` quand on vous le demande pour dialoguer avec l'agent :

```
Choisissez un mode [interactive/demo]: interactive
```

Vous pouvez alors poser des questions comme :
- "Cr√©e-moi une t√¢che pour pr√©parer ma pr√©sentation"
- "Quelles sont mes t√¢ches en cours ?"
- "Marque la t√¢che #1 comme termin√©e"
- "Supprime toutes les t√¢ches termin√©es"

## üõ†Ô∏è Outils disponibles

Le serveur MCP expose 5 outils :

| Outil | Description |
|-------|-------------|
| `create_task` | Cr√©er une nouvelle t√¢che avec titre, description et priorit√© |
| `list_tasks` | Lister les t√¢ches (avec filtres optionnels) |
| `update_task` | Modifier une t√¢che existante |
| `delete_task` | Supprimer une t√¢che |
| `get_task_stats` | Obtenir des statistiques sur toutes les t√¢ches |

## üìä Ce que vous verrez

- **Outils d√©couverts** : Tableau montrant tous les outils MCP disponibles
- **Appels d'outils** : Chaque utilisation d'un outil est affich√©e en temps r√©el (gr√¢ce √† `trace_tools=True`)
- **R√©ponses de l'agent** : Les r√©ponses de l'IA avec les r√©sultats des op√©rations

## üîç Comprendre le code

### Serveur MCP (`task_manager_server.py`)

- Utilise **FastMCP** pour cr√©er un serveur HTTP/SSE
- Expose des fonctions Python comme outils MCP via `@mcp.tool()`
- Stocke les donn√©es en m√©moire (base de donn√©es simple)

### Agent (`example_task_manager.py`)

- **HTTPServerSpec** : Configure la connexion au serveur MCP
- **build_deep_agent()** : Construit l'agent avec d√©couverte automatique des outils
- **LangChain ChatOpenAI** : Mod√®le LLM utilis√© (facilement rempla√ßable)
- **trace_tools=True** : Active l'affichage des appels d'outils pour le debugging

## üí° Personnalisation

### Changer le mod√®le LLM

Dans `example_task_manager.py`, remplacez :

```python
from langchain_openai import ChatOpenAI
model = ChatOpenAI(model="gpt-4o-mini")
```

Par exemple, pour Anthropic :

```python
from langchain_anthropic import ChatAnthropic
model = ChatAnthropic(model="claude-3-5-sonnet-20241022")
```

### Ajouter des outils au serveur

Dans `task_manager_server.py`, ajoutez simplement :

```python
@mcp.tool()
def mon_nouvel_outil(param1: str, param2: int) -> dict:
    """Description de ce que fait l'outil."""
    # Votre logique ici
    return {"result": "..."}
```

L'agent d√©couvrira automatiquement le nouvel outil !

### Changer le port

Modifiez le port dans les deux fichiers :
- **Serveur** : `mcp.run(..., port=8001, ...)`
- **Client** : `url="http://127.0.0.1:8001/mcp"`

## üêõ D√©pannage

### Erreur : "Failed to initialize agent"
- ‚úÖ V√©rifiez que le serveur MCP est d√©marr√© sur le bon port
- ‚úÖ V√©rifiez l'URL dans `HTTPServerSpec`

### Erreur : "OPENAI_API_KEY not found"
- ‚úÖ Cr√©ez un fichier `.env` avec votre cl√© API
- ‚úÖ Ou exportez la variable d'environnement : `export OPENAI_API_KEY=...`

### Aucun outil d√©couvert
- ‚úÖ V√©rifiez que le serveur est accessible : `curl http://127.0.0.1:8001/mcp`
- ‚úÖ V√©rifiez les logs du serveur pour les erreurs

## üìö Pour aller plus loin

- [Documentation DeepMCPAgent](https://cryxnet.github.io/DeepMCPAgent/)
- [Documentation FastMCP](https://gofastmcp.com/)
- [Model Context Protocol (MCP)](https://modelcontextprotocol.io/)

