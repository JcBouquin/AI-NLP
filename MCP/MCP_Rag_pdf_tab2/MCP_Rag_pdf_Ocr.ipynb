{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabula-py in c:\\users\\kosmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: camelot-py in c:\\users\\kosmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\kosmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: pandas in c:\\users\\kosmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>1.24.4 in c:\\users\\kosmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tabula-py) (1.26.4)\n",
      "Requirement already satisfied: distro in c:\\users\\kosmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tabula-py) (1.9.0)\n",
      "Requirement already satisfied: click>=8.0.1 in c:\\users\\kosmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from camelot-py) (8.1.7)\n",
      "Requirement already satisfied: chardet>=5.1.0 in c:\\users\\kosmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from camelot-py) (5.2.0)\n",
      "Requirement already satisfied: openpyxl>=3.1.0 in c:\\users\\kosmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from camelot-py) (3.1.5)\n",
      "Requirement already satisfied: pdfminer-six>=20240706 in c:\\users\\kosmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from camelot-py) (20250327)\n",
      "Requirement already satisfied: pypdf<6.0,>=4.0 in c:\\users\\kosmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from camelot-py) (4.2.0)\n",
      "Requirement already satisfied: tabulate>=0.9.0 in c:\\users\\kosmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from camelot-py) (0.9.0)\n",
      "Requirement already satisfied: opencv-python-headless>=4.7.0.68 in c:\\users\\kosmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from camelot-py) (4.11.0.86)\n",
      "Requirement already satisfied: pypdfium2>=4 in c:\\users\\kosmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from camelot-py) (4.30.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kosmo\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kosmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kosmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\kosmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click>=8.0.1->camelot-py) (0.4.6)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\kosmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openpyxl>=3.1.0->camelot-py) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\kosmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pdfminer-six>=20240706->camelot-py) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\kosmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pdfminer-six>=20240706->camelot-py) (43.0.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kosmo\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\kosmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cryptography>=36.0.0->pdfminer-six>=20240706->camelot-py) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\kosmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer-six>=20240706->camelot-py) (2.22)\n"
     ]
    }
   ],
   "source": [
    "# Dans un terminal ou une cellule de notebook\n",
    "! pip install tabula-py camelot-py opencv-python pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytesseract\n",
      "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pdf2image\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\kosmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\kosmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytesseract) (24.1)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\kosmo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytesseract) (10.3.0)\n",
      "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
      "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pytesseract, pdf2image\n",
      "Successfully installed pdf2image-1.17.0 pytesseract-0.3.13\n"
     ]
    }
   ],
   "source": [
    "! pip install pytesseract pdf2image PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Traitement du PDF 1/1: C:\\Users\\kosmo\\pycode\\MCP_Rag_pdf_tab2\\sdata201635.pdf\n",
      "Extraction des tableaux de C:\\Users\\kosmo\\pycode\\MCP_Rag_pdf_tab2\\sdata201635.pdf...\n",
      "Utilisation de tabula...\n",
      "Erreur avec tabula: `java` command is not found from this Python process.Please ensure Java is installed and PATH is set for `java`\n",
      "\n",
      "Utilisation de camelot (mode lattice)...\n",
      "Camelot (lattice) a trouvé 7 tableaux.\n",
      "Tableau sauvegardé: tableaux_extraits\\sdata201635\\camelot_lattice_table_0.csv\n",
      "Tableau sauvegardé: tableaux_extraits\\sdata201635\\camelot_lattice_table_1.csv\n",
      "Tableau sauvegardé: tableaux_extraits\\sdata201635\\camelot_lattice_table_2.csv\n",
      "Tableau sauvegardé: tableaux_extraits\\sdata201635\\camelot_lattice_table_3.csv\n",
      "Tableau sauvegardé: tableaux_extraits\\sdata201635\\camelot_lattice_table_4.csv\n",
      "Tableau sauvegardé: tableaux_extraits\\sdata201635\\camelot_lattice_table_5.csv\n",
      "Tableau sauvegardé: tableaux_extraits\\sdata201635\\camelot_lattice_table_6.csv\n",
      "\n",
      "Utilisation de camelot (mode stream)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kosmo\\AppData\\Local\\Temp\\ipykernel_20348\\2751630715.py:59: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = table.df.applymap(lambda x: clean_cid_markers(str(x)) if isinstance(x, str) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camelot (stream) a trouvé 14 tableaux.\n",
      "Tableau sauvegardé: tableaux_extraits\\sdata201635\\camelot_stream_table_0.csv\n",
      "Tableau sauvegardé: tableaux_extraits\\sdata201635\\camelot_stream_table_1.csv\n",
      "Tableau sauvegardé: tableaux_extraits\\sdata201635\\camelot_stream_table_2.csv\n",
      "Tableau sauvegardé: tableaux_extraits\\sdata201635\\camelot_stream_table_3.csv\n",
      "Tableau sauvegardé: tableaux_extraits\\sdata201635\\camelot_stream_table_4.csv\n",
      "Tableau sauvegardé: tableaux_extraits\\sdata201635\\camelot_stream_table_5.csv\n",
      "Tableau sauvegardé: tableaux_extraits\\sdata201635\\camelot_stream_table_6.csv\n",
      "Tableau sauvegardé: tableaux_extraits\\sdata201635\\camelot_stream_table_7.csv\n",
      "Tableau sauvegardé: tableaux_extraits\\sdata201635\\camelot_stream_table_8.csv\n",
      "Tableau sauvegardé: tableaux_extraits\\sdata201635\\camelot_stream_table_9.csv\n",
      "Tableau sauvegardé: tableaux_extraits\\sdata201635\\camelot_stream_table_10.csv\n",
      "Tableau sauvegardé: tableaux_extraits\\sdata201635\\camelot_stream_table_11.csv\n",
      "Tableau sauvegardé: tableaux_extraits\\sdata201635\\camelot_stream_table_12.csv\n",
      "Tableau sauvegardé: tableaux_extraits\\sdata201635\\camelot_stream_table_13.csv\n",
      "\n",
      "Utilisation de PyPDF2 pour extraction de texte...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kosmo\\AppData\\Local\\Temp\\ipykernel_20348\\2751630715.py:76: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = table.df.applymap(lambda x: clean_cid_markers(str(x)) if isinstance(x, str) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte brut sauvegardé: tableaux_extraits\\sdata201635\\pdf_text_extraction.txt\n",
      "\n",
      "Utilisation de l'OCR (Tesseract)...\n",
      "Erreur avec OCR: Unable to get page count. Is poppler installed and in PATH?\n",
      "\n",
      "Extraction terminée. Vérifiez le dossier tableaux_extraits\\sdata201635\n",
      "Aperçu des 21 fichiers CSV extraits:\n",
      "\n",
      "==================================================\n",
      "Fichier: camelot_lattice_table_0.csv\n",
      "Dimensions: 1 lignes × 2 colonnes\n",
      "--------------------------------------------------\n",
      "                                                   0  \\\n",
      "0  Design Type(s)\\nMeasurement Type(s)\\nTechnolog...   \n",
      "\n",
      "                                                   1  \n",
      "0  data integration objective\\n\\n\\n\\nDemographics...  \n",
      "\n",
      "==================================================\n",
      "Fichier: camelot_lattice_table_1.csv\n",
      "Dimensions: 3 lignes × 3 colonnes\n",
      "--------------------------------------------------\n",
      "    0                     1   2\n",
      "0 NaN                   NaN NaN\n",
      "1 NaN  MIMIC-III\\n Database NaN\n",
      "2 NaN                   NaN NaN\n",
      "\n",
      "==================================================\n",
      "Fichier: camelot_lattice_table_2.csv\n",
      "Dimensions: 13 lignes × 1 colonnes\n",
      "--------------------------------------------------\n",
      "                                                   0\n",
      "0  Hospital\\nICU\\nMICU\\nSICU\\n CCU \\n CSRU\\n NICU...\n",
      "1                                                NaN\n",
      "2                                                NaN\n",
      "\n",
      "==================================================\n",
      "Fichier: camelot_lattice_table_3.csv\n",
      "Dimensions: 10 lignes × 7 colonnes\n",
      "--------------------------------------------------\n",
      "                                                   0              1  \\\n",
      "0                                 Critical care unit            CCU   \n",
      "1   Distinct patients, no. (% of\\ntotal\\nadmissions)  5,674 (14.7%)   \n",
      "2  Hospital admissions, no. (% of\\ntotal\\nadmissi...  7,258 (14.6%)   \n",
      "\n",
      "               2               3              4              5              6  \n",
      "0           CSRU            MICU           SICU          TSICU          Total  \n",
      "1  8,091 (20.9%)  13,649 (35.4%)  6,372 (16.5%)  4,811 (12.5%)  38,597 (100%)  \n",
      "2  9,156 (18.4%)  19,770 (39.7%)  8,110 (16.3%)  5,491 (11.0%)  49,785 (100%)  \n",
      "\n",
      "==================================================\n",
      "Fichier: camelot_lattice_table_4.csv\n",
      "Dimensions: 12 lignes × 7 colonnes\n",
      "--------------------------------------------------\n",
      "                                                   0  \\\n",
      "0                                 Critical care unit   \n",
      "1  Infectious and parasitic diseases,\\ni.e.,\\nsep...   \n",
      "2  Neoplasms of digestive organs and\\nintrathorac...   \n",
      "\n",
      "                             1                             2  \\\n",
      "0  CCU stays, No.\\n(% by unit)  CSRU stays, No.\\n(% by unit)   \n",
      "1                   305 (4.2%)                     72 (0.8%)   \n",
      "2                   126 (1.8%)                    287 (3.2%)   \n",
      "\n",
      "                              3                             4  \\\n",
      "0  MICU stays, No.\\n(% by unit)  SICU stays, No.\\n(% by unit)   \n",
      "1                 3,229 (16.7%)                    448 (5.6%)   \n",
      "2                  1,415 (7.3%)                 1,225 (15.3%)   \n",
      "\n",
      "                               5                              6  \n",
      "0  TSICU stays, No.\\n(% by unit)  Total stays, No.\\n(% by unit)  \n",
      "1                     152 (2.8%)                   4,206 (8.6%)  \n",
      "2                     466 (8.6%)                   3,519 (7.2%)  \n",
      "\n",
      "==================================================\n",
      "Fichier: camelot_lattice_table_5.csv\n",
      "Dimensions: 10 lignes × 2 colonnes\n",
      "--------------------------------------------------\n",
      "               0                                                  1\n",
      "0  Class of data                                        Description\n",
      "1        Billing  Coded data recorded primarily for billing and ...\n",
      "2    Descriptive  Demographic detail, admission and discharge ti...\n",
      "\n",
      "==================================================\n",
      "Fichier: camelot_lattice_table_6.csv\n",
      "Dimensions: 27 lignes × 2 colonnes\n",
      "--------------------------------------------------\n",
      "            0                                                  1\n",
      "0  Table name                                        Description\n",
      "1  ADMISSIONS  Every unique hospitalization for each patient\\...\n",
      "2     CALLOUT  Information regarding when a patient was clear...\n",
      "\n",
      "==================================================\n",
      "Fichier: camelot_stream_table_0.csv\n",
      "Dimensions: 19 lignes × 2 colonnes\n",
      "--------------------------------------------------\n",
      "                    0                                     1\n",
      "0                 NaN                                   NaN\n",
      "1                OPEN  Data Descriptor: MIMIC-III, a freely\n",
      "2  SUBJECT CATEGORIES                                   NaN\n",
      "\n",
      "==================================================\n",
      "Fichier: camelot_stream_table_1.csv\n",
      "Dimensions: 15 lignes × 5 colonnes\n",
      "--------------------------------------------------\n",
      "                                                   0  \\\n",
      "0  more. The database supports applications inclu...   \n",
      "1      initiatives, and higher education coursework.   \n",
      "2                                     Design Type(s)   \n",
      "\n",
      "                            1    2    3    4  \n",
      "0                         NaN  NaN  NaN  NaN  \n",
      "1                         NaN  NaN  NaN  NaN  \n",
      "2  data integration objective  NaN  NaN  NaN  \n",
      "\n",
      "==================================================\n",
      "Fichier: camelot_stream_table_10.csv\n",
      "Dimensions: 29 lignes × 2 colonnes\n",
      "--------------------------------------------------\n",
      "            0                                                  1\n",
      "0  Table name                                        Description\n",
      "1  ADMISSIONS  Every unique hospitalization for each patient\\...\n",
      "2     CALLOUT  Information regarding when a patient was clear...\n",
      "\n",
      "==================================================\n",
      "Fichier: camelot_stream_table_11.csv\n",
      "Dimensions: 30 lignes × 1 colonnes\n",
      "--------------------------------------------------\n",
      "                                                   0\n",
      "0  implications of blood pressure monitoring tech...\n",
      "1                                        notes10–13.\n",
      "2  A series of\\n'datathons' have been held alongs...\n",
      "\n",
      "==================================================\n",
      "Fichier: camelot_stream_table_12.csv\n",
      "Dimensions: 28 lignes × 1 colonnes\n",
      "--------------------------------------------------\n",
      "                                                   0\n",
      "0  these\\ncommon models may help\\nto\\nfacilitate\\...\n",
      "1  datasets and to enable the application of gene...\n",
      "2  standardized clinical ontologies are also unde...\n",
      "\n",
      "==================================================\n",
      "Fichier: camelot_stream_table_13.csv\n",
      "Dimensions: 11 lignes × 1 colonnes\n",
      "--------------------------------------------------\n",
      "                                                   0\n",
      "0                            Additional\\nInformation\n",
      "1  Competing ﬁnancial\\ninterests: The authors dec...\n",
      "2  How to cite this article:\\nJohnson, A. E. W. e...\n",
      "\n",
      "==================================================\n",
      "Fichier: camelot_stream_table_2.csv\n",
      "Dimensions: 23 lignes × 1 colonnes\n",
      "--------------------------------------------------\n",
      "                                                   0\n",
      "0                               Background & Summary\n",
      "1  In recent years there has been a concerted mov...\n",
      "2  hospitals.\\nIn the US,\\nfor\\nexample,\\nthe num...\n",
      "\n",
      "==================================================\n",
      "Fichier: camelot_stream_table_3.csv\n",
      "Dimensions: 35 lignes × 2 colonnes\n",
      "--------------------------------------------------\n",
      "                                                   0  \\\n",
      "0  ● the dataset spans more than a decade, with d...   \n",
      "1                                                NaN   \n",
      "2                                  around the world.   \n",
      "\n",
      "                                                   1  \n",
      "0                           individual patient care;  \n",
      "1  ● analysis is unrestricted once a data use agr...  \n",
      "2                                                NaN  \n",
      "\n",
      "==================================================\n",
      "Fichier: camelot_stream_table_4.csv\n",
      "Dimensions: 37 lignes × 1 colonnes\n",
      "--------------------------------------------------\n",
      "                                                   0\n",
      "0                            Patient characteristics\n",
      "1  MIMIC-III\\ncontains\\ndata\\nassociated with\\n53...\n",
      "2  (aged\\n16\\nyears\\nor\\nabove)\\nadmitted\\nto\\ncr...\n",
      "\n",
      "==================================================\n",
      "Fichier: camelot_stream_table_5.csv\n",
      "Dimensions: 17 lignes × 7 colonnes\n",
      "--------------------------------------------------\n",
      "                                                   0    1    2    3    4    5  \\\n",
      "0  ● archives from critical care information syst...  NaN  NaN  NaN  NaN  NaN   \n",
      "1     ● hospital electronic health record databases.  NaN  NaN  NaN  NaN  NaN   \n",
      "2  ● Social Security Administration Death Master ...  NaN  NaN  NaN  NaN  NaN   \n",
      "\n",
      "     6  \n",
      "0  NaN  \n",
      "1  NaN  \n",
      "2  NaN  \n",
      "\n",
      "==================================================\n",
      "Fichier: camelot_stream_table_6.csv\n",
      "Dimensions: 28 lignes × 7 colonnes\n",
      "--------------------------------------------------\n",
      "                                           0               1                2  \\\n",
      "0                         Critical care unit  CCU stays, No.  CSRU stays, No.   \n",
      "1                                        NaN     (% by unit)      (% by unit)   \n",
      "2  Infectious and parasitic diseases,\\ni.e.,      305 (4.2%)        72 (0.8%)   \n",
      "\n",
      "                 3                4                 5                 6  \n",
      "0  MICU stays, No.  SICU stays, No.  TSICU stays, No.  Total stays, No.  \n",
      "1      (% by unit)      (% by unit)       (% by unit)       (% by unit)  \n",
      "2    3,229 (16.7%)       448 (5.6%)        152 (2.8%)      4,206 (8.6%)  \n",
      "\n",
      "==================================================\n",
      "Fichier: camelot_stream_table_7.csv\n",
      "Dimensions: 20 lignes × 9 colonnes\n",
      "--------------------------------------------------\n",
      "                       0          1         2    3         4    5         6  \\\n",
      "0  www.nature.com/sdata/        NaN       NaN  NaN       NaN  NaN       NaN   \n",
      "1            Code status  Full code       NaN  NaN       NaN  NaN       NaN   \n",
      "2                    NaN   Oriented  Oriented  NaN  Oriented  NaN  Confused   \n",
      "\n",
      "          7                        8  \n",
      "0       NaN                      NaN  \n",
      "1       NaN         Comfort measures  \n",
      "2  Confused  Incomprehensible sounds  \n",
      "\n",
      "==================================================\n",
      "Fichier: camelot_stream_table_8.csv\n",
      "Dimensions: 25 lignes × 2 colonnes\n",
      "--------------------------------------------------\n",
      "     0                                                  1\n",
      "0  0.0                             60\\n10\\n30\\n40\\n50\\n20\n",
      "1  NaN  Time after admission to the intensive care uni...\n",
      "2  NaN  Figure 2.\\nSample data for a single patient st...\n",
      "\n",
      "==================================================\n",
      "Fichier: camelot_stream_table_9.csv\n",
      "Dimensions: 58 lignes × 1 colonnes\n",
      "--------------------------------------------------\n",
      "                                                   0\n",
      "0                                    Deidentiﬁcation\n",
      "1  Before data was incorporated into the MIMIC-II...\n",
      "2  Health Insurance Portability and Accountabilit...\n",
      "\n",
      "Aperçu des 1 fichiers texte extraits:\n",
      "\n",
      "==================================================\n",
      "Fichier: pdf_text_extraction.txt\n",
      "--------------------------------------------------\n",
      "\n",
      "--- PAGE 1 ---\n",
      "Data Descriptor: MIMIC-III, a freely\n",
      "accessible critical care database\n",
      "Alistair E.W. Johnson1,*, Tom J. Pollard1,*, Lu Shen2, Li-wei H. Lehman1, Mengling Feng1,3,\n",
      "Mohammad Ghassemi1, Benjamin Moody1, Peter Szolovits4, Leo Anthony Celi1,2&\n",
      "Roger G. Mark1,2\n",
      "MIMIC-III ( ‘Medical Information Mart for Intensive Care ’) is a large, single-center database comprising\n",
      "information relating to patients admitted to critical care units at a large tertiary care hospital. Data includesvital sig...\n",
      "\n",
      "[texte tronqué]\n",
      "\n",
      "Post-traitement des extractions...\n",
      "Meilleure extraction CSV identifiée: camelot_stream_table_6.csv\n",
      "Table traitée sauvegardée dans: tableaux_extraits\\sdata201635\\processed_tables.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tabula\n",
    "import pandas as pd\n",
    "import camelot\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import PyPDF2\n",
    "import re\n",
    "\n",
    "def clean_cid_markers(text):\n",
    "    \"\"\"Nettoie les marqueurs CID des textes extraits des PDFs\"\"\"\n",
    "    return re.sub(r'\\(cid:\\d+\\)', '', text)\n",
    "\n",
    "def extract_pdf_tables(pdf_path: str, output_dir: str = \"extracted_tables\"):\n",
    "    \"\"\"\n",
    "    Extract tables from a PDF file using multiple libraries for best results.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(f\"Erreur: Fichier non trouvé: {pdf_path}\")\n",
    "        return\n",
    "    \n",
    "    # Créer le répertoire de sortie s'il n'existe pas\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Extraction des tableaux de {pdf_path}...\")\n",
    "    \n",
    "    # 1. Essayer avec tabula\n",
    "    try:\n",
    "        print(\"Utilisation de tabula...\")\n",
    "        tabula_tables = tabula.read_pdf(pdf_path, pages='all', multiple_tables=True)\n",
    "        \n",
    "        if tabula_tables:\n",
    "            print(f\"Tabula a trouvé {len(tabula_tables)} tableaux.\")\n",
    "            \n",
    "            # Sauvegarder chaque tableau\n",
    "            for i, df in enumerate(tabula_tables):\n",
    "                # Nettoyer les données\n",
    "                df = df.applymap(lambda x: clean_cid_markers(str(x)) if isinstance(x, str) else x)\n",
    "                \n",
    "                output_path = os.path.join(output_dir, f\"tabula_table_{i}.csv\")\n",
    "                df.to_csv(output_path, index=False)\n",
    "                print(f\"Tableau sauvegardé: {output_path}\")\n",
    "        else:\n",
    "            print(\"Tabula n'a trouvé aucun tableau.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur avec tabula: {str(e)}\")\n",
    "    \n",
    "    # 2. Essayer avec camelot avec différentes saveurs\n",
    "    try:\n",
    "        print(\"\\nUtilisation de camelot (mode lattice)...\")\n",
    "        camelot_tables_lattice = camelot.read_pdf(pdf_path, pages='all', flavor='lattice')\n",
    "        \n",
    "        if len(camelot_tables_lattice) > 0:\n",
    "            print(f\"Camelot (lattice) a trouvé {len(camelot_tables_lattice)} tableaux.\")\n",
    "            \n",
    "            # Sauvegarder chaque tableau\n",
    "            for i, table in enumerate(camelot_tables_lattice):\n",
    "                # Nettoyer les données\n",
    "                df = table.df.applymap(lambda x: clean_cid_markers(str(x)) if isinstance(x, str) else x)\n",
    "                \n",
    "                output_path = os.path.join(output_dir, f\"camelot_lattice_table_{i}.csv\")\n",
    "                df.to_csv(output_path, index=False)\n",
    "                print(f\"Tableau sauvegardé: {output_path}\")\n",
    "        else:\n",
    "            print(\"Camelot (lattice) n'a trouvé aucun tableau.\")\n",
    "        \n",
    "        print(\"\\nUtilisation de camelot (mode stream)...\")\n",
    "        camelot_tables_stream = camelot.read_pdf(pdf_path, pages='all', flavor='stream')\n",
    "        \n",
    "        if len(camelot_tables_stream) > 0:\n",
    "            print(f\"Camelot (stream) a trouvé {len(camelot_tables_stream)} tableaux.\")\n",
    "            \n",
    "            # Sauvegarder chaque tableau\n",
    "            for i, table in enumerate(camelot_tables_stream):\n",
    "                # Nettoyer les données\n",
    "                df = table.df.applymap(lambda x: clean_cid_markers(str(x)) if isinstance(x, str) else x)\n",
    "                \n",
    "                output_path = os.path.join(output_dir, f\"camelot_stream_table_{i}.csv\")\n",
    "                df.to_csv(output_path, index=False)\n",
    "                print(f\"Tableau sauvegardé: {output_path}\")\n",
    "        else:\n",
    "            print(\"Camelot (stream) n'a trouvé aucun tableau.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur avec camelot: {str(e)}\")\n",
    "    \n",
    "    # 3. Essayer avec PyPDF2 pour extraction de texte brut\n",
    "    try:\n",
    "        print(\"\\nUtilisation de PyPDF2 pour extraction de texte...\")\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            text = \"\"\n",
    "            for page_num, page in enumerate(reader.pages):\n",
    "                page_text = page.extract_text()\n",
    "                text += f\"\\n--- PAGE {page_num+1} ---\\n\" + page_text\n",
    "        \n",
    "        # Nettoyer les marqueurs CID\n",
    "        text = clean_cid_markers(text)\n",
    "        \n",
    "        # Sauvegarder le texte complet\n",
    "        output_path = os.path.join(output_dir, \"pdf_text_extraction.txt\")\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(text)\n",
    "        print(f\"Texte brut sauvegardé: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur avec PyPDF2: {str(e)}\")\n",
    "    \n",
    "    # 4. Essayer avec OCR\n",
    "    try:\n",
    "        print(\"\\nUtilisation de l'OCR (Tesseract)...\")\n",
    "        images = convert_from_path(pdf_path)\n",
    "        \n",
    "        # Sauvegarder le texte OCR page par page\n",
    "        for i, img in enumerate(images):\n",
    "            ocr_text = pytesseract.image_to_string(img)\n",
    "            \n",
    "            # Essayer de détecter des tableaux dans l'image\n",
    "            ocr_data = pytesseract.image_to_data(img, output_type=pytesseract.Output.DATAFRAME)\n",
    "            \n",
    "            # Sauvegarder le texte OCR\n",
    "            output_path = os.path.join(output_dir, f\"ocr_page_{i+1}.txt\")\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(ocr_text)\n",
    "            \n",
    "            # Sauvegarder les données OCR structurées\n",
    "            output_path = os.path.join(output_dir, f\"ocr_data_page_{i+1}.csv\")\n",
    "            ocr_data.to_csv(output_path, index=False)\n",
    "            \n",
    "        print(f\"OCR terminé pour {len(images)} pages.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur avec OCR: {str(e)}\")\n",
    "    \n",
    "    print(\"\\nExtraction terminée. Vérifiez le dossier\", output_dir)\n",
    "\n",
    "# Fonction pour afficher un aperçu des tableaux extraits\n",
    "def preview_extracted_tables(directory):\n",
    "    \"\"\"Affiche un aperçu des tableaux extraits\"\"\"\n",
    "    # Fichiers CSV\n",
    "    csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "    \n",
    "    if csv_files:\n",
    "        print(f\"Aperçu des {len(csv_files)} fichiers CSV extraits:\")\n",
    "        \n",
    "        for csv_file in csv_files:\n",
    "            file_path = os.path.join(directory, csv_file)\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "                print(\"\\n\" + \"=\"*50)\n",
    "                print(f\"Fichier: {csv_file}\")\n",
    "                print(f\"Dimensions: {df.shape[0]} lignes × {df.shape[1]} colonnes\")\n",
    "                print(\"-\"*50)\n",
    "                print(df.head(3))  # Affiche les 3 premières lignes\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur lors de la lecture de {csv_file}: {str(e)}\")\n",
    "    else:\n",
    "        print(\"Aucun fichier CSV trouvé dans le répertoire.\")\n",
    "    \n",
    "    # Fichiers texte\n",
    "    txt_files = [f for f in os.listdir(directory) if f.endswith('.txt')]\n",
    "    \n",
    "    if txt_files:\n",
    "        print(f\"\\nAperçu des {len(txt_files)} fichiers texte extraits:\")\n",
    "        \n",
    "        for txt_file in txt_files:\n",
    "            file_path = os.path.join(directory, txt_file)\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read(500)  # Lire les 500 premiers caractères\n",
    "                \n",
    "                print(\"\\n\" + \"=\"*50)\n",
    "                print(f\"Fichier: {txt_file}\")\n",
    "                print(\"-\"*50)\n",
    "                print(f\"{content}...\")\n",
    "                print(\"\\n[texte tronqué]\")\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur lors de la lecture de {txt_file}: {str(e)}\")\n",
    "    else:\n",
    "        print(\"Aucun fichier texte trouvé dans le répertoire.\")\n",
    "\n",
    "# Post-traitement pour créer une structure de données propre à partir des différentes extractions\n",
    "def post_process_extractions(directory, output_file=\"processed_tables.csv\"):\n",
    "    \"\"\"\n",
    "    Analyse toutes les extractions et tente de créer une version consolidée et propre\n",
    "    \"\"\"\n",
    "    print(\"\\nPost-traitement des extractions...\")\n",
    "    \n",
    "    # Liste tous les fichiers\n",
    "    all_files = os.listdir(directory)\n",
    "    csv_files = [f for f in all_files if f.endswith('.csv')]\n",
    "    txt_files = [f for f in all_files if f.endswith('.txt')]\n",
    "    \n",
    "    # Identifier la meilleure extraction (heuristique simple: celle avec le plus de lignes et colonnes)\n",
    "    best_csv = None\n",
    "    max_cells = 0\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(os.path.join(directory, csv_file))\n",
    "            num_cells = df.shape[0] * df.shape[1]\n",
    "            \n",
    "            if num_cells > max_cells:\n",
    "                max_cells = num_cells\n",
    "                best_csv = csv_file\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if best_csv:\n",
    "        print(f\"Meilleure extraction CSV identifiée: {best_csv}\")\n",
    "        # Charger et nettoyer la meilleure extraction\n",
    "        best_df = pd.read_csv(os.path.join(directory, best_csv))\n",
    "        \n",
    "        # Nettoyage de base\n",
    "        best_df = best_df.dropna(how='all')  # Supprimer les lignes vides\n",
    "        best_df = best_df.dropna(axis=1, how='all')  # Supprimer les colonnes vides\n",
    "        \n",
    "        # Sauvegarder le résultat traité\n",
    "        output_path = os.path.join(directory, output_file)\n",
    "        best_df.to_csv(output_path, index=False)\n",
    "        print(f\"Table traitée sauvegardée dans: {output_path}\")\n",
    "        \n",
    "        return best_df\n",
    "    else:\n",
    "        print(\"Aucune extraction CSV valide n'a été trouvée.\")\n",
    "        return None\n",
    "\n",
    "# Exemple d'utilisation\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_paths = [\n",
    "        r\"C:\\Users\\kosmo\\pycode\\MCP_Rag_pdf_tab2\\sdata201635.pdf\"\n",
    "        # Ajoutez d'autres chemins si nécessaire\n",
    "    ]\n",
    "    \n",
    "    output_dir = \"tableaux_extraits\"\n",
    "    \n",
    "    # Parcourir chaque PDF dans la liste\n",
    "    for i, pdf_path in enumerate(pdf_paths):\n",
    "        print(f\"\\nTraitement du PDF {i+1}/{len(pdf_paths)}: {pdf_path}\")\n",
    "        \n",
    "        # Créer un sous-dossier pour chaque PDF pour éviter les écrasements\n",
    "        pdf_name = os.path.basename(pdf_path).replace(\".pdf\", \"\")\n",
    "        pdf_output_dir = os.path.join(output_dir, pdf_name)\n",
    "        \n",
    "        # Extraire les tableaux\n",
    "        extract_pdf_tables(pdf_path, pdf_output_dir)\n",
    "        \n",
    "        # Afficher un aperçu\n",
    "        preview_extracted_tables(pdf_output_dir)\n",
    "        \n",
    "        # Post-traitement\n",
    "        processed_df = post_process_extractions(pdf_output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
