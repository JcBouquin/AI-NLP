{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6d436a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Scraper Météo Paris - Version Ciblage Précis ===\n",
      "Page web récupérée (355873 caractères)\n",
      "=== Extraction ciblée basée sur l'inspection HTML ===\n",
      "Trouvé 31 conteneurs potentiels de jours\n",
      "\n",
      "Analyse du conteneur #1 pour Lun.21\n",
      "  Textes des éléments de température: ['10', '18']\n",
      "  Températures trouvées: min=10, max=18\n",
      "\n",
      "Analyse du conteneur #2 pour Mar.22\n",
      "  Textes des éléments de température: ['9', '19']\n",
      "  Températures trouvées: min=9, max=19\n",
      "\n",
      "Analyse du conteneur #3 pour Mer.23\n",
      "  Textes des éléments de température: ['', '9', '15']\n",
      "  Températures trouvées: min=9, max=15\n",
      "\n",
      "Analyse du conteneur #4 pour Jeu.24\n",
      "  Textes des éléments de température: ['', '10', '16']\n",
      "  Températures trouvées: min=10, max=16\n",
      "\n",
      "Analyse du conteneur #5 pour Ven.25\n",
      "  Textes des éléments de température: ['', '8', '18']\n",
      "  Températures trouvées: min=8, max=18\n",
      "\n",
      "Analyse du conteneur #6 pour Sam.26\n",
      "  Textes des éléments de température: ['', '11', '16']\n",
      "  Températures trouvées: min=11, max=16\n",
      "\n",
      "Analyse du conteneur #7 pour Dim.27\n",
      "  Textes des éléments de température: ['', '9', '18']\n",
      "  Températures trouvées: min=9, max=18\n",
      "\n",
      "Analyse du conteneur #8 pour Lun.28\n",
      "  Textes des éléments de température: ['', '9', '21']\n",
      "  Températures trouvées: min=9, max=21\n",
      "\n",
      "Analyse du conteneur #9 pour Mar.29\n",
      "  Textes des éléments de température: ['', '13', '23']\n",
      "  Températures trouvées: min=13, max=23\n",
      "\n",
      "Analyse du conteneur #10 pour Lun.21\n",
      "  Textes des éléments de température: ['10', '18', 'Déplier']\n",
      "  Températures trouvées: min=10, max=18\n",
      "\n",
      "Analyse du conteneur #11 pour Lun.21\n",
      "  Pas assez d'éléments de température trouvés\n",
      "\n",
      "Analyse du conteneur #12 pour Mar.22\n",
      "  Textes des éléments de température: ['9', '19', 'Déplier']\n",
      "  Températures trouvées: min=9, max=19\n",
      "\n",
      "Analyse du conteneur #13 pour Mar.22\n",
      "  Pas assez d'éléments de température trouvés\n",
      "\n",
      "Analyse du conteneur #14 pour Mer.23\n",
      "  Textes des éléments de température: ['', '9', '15', 'Déplier']\n",
      "  Températures trouvées: min=9, max=15\n",
      "\n",
      "Analyse du conteneur #15 pour Mer.23\n",
      "  Pas assez d'éléments de température trouvés\n",
      "\n",
      "Analyse du conteneur #16 pour Jeu.24\n",
      "  Textes des éléments de température: ['', '10', '16', 'Déplier']\n",
      "  Températures trouvées: min=10, max=16\n",
      "\n",
      "Analyse du conteneur #17 pour Jeu.24\n",
      "  Pas assez d'éléments de température trouvés\n",
      "\n",
      "Analyse du conteneur #18 pour Ven.25\n",
      "  Textes des éléments de température: ['', '8', '18', 'Déplier']\n",
      "  Températures trouvées: min=8, max=18\n",
      "\n",
      "Analyse du conteneur #19 pour Ven.25\n",
      "  Pas assez d'éléments de température trouvés\n",
      "\n",
      "Analyse du conteneur #20 pour Sam.26\n",
      "  Textes des éléments de température: ['', '11', '16', 'Déplier']\n",
      "  Températures trouvées: min=11, max=16\n",
      "\n",
      "Analyse du conteneur #21 pour Sam.26\n",
      "  Pas assez d'éléments de température trouvés\n",
      "\n",
      "Analyse du conteneur #22 pour Dim.27\n",
      "  Textes des éléments de température: ['', '9', '18', 'Déplier']\n",
      "  Températures trouvées: min=9, max=18\n",
      "\n",
      "Analyse du conteneur #23 pour Dim.27\n",
      "  Pas assez d'éléments de température trouvés\n",
      "\n",
      "Analyse du conteneur #24 pour Lun.28\n",
      "  Textes des éléments de température: ['', '9', '21', 'Déplier']\n",
      "  Températures trouvées: min=9, max=21\n",
      "\n",
      "Analyse du conteneur #25 pour Lun.28\n",
      "  Pas assez d'éléments de température trouvés\n",
      "\n",
      "Analyse du conteneur #26 pour Mar.29\n",
      "  Textes des éléments de température: ['', '13', '23', 'Déplier']\n",
      "  Températures trouvées: min=13, max=23\n",
      "\n",
      "Analyse du conteneur #27 pour Mar.29\n",
      "  Pas assez d'éléments de température trouvés\n",
      "\n",
      "Analyse du conteneur #28 pour Mar.22\n",
      "  Textes des éléments de température: ['9', '19', 'Déplier']\n",
      "  Températures trouvées: min=9, max=19\n",
      "\n",
      "Analyse du conteneur #29 pour Jeu.24\n",
      "  Textes des éléments de température: ['', '10', '16', 'Déplier']\n",
      "  Températures trouvées: min=10, max=16\n",
      "\n",
      "Analyse du conteneur #30 pour Sam.26\n",
      "  Textes des éléments de température: ['', '11', '16', 'Déplier']\n",
      "  Températures trouvées: min=11, max=16\n",
      "\n",
      "Analyse du conteneur #31 pour Lun.28\n",
      "  Textes des éléments de température: ['', '9', '21', 'Déplier']\n",
      "  Températures trouvées: min=9, max=21\n",
      "\n",
      "=== Résultats formatés ===\n",
      "Lun.21, température mini 10°C, maxi 18°C\n",
      "Mar.22, température mini 9°C, maxi 19°C\n",
      "Mer.23, température mini 9°C, maxi 15°C\n",
      "Jeu.24, température mini 10°C, maxi 16°C\n",
      "Ven.25, température mini 8°C, maxi 18°C\n",
      "Sam.26, température mini 11°C, maxi 16°C\n",
      "Dim.27, température mini 9°C, maxi 18°C\n",
      "Lun.28, température mini 9°C, maxi 21°C\n",
      "Mar.29, température mini 13°C, maxi 23°C\n",
      "Lun.21, température mini 10°C, maxi 18°C\n",
      "Mar.22, température mini 9°C, maxi 19°C\n",
      "Mer.23, température mini 9°C, maxi 15°C\n",
      "Jeu.24, température mini 10°C, maxi 16°C\n",
      "Ven.25, température mini 8°C, maxi 18°C\n",
      "Sam.26, température mini 11°C, maxi 16°C\n",
      "Dim.27, température mini 9°C, maxi 18°C\n",
      "Lun.28, température mini 9°C, maxi 21°C\n",
      "Mar.29, température mini 13°C, maxi 23°C\n",
      "Mar.22, température mini 9°C, maxi 19°C\n",
      "Jeu.24, température mini 10°C, maxi 16°C\n",
      "Sam.26, température mini 11°C, maxi 16°C\n",
      "Lun.28, température mini 9°C, maxi 21°C\n"
     ]
    }
   ],
   "source": [
    "# Scraper Météo Paris - Version avec ciblage précis basé sur l'inspection HTML\n",
    "\n",
    "# Installation des dépendances nécessaires\n",
    "# !pip install requests beautifulsoup4 pandas\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Constants\n",
    "BASE_URL = \"https://www.meteo-paris.com/ile-de-france/previsions\"\n",
    "USER_AGENT = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "\n",
    "def fetch_webpage(url):\n",
    "    \"\"\"Fetch the webpage content.\"\"\"\n",
    "    headers = {\n",
    "        \"User-Agent\": USER_AGENT,\n",
    "        \"Accept\": \"text/html\",\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=30.0)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching webpage: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def extract_weather_data_targeted(html_content):\n",
    "    \"\"\"\n",
    "    Extraction ciblée basée sur l'inspection HTML fournie.\n",
    "    Cette méthode s'appuie sur les classes CSS spécifiques vues dans l'inspection.\n",
    "    \"\"\"\n",
    "    if not html_content:\n",
    "        return []\n",
    "    \n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    weather_data = []\n",
    "    \n",
    "    print(\"=== Extraction ciblée basée sur l'inspection HTML ===\")\n",
    "    \n",
    "    # 1. Chercher les jours de la semaine avec leur numéro\n",
    "    # D'après l'inspection, ils sont dans des éléments avec des classes spécifiques\n",
    "    day_pattern = re.compile(r'(Lun\\.|Mar\\.|Mer\\.|Jeu\\.|Ven\\.|Sam\\.|Dim\\.)\\s*(\\d+)')\n",
    "    \n",
    "    # Chercher les éléments qui contiennent le jour et le numéro\n",
    "    # D'après l'inspection, les jours sont dans des éléments avec des classes comme \"flex-1\" ou \"text-xl\"\n",
    "    day_containers = []\n",
    "    \n",
    "    # Méthode 1: Chercher les éléments qui contiennent directement le texte du jour\n",
    "    for text in soup.find_all(string=day_pattern):\n",
    "        parent = text.parent\n",
    "        # Remonter jusqu'à trouver un conteneur qui semble être une ligne de prévision\n",
    "        container = parent\n",
    "        while container and container.name != 'div' and not container.get('class'):\n",
    "            container = container.parent\n",
    "        \n",
    "        if container and container not in day_containers:\n",
    "            day_containers.append(container)\n",
    "    \n",
    "    # Méthode 2: Chercher par structure de classes vue dans l'inspection\n",
    "    row_selectors = [\n",
    "        'div.flex-1',\n",
    "        'div[class*=\"flex-1\"]',\n",
    "        'div.relative.flex',\n",
    "        'div[class*=\"relative\"]',\n",
    "        'div.bg-secondary-darken'\n",
    "    ]\n",
    "    \n",
    "    for selector in row_selectors:\n",
    "        elements = soup.select(selector)\n",
    "        for elem in elements:\n",
    "            text = elem.get_text()\n",
    "            if day_pattern.search(text) and elem not in day_containers:\n",
    "                day_containers.append(elem)\n",
    "    \n",
    "    print(f\"Trouvé {len(day_containers)} conteneurs potentiels de jours\")\n",
    "    \n",
    "    # Pour chaque conteneur de jour, chercher les températures associées\n",
    "    for i, container in enumerate(day_containers):\n",
    "        container_text = container.get_text().strip()\n",
    "        day_match = day_pattern.search(container_text)\n",
    "        \n",
    "        if day_match:\n",
    "            full_day = day_match.group(0)\n",
    "            full_day = full_day.split('.')[0] + '.' + full_day.split('.')[1][:2]\n",
    "             \n",
    "            print(f\"\\nAnalyse du conteneur #{i+1} pour {full_day}\")\n",
    "            \n",
    "            # D'après l'inspection, les températures sont dans des éléments circulaires\n",
    "            # avec des classes comme \"rounded-full\" ou des couleurs de fond spécifiques\n",
    "            \n",
    "            # Méthode 1: Chercher des éléments avec la classe rounded-full\n",
    "            temp_elements = container.select('.rounded-full') or container.select('[class*=\"rounded\"]')\n",
    "            \n",
    "            # Méthode 2: Chercher des éléments avec les couleurs de fond vues dans l'inspection\n",
    "            if not temp_elements:\n",
    "                temp_elements = []\n",
    "                \n",
    "                # Chercher par la structure de classe vue dans l'inspection\n",
    "                for elem in container.find_all():\n",
    "                    elem_classes = elem.get('class', [])\n",
    "                    elem_class_str = ' '.join(elem_classes) if elem_classes else ''\n",
    "                    \n",
    "                    # Ces éléments correspondent souvent aux températures\n",
    "                    if (('flex' in elem_class_str and 'items-center' in elem_class_str) or\n",
    "                        ('bg-' in elem_class_str) or\n",
    "                        ('rounded' in elem_class_str)):\n",
    "                        \n",
    "                        elem_text = elem.get_text().strip()\n",
    "                        # Vérifier que c'est un nombre simple\n",
    "                        if re.match(r'^\\d+$', elem_text):\n",
    "                            temp_elements.append(elem)\n",
    "            \n",
    "            # Si nous avons trouvé des éléments de température\n",
    "            if temp_elements and len(temp_elements) >= 2:\n",
    "                temp_texts = [elem.get_text().strip() for elem in temp_elements]\n",
    "                print(f\"  Textes des éléments de température: {temp_texts}\")\n",
    "                \n",
    "                # Filtrer pour ne garder que les éléments qui contiennent des nombres\n",
    "                temp_elements = [elem for elem in temp_elements if re.match(r'^\\d+$', elem.get_text().strip())]\n",
    "                \n",
    "                if len(temp_elements) >= 2:\n",
    "                    # Les deux premiers éléments sont probablement min et max\n",
    "                    temp_min = temp_elements[0].get_text().strip()\n",
    "                    temp_max = temp_elements[1].get_text().strip()\n",
    "                    \n",
    "                    print(f\"  Températures trouvées: min={temp_min}, max={temp_max}\")\n",
    "                    \n",
    "                    weather_data.append({\n",
    "                        \"date\": full_day,\n",
    "                        \"temperature_min\": temp_min,\n",
    "                        \"temperature_max\": temp_max,\n",
    "                        \"source\": \"Ciblage précis\"\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"  Pas assez d'éléments de température trouvés après filtrage\")\n",
    "            else:\n",
    "                print(f\"  Pas assez d'éléments de température trouvés\")\n",
    "                \n",
    "                # Dernière tentative: chercher des nombres simples dans le conteneur\n",
    "                numbers = re.findall(r'\\b\\d{1,2}\\b', container_text)\n",
    "                \n",
    "                if len(numbers) >= 3:  # Jour + min + max\n",
    "                    # Le premier nombre est souvent le jour\n",
    "                    if numbers[0] in full_day:\n",
    "                        temp_min, temp_max = numbers[1], numbers[2]\n",
    "                    else:\n",
    "                        temp_min, temp_max = numbers[0], numbers[1]\n",
    "                    \n",
    "                    print(f\"  Températures extraites du texte: min={temp_min}, max={temp_max}\")\n",
    "                    \n",
    "                    weather_data.append({\n",
    "                        \"date\": full_day,\n",
    "                        \"temperature_min\": temp_min,\n",
    "                        \"temperature_max\": temp_max,\n",
    "                        \"source\": \"Extraction de texte\"\n",
    "                    })\n",
    "    \n",
    "    # Si nous n'avons pas trouvé de données, essayer une approche plus générique\n",
    "    if not weather_data:\n",
    "        weather_data = extract_weather_data_generic(soup)\n",
    "    \n",
    "    return weather_data\n",
    "\n",
    "def extract_weather_data_generic(soup):\n",
    "    \"\"\"\n",
    "    Méthode d'extraction générique qui tente de trouver les données\n",
    "    sans s'appuyer sur des classes spécifiques.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Extraction générique ===\")\n",
    "    weather_data = []\n",
    "    \n",
    "    # Pattern pour les jours de la semaine\n",
    "    day_pattern = re.compile(r'(Lun\\.|Mar\\.|Mer\\.|Jeu\\.|Ven\\.|Sam\\.|Dim\\.)\\s*(\\d+)')\n",
    "    \n",
    "    # Chercher tous les éléments qui pourraient contenir un jour de la semaine\n",
    "    day_elements = []\n",
    "    \n",
    "    for element in soup.find_all(string=day_pattern):\n",
    "        parent = element.parent\n",
    "        day_elements.append(parent)\n",
    "    \n",
    "    print(f\"Trouvé {len(day_elements)} éléments contenant des jours\")\n",
    "    \n",
    "    # Pour chaque jour trouvé\n",
    "    for day_elem in day_elements:\n",
    "        day_text = day_elem.get_text().strip()\n",
    "        day_match = day_pattern.search(day_text)\n",
    "        \n",
    "        if day_match:\n",
    "            full_day = day_match.group(0)\n",
    "            print(f\"Analyse pour {full_day}\")\n",
    "            \n",
    "            # Chercher les températures à proximité de cet élément\n",
    "            # 1. Chercher dans les frères de l'élément\n",
    "            siblings = list(day_elem.parent.find_all(recursive=False))\n",
    "            \n",
    "            # Chercher des éléments qui contiennent un seul nombre\n",
    "            number_elements = []\n",
    "            \n",
    "            for sib in siblings:\n",
    "                sib_text = sib.get_text().strip()\n",
    "                if re.match(r'^\\d+$', sib_text):\n",
    "                    number_elements.append(sib)\n",
    "            \n",
    "            # Si nous avons trouvé au moins deux nombres\n",
    "            if len(number_elements) >= 2:\n",
    "                temp_min = number_elements[0].get_text().strip()\n",
    "                temp_max = number_elements[1].get_text().strip()\n",
    "                \n",
    "                print(f\"  Températures trouvées dans les frères: min={temp_min}, max={temp_max}\")\n",
    "                \n",
    "                weather_data.append({\n",
    "                    \"date\": full_day,\n",
    "                    \"temperature_min\": temp_min,\n",
    "                    \"temperature_max\": temp_max,\n",
    "                    \"source\": \"Éléments frères\"\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # 2. Si nous n'avons pas trouvé dans les frères directs, chercher dans le parent\n",
    "            parent_container = day_elem.parent\n",
    "            \n",
    "            # Chercher des éléments qui contiennent un seul nombre\n",
    "            number_elements = []\n",
    "            \n",
    "            for elem in parent_container.find_all():\n",
    "                elem_text = elem.get_text().strip()\n",
    "                if re.match(r'^\\d+$', elem_text):\n",
    "                    number_elements.append(elem)\n",
    "            \n",
    "            # Si nous avons trouvé au moins deux nombres\n",
    "            if len(number_elements) >= 2:\n",
    "                temp_min = number_elements[0].get_text().strip()\n",
    "                temp_max = number_elements[1].get_text().strip()\n",
    "                \n",
    "                print(f\"  Températures trouvées dans le parent: min={temp_min}, max={temp_max}\")\n",
    "                \n",
    "                weather_data.append({\n",
    "                    \"date\": full_day,\n",
    "                    \"temperature_min\": temp_min,\n",
    "                    \"temperature_max\": temp_max,\n",
    "                    \"source\": \"Éléments parent\"\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # 3. Dernière tentative: chercher des nombres dans le texte autour du jour\n",
    "            row_text = parent_container.get_text()\n",
    "            numbers = re.findall(r'\\b\\d{1,2}\\b', row_text)\n",
    "            \n",
    "            if len(numbers) >= 3:  # Jour + min + max\n",
    "                # Vérifier si le premier nombre est le jour\n",
    "                if numbers[0] in full_day:\n",
    "                    temp_min, temp_max = numbers[1], numbers[2]\n",
    "                else:\n",
    "                    temp_min, temp_max = numbers[0], numbers[1]\n",
    "                \n",
    "                print(f\"  Températures extraites du texte: min={temp_min}, max={temp_max}\")\n",
    "                \n",
    "                weather_data.append({\n",
    "                    \"date\": full_day,\n",
    "                    \"temperature_min\": temp_min,\n",
    "                    \"temperature_max\": temp_max,\n",
    "                    \"source\": \"Texte\"\n",
    "                })\n",
    "    \n",
    "    return weather_data\n",
    "\n",
    "def find_weather_by_structure(html_content):\n",
    "    \"\"\"\n",
    "    Cette méthode cherche spécifiquement les éléments arrondis jaunes et verts\n",
    "    qui contiennent les températures, comme vu dans les captures d'écran.\n",
    "    \"\"\"\n",
    "    if not html_content:\n",
    "        return []\n",
    "    \n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    weather_data = []\n",
    "    \n",
    "    print(\"\\n=== Recherche par structure visuelle ===\")\n",
    "    \n",
    "    # Chercher les lignes qui contiennent les jours et les températures\n",
    "    # D'après les captures d'écran, chaque ligne contient un jour (Lun. 21, etc.)\n",
    "    # et deux cercles colorés pour les températures min et max\n",
    "    \n",
    "    # 1. D'abord, chercher toutes les lignes potentielles\n",
    "    day_pattern = re.compile(r'(Lun\\.|Mar\\.|Mer\\.|Jeu\\.|Ven\\.|Sam\\.|Dim\\.)\\s*(\\d+)')\n",
    "    \n",
    "    # Chercher les éléments qui pourraient être des lignes de prévision\n",
    "    # D'après l'inspection, cela pourrait être des div avec des classes comme bg-secondary-darken\n",
    "    rows = soup.select('div.bg-secondary-darken') or soup.select('div[class*=\"flex-1\"]') or soup.select('div.relative')\n",
    "    \n",
    "    print(f\"Trouvé {len(rows)} lignes potentielles\")\n",
    "    \n",
    "    # Pour chaque ligne potentielle\n",
    "    for i, row in enumerate(rows[:10]):  # Limiter à 10 pour le débogage\n",
    "        row_text = row.get_text().strip()\n",
    "        day_match = day_pattern.search(row_text)\n",
    "        \n",
    "        if day_match:\n",
    "            full_day = day_match.group(0)\n",
    "          \n",
    "            print(f\"\\nLigne #{i+1} contenant {full_day}\")\n",
    "            \n",
    "            # Chercher spécifiquement les éléments arrondis qui contiennent les températures\n",
    "            # D'après les captures d'écran, ils ont souvent des classes contenant \"rounded\"\n",
    "            # et peuvent avoir des arrière-plans colorés\n",
    "            temp_elements = row.select('[class*=\"rounded\"]')\n",
    "            \n",
    "            # Filtrer pour ne garder que ceux qui contiennent un nombre simple\n",
    "            temp_elements = [elem for elem in temp_elements if re.match(r'^\\d+$', elem.get_text().strip())]\n",
    "            \n",
    "            if temp_elements:\n",
    "                print(f\"  Trouvé {len(temp_elements)} éléments de température potentiels\")\n",
    "                \n",
    "                # Afficher les classes pour aider au débogage\n",
    "                for j, elem in enumerate(temp_elements[:5]):\n",
    "                    elem_classes = ' '.join(elem.get('class', []))\n",
    "                    elem_text = elem.get_text().strip()\n",
    "                    print(f\"  #{j+1}: {elem_text} - Classes: {elem_classes}\")\n",
    "                \n",
    "                # Si nous avons au moins deux éléments (min et max)\n",
    "                if len(temp_elements) >= 2:\n",
    "                    temp_min = temp_elements[0].get_text().strip()\n",
    "                    temp_max = temp_elements[1].get_text().strip()\n",
    "                    \n",
    "                    print(f\"  Températures extraites: min={temp_min}, max={temp_max}\")\n",
    "                    \n",
    "                    weather_data.append({\n",
    "                        \"date\": full_day,\n",
    "                        \"temperature_min\": temp_min,\n",
    "                        \"temperature_max\": temp_max,\n",
    "                        \"source\": \"Structure visuelle\"\n",
    "                    })\n",
    "            else:\n",
    "                print(f\"  Pas d'éléments arrondis trouvés dans cette ligne\")\n",
    "    \n",
    "    return weather_data\n",
    "\n",
    "def main():\n",
    "    \"\"\"Fonction principale qui exécute l'analyse complète.\"\"\"\n",
    "    print(\"=== Scraper Météo Paris - Version Ciblage Précis ===\")\n",
    "    html_content = fetch_webpage(BASE_URL)\n",
    "    \n",
    "    if not html_content:\n",
    "        print(\"Échec de la récupération de la page web\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Page web récupérée ({len(html_content)} caractères)\")\n",
    "    \n",
    "    # Essayer d'abord l'extraction ciblée basée sur l'inspection HTML\n",
    "    weather_data = extract_weather_data_targeted(html_content)\n",
    "    \n",
    "    # Si cela échoue, essayer la recherche par structure visuelle\n",
    "    if not weather_data:\n",
    "        weather_data = find_weather_by_structure(html_content)\n",
    "    \n",
    "    # Si toutes les méthodes échouent, créer des données placeholder\n",
    "     \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Afficher les résultats formatés\n",
    "    print(\"\\n=== Résultats formatés ===\")\n",
    "    for day in weather_data:\n",
    "        print(f\"{day['date']}, température mini {day['temperature_min']}°C, maxi {day['temperature_max']}°C\")\n",
    "    \n",
    "     \n",
    "    \n",
    "    \n",
    "\n",
    "# Pour exécuter l'analyse\n",
    "df_meteo = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
